{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ransac affine for point cloud alignment\n",
    "In this tutorial we will learn to align several point clouds using two variants of the ransac affine and ICP algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to implement other better non-rigid methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with loading the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pools\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from math import pi, sin, cos, sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from matplotlib import cm\n",
    "from scipy import ndimage\n",
    "import scipy.io\n",
    "from skimage import data\n",
    "from skimage.io import imread, imsave\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from cv2 import estimateTranslation3D\n",
    "import tifffile\n",
    "import seaborn as sns\n",
    "\n",
    "# import bigstream library\n",
    "import zarr\n",
    "from bigstream import features\n",
    "from bigstream import features1\n",
    "from bigstream import ransac\n",
    "from bigstream import affine\n",
    "from bigstream import affine1\n",
    "from bigstream import transform\n",
    "from fishspot.filter import white_tophat\n",
    "from fishspot.detect import detect_spots_log\n",
    "\n",
    "# napari\n",
    "%gui qt5\n",
    "import napari\n",
    "viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with loading the required modules for ransac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ransac from bigstream\n",
    "def blob_detection(\n",
    "    image,\n",
    "    min_blob_radius,\n",
    "    max_blob_radius,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "  #  wth = white_tophat(image, max_blob_radius)\n",
    "    spots = detect_spots_log(\n",
    "        image,\n",
    "        min_blob_radius,\n",
    "        max_blob_radius,\n",
    "        **kwargs,\n",
    "    ).astype(int)\n",
    "    intensities = image[spots[:, 0], spots[:, 1], spots[:, 2]]\n",
    "    return np.hstack((spots[:, :3], intensities[..., None]))\n",
    "\n",
    "def get_spot_context(image, spots, vox, radius):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # s[0] need to be pixels in images, spot is phsyical distance/um, and vox is um/pixel\n",
    "    output = []\n",
    "    for spot in spots:\n",
    "        s = (spot/vox).astype(int)\n",
    "        w = image[s[0]-radius:s[0]+radius+1,\n",
    "                  s[1]-radius:s[1]+radius+1,\n",
    "                  s[2]-radius:s[2]+radius+1]\n",
    "        output.append( [spot, w] )\n",
    "    return output    \n",
    "\n",
    "def pairwise_correlation(A, B):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # grab and flatten context\n",
    "    a_con = np.array( [a[1].flatten() for a in A] )\n",
    "    b_con = np.array( [b[1].flatten() for b in B] )\n",
    "\n",
    "    # get means and std for all contexts, center contexts\n",
    "    a_mean, a_std = _stats(a_con)\n",
    "    b_mean, b_std = _stats(b_con)\n",
    "    a_con = a_con - a_mean[..., None]\n",
    "    b_con = b_con - b_mean[..., None]\n",
    "\n",
    "    # compute pairwise correlations\n",
    "    corr = np.matmul(a_con, b_con.T)\n",
    "    corr = corr / a_std[..., None]\n",
    "    corr = corr / b_std[None, ...]\n",
    "    corr = corr / a_con.shape[1]\n",
    "\n",
    "    # contexts with no variability are nan, set to 0\n",
    "    corr[np.isnan(corr)] = 0\n",
    "    return corr\n",
    "\n",
    "def _stats(arr):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # compute mean and standard deviation along columns\n",
    "    arr = arr.astype(np.float64)\n",
    "    means = np.mean(arr, axis=1)\n",
    "    sqr_means = np.mean(np.square(arr), axis=1)\n",
    "    stddevs = np.sqrt( sqr_means - np.square(means) )\n",
    "    return means, stddevs\n",
    "\n",
    "def match_points(A, B, scores, threshold):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # split positions from context\n",
    "    a_pos = np.array( [a[0] for a in A] )\n",
    "    b_pos = np.array( [b[0] for b in B] )\n",
    "\n",
    "    # get highest scores above threshold\n",
    "    best_indcs = np.argmax(scores, axis=1)\n",
    "    a_indcs = range(len(a_pos))\n",
    "    keeps = scores[(a_indcs, best_indcs)] > threshold\n",
    "\n",
    "    # return positions of corresponding points\n",
    "    return a_pos[keeps, :3], b_pos[best_indcs[keeps], :3]\n",
    "\n",
    "def ransac_align_points(\n",
    "    pA, pB, threshold, diagonal_constraint=0.75, default=np.eye(4)[:3],\n",
    "):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # sensible requirement of 51 or more spots to compute ransac affine\n",
    "    if len(pA) <= 4 or len(pB) <= 4:\n",
    "        if default is not None:\n",
    "            print(\"Insufficient spot matches for ransac, returning default identity\")\n",
    "            return default\n",
    "        else:\n",
    "            raise ValueError(\"Insufficient spot matches for ransac, need more than 4\")\n",
    "\n",
    "    # compute the affine\n",
    "    r, Aff, inline = cv2.estimateAffine3D(pA, pB, ransacThreshold=threshold, confidence=0.999)\n",
    "\n",
    "#     print(np.diag(Aff))\n",
    "#     print(Aff)\n",
    "#     print(diagonal_constraint)\n",
    "    # rarely ransac just doesn't work (depends on data and parameters)\n",
    "    # sensible choices for hard constraints on the affine matrix\n",
    "    if np.any( np.diag(Aff) < diagonal_constraint ):\n",
    "        if default is not None:\n",
    "            print(\"Degenerate affine produced, returning default identity\")\n",
    "            return default\n",
    "        else:\n",
    "            raise ValueError(\"Degenerate affine produced, ransac failed\")\n",
    "\n",
    "    return Aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucldist(coords1, coords2):\n",
    "    \"\"\" Calculates the euclidean distance between 2 lists of coordinates. \"\"\"\n",
    "    dist = np.zeros(len(coords1))\n",
    "    i = 0\n",
    "    for (x, y) in zip(coords1, coords2):\n",
    "        p1 = x\n",
    "        p2 = y\n",
    "        squared_dist = (p1[0]-p2[0])**2+(p1[1]-p2[1])**2+(p1[2]-p2[2])**2\n",
    "        dist[i] = np.sqrt(squared_dist)\n",
    "        i = i+1\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spot_inside(all_spots,segmentation_mini,fix_spacing,ROI_fixed,cc):\n",
    "    \"\"\"remove spots outside of segmenation_mini\n",
    "       change spot location back to segmentation mask in pixels\n",
    "    \"\"\"\n",
    "    fix_spots_mini = all_spots[:,:3] / fix_spacing * [0.5,0.25,0.25] + cc\n",
    "    spot_mini = np.zeros(len(fix_spots_mini))\n",
    "    rounded_spot = fix_spots_mini.astype('int') \n",
    "    for i in range(0, len(fix_spots_mini)):          \n",
    "        Coord = rounded_spot[i]\n",
    "        if Coord[0]<0: Coord[0] = 0\n",
    "        if Coord[1]<0: Coord[1] = 0\n",
    "        if Coord[2]<0: Coord[2] = 0\n",
    "        if Coord[0]>segmentation_mini.shape[0]: Coord[0] = segmentation_mini.shape[0]\n",
    "        if Coord[1]>segmentation_mini.shape[1]: Coord[1] = segmentation_mini.shape[1]            \n",
    "        if Coord[2]>segmentation_mini.shape[2]: Coord[2] = segmentation_mini.shape[2]\n",
    "        idx = segmentation_mini[Coord[0]-1, Coord[1]-1, Coord[2]-1]   # roi id\n",
    "        if idx == ROI_fixed:\n",
    "            spot_mini[i] = idx  # add ROI number  \n",
    "    spots_in = all_spots[np.where(spot_mini==ROI_fixed)]\n",
    "    spots_out = all_spots[np.where(spot_mini==0)]\n",
    "\n",
    "    ns = spots_in.shape[0]\n",
    "    print(f'Image: found {ns} key points inside ROI')\n",
    "    print(f'Image: found {spots_out.shape[0]} key points outside ROI')\n",
    "    return spots_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance of paired spot cloud\n",
    "def cloud_distance(spot_fix,spot_mov):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    c0=spot_fix[:,:3].copy()\n",
    "    c1=spot_mov[:,:3].copy()\n",
    "    kdtree_c0 = cKDTree(c0)\n",
    "    kdtree_c1 = cKDTree(c1)\n",
    "    dist2,idx2 = kdtree_c0.query(c1, k=3)\n",
    "    [Idx_unique, I] = np.unique(idx2,return_index=True) \n",
    "    \n",
    "#     ## find the smallest repeated value location, and delete the others\n",
    "#     for i in range(Idx_unique.shape[0]):  \n",
    "#         Loc_rep=np.where(idx2==Idx_unique[i])  # multiple loc, but should repeat for only once   \n",
    "#     #     print(Loc_rep[0])\n",
    "#         A=dist2[Loc_rep[0],Loc_rep[1]]\n",
    "#         minposition = min(A)\n",
    "#         Loc_min = np.where(A==minposition)[0]\n",
    "#     #     print(Loc_min)\n",
    "#     #     Loc_rep_min=Loc_rep[0][Loc_min[0]]    \n",
    "#         Loc_rep_nouse=np.delete(range(len(Loc_rep[0])),Loc_min)\n",
    "#         dist2[Loc_rep[0][Loc_rep_nouse],Loc_rep[1][Loc_rep_nouse]]=neighbor_radius*2 \n",
    "#     ## find the results that are less than radius; used later column data \n",
    "#     # when only first row is not exist use latter column, or just dispose it. \n",
    "#     co_loc=np.where(dist2>neighbor_radius)\n",
    "\n",
    "#     for j in range(dist2.shape[0]):\n",
    "#          if dist2[j,0] < neighbor_radius:\n",
    "#                 dist2[j,1] = neighbor_radius*2\n",
    "#     for j in range(dist2.shape[0]):            \n",
    "#          if dist2[j,0] <neighbor_radius or dist2[j,1] <neighbor_radius:\n",
    "#                 dist2[j,2] = neighbor_radius*2       \n",
    "#     row_c1 = np.where(dist2<neighbor_radius)\n",
    "# #     print(len(row_c1[0]))\n",
    "\n",
    "#     # lipo spot_c1 is row_c1\n",
    "#     pBind = row_c1[0]\n",
    "#     # print(idx2)\n",
    "#     # lipo spot_c1 is idx2\n",
    "#     pAind = [(idx2[row_c1[0][x], row_c1[1][x]]) for x in range(len(row_c1[0]))]\n",
    "#     lipo_c0 = spot_c0[pAind]\n",
    "#     lipo_c1 = spot_c1[pBind]\n",
    "\n",
    "# #     print(np.unique(pAind).shape)\n",
    "    \n",
    "#     true_pos_c0 = np.delete(spot_c0, pAind, axis=0)\n",
    "#     true_pos_c1 = np.delete(spot_c1, pBind, axis=0) #true\n",
    "    \n",
    "    \n",
    "    return dist2[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colocalization filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colocalization(spot_c0,spot_c1,neighbor_radius):\n",
    "    # Fix and Mov true spots\n",
    "#     neighbor_radius = math.sqrt(3*3*3) #3.464\n",
    "    #vox=[0.23,0.23,0.38]\n",
    "    c0=spot_c0[:,:3].copy()\n",
    "    c1=spot_c1[:,:3].copy()\n",
    "\n",
    "    kdtree_c0 = cKDTree(c0)\n",
    "    kdtree_c1 = cKDTree(c1)\n",
    "    neighbors = kdtree_c0.query_ball_tree(kdtree_c1, neighbor_radius)\n",
    "    # neighbors1 = kdtree_c0.query_ball_point(c1,neighbor_radius) #1 is all unique idx, 2 is the location\n",
    "    # neighbors2 = kdtree_c0.sparse_distance_matrix(kdtree_c1, neighbor_radius)\n",
    "    dist2,idx2 = kdtree_c0.query(c1, k=3)\n",
    "    [Idx_unique, I] = np.unique(idx2,return_index=True) \n",
    "#     print(len(dist2[:,0])*3)\n",
    "    \n",
    "    ## find the smallest repeated value location, and delete the others\n",
    "    for i in range(Idx_unique.shape[0]):  # should repeat for only once\n",
    "    #     print(Idx_unique[i])\n",
    "        Loc_rep=np.where(idx2==Idx_unique[i])    \n",
    "    #     print(Loc_rep[0])\n",
    "        A=dist2[Loc_rep[0],Loc_rep[1]]\n",
    "        minposition = min(A)\n",
    "        Loc_min = np.where(A==minposition)[0]\n",
    "    #     print(Loc_min)\n",
    "    #     Loc_rep_min=Loc_rep[0][Loc_min[0]]    \n",
    "        Loc_rep_nouse=np.delete(range(len(Loc_rep[0])),Loc_min)\n",
    "        dist2[Loc_rep[0][Loc_rep_nouse],Loc_rep[1][Loc_rep_nouse]]=neighbor_radius*2 \n",
    "    ## find the results that are less than radius; used later column data \n",
    "    # when only first row is not exist use latter column, or just dispose it. \n",
    "    co_loc=np.where(dist2>neighbor_radius)\n",
    "\n",
    "    for j in range(dist2.shape[0]):\n",
    "         if dist2[j,0] < neighbor_radius:\n",
    "                dist2[j,1] = neighbor_radius*2\n",
    "    for j in range(dist2.shape[0]):            \n",
    "         if dist2[j,0] <neighbor_radius or dist2[j,1] <neighbor_radius:\n",
    "                dist2[j,2] = neighbor_radius*2       \n",
    "    row_c1 = np.where(dist2<neighbor_radius)\n",
    "#     print(len(row_c1[0]))\n",
    "\n",
    "    # lipo spot_c1 is row_c1\n",
    "    pBind = row_c1[0]\n",
    "    # print(idx2)\n",
    "    # lipo spot_c1 is idx2\n",
    "    pAind = [(idx2[row_c1[0][x], row_c1[1][x]]) for x in range(len(row_c1[0]))]\n",
    "    lipo_c0 = spot_c0[pAind]\n",
    "    lipo_c1 = spot_c1[pBind]\n",
    "\n",
    "#     print(np.unique(pAind).shape)\n",
    "    \n",
    "    true_pos_c0 = np.delete(spot_c0, pAind, axis=0)\n",
    "    true_pos_c1 = np.delete(spot_c1, pBind, axis=0) #true\n",
    "\n",
    "    if spot_c0.shape[0]>0:\n",
    "        P1 = (lipo_c0.shape[0] / spot_c0.shape[0])*100   # % mov spots from  previous images  /spot_c0.shape\n",
    "    else:\n",
    "        P1 = 0\n",
    "        \n",
    "    if spot_c1.shape[0]>0:\n",
    "        P2 = (lipo_c1.shape[0] / spot_c1.shape[0])*100  # % fixed spots can be found in later mov images  /spot_c0.shape\n",
    "    else:\n",
    "        P2 = 0\n",
    "\n",
    "    print('% P1: ',str(P1) + ';  % P2: ',str(P2)) \n",
    "    Dist = eucldist(lipo_c0,lipo_c1)\n",
    "\n",
    "    return lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## ICP\n",
    "def nearest_neighbor(src, dst):\n",
    "    '''\n",
    "    Find the nearest (Euclidean) neighbor in dst for each point in src\n",
    "    Input:\n",
    "        src: Nx3 array of points\n",
    "        dst: Nx3 array of points\n",
    "    Output:\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "        indecies: dst indecies of the nearest neighbor\n",
    "    '''\n",
    "\n",
    "    indecies = np.zeros(src.shape[0], dtype=np.int)\n",
    "    distances = np.zeros(src.shape[0])\n",
    "    for i, s in enumerate(src):\n",
    "        min_dist = np.inf\n",
    "        for j, d in enumerate(dst):\n",
    "            dist = np.linalg.norm(s-d)\n",
    "            # 找出与src[i]距离最近的dst[j]\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                indecies[i] = j\n",
    "                distances[i] = dist\n",
    "    return distances, indecies  \n",
    "\n",
    "def best_fit_transform(A, B):\n",
    "    '''\n",
    "    Calculates the least-squares best-fit transform between corresponding 3D points A->B\n",
    "    Input:\n",
    "      A: Nx3 numpy array of corresponding 3D points\n",
    "      B: Nx3 numpy array of corresponding 3D points\n",
    "    Returns:\n",
    "      T: 4x4 homogeneous transformation matrix\n",
    "      R: 3x3 rotation matrix\n",
    "      t: 3x1 column vector\n",
    "    '''\n",
    "    assert len(A) == len(B)\n",
    "\n",
    "    # translate points to their centroids\n",
    "    centroid_A = np.mean(A, axis=0) \n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # rotation matrix\n",
    "    W = np.dot(BB.T, AA)\n",
    "    U, s, VT = np.linalg.svd(W, full_matrices=True, compute_uv=True)\n",
    "    R = np.dot(U, VT)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        VT[2,:] *= -1\n",
    "        R = np.dot(U, VT)\n",
    "\n",
    "    # translation\n",
    "    t = centroid_B.T - np.dot(R,centroid_A.T)\n",
    "\n",
    "    # homogeneous transformation\n",
    "    T = np.identity(4)\n",
    "    T[0:3, 0:3] = R\n",
    "    T[0:3, 3] = t\n",
    "\n",
    "    return T, R, t\n",
    "       \n",
    "def icp(A, B, init_pose = None, max_iterations=200, tolerance=0.0001):\n",
    "    '''\n",
    "    The Iterative Closest Point method\n",
    "    Input:\n",
    "        A: Nx3 numpy array of source 3D points\n",
    "        B: Nx3 numpy array of destination 3D point\n",
    "        init_pose: 4x4 homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "    '''\n",
    "    #  select points \n",
    "    A,B,_,_,dist = colocalization(A,B,3)\n",
    "    \n",
    "    # make points homogeneous, copy them so as to maintain the originals\n",
    "    src = np.ones((4,A.shape[0]))  #(4, A.shape[0])\n",
    "    dst = np.ones((4,B.shape[0]))\n",
    "    src[0:3,:] = np.copy(A.T)  # A.T shape (3,20)\n",
    "    dst[0:3,:] = np.copy(B.T)\n",
    "    \n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    prev_error = 0\n",
    "    distances_iter = np.zeros((max_iterations,1))\n",
    "    for i in range(max_iterations):\n",
    "        # find the nearest neighbours between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[0:3,:].T, dst[0:3,:].T)\n",
    "\n",
    "#         AAA = np.where(distances<3)\n",
    "#         BBB = indices[AAA]\n",
    "#         src = src[0:3,AAA]  # A.T shape (3,20)\n",
    "#         dst = dst[0:3,BBB]\n",
    "#         A = A[AAA,0:3]\n",
    "        \n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T,_,_ = best_fit_transform(src[0:3,:].T, dst[0:3,indices].T)  #将dst[]按照indices排序\n",
    "#         T,_,_ = best_fit_transform(src[0:3,AAA].T, dst[0:3,BBB].T)  #将dst[]按照indices排序\n",
    "\n",
    "        # update the current source\n",
    "    # refer to \"Introduction to Robotics\" Chapter2 P28. Spatial description and transformations\n",
    "        src = np.dot(T, src)\n",
    "\n",
    "        # check error\n",
    "        mean_error = np.sum(distances) / distances.size\n",
    "#         print(f'mean_error: {mean_error}')\n",
    "        if abs(prev_error-mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "        distances_iter[i] = mean_error\n",
    "    \n",
    "#     fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "#     plt.plot(distances_iter[:20])\n",
    "#     sns.despine() \n",
    "#     plt.xlabel('Spots:'+ str(distances_iter[:20].shape[0]))\n",
    "#     plt.ylabel('Distance/pixel')\n",
    "#     ave=np.average(distances_iter[:20])\n",
    "#     plt.title(str(float('%.2f' % ave)))\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(f'mean_error: {mean_error}')\n",
    "    # calculcate final tranformation\n",
    "    T,_,_ = best_fit_transform(A, src[0:3,:].T)\n",
    "\n",
    "    return T, distances     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use import spots or not. If yes, the spot should align with images checked with Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hAir = 0\n",
    "# Adapt ROI from images or from hAirlocalize\n",
    "if hAir < 1:\n",
    "    print(f'hAirlocalize points')\n",
    "    # read spot data into memory as numpy arrays  Airlocolize spots data in xyz order: physical distance\n",
    "    spotdir = 'E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/spots/R2_c3_ROI.txt'\n",
    "    spot_fix=np.loadtxt(spotdir, delimiter=',')\n",
    "    fixed_spots1 = spot_fix[spot_fix[:,4] == i][:,:3]\n",
    "    spotdir = 'E:/Maxprobe_analysis/R2_R1_3tm50/R1_3tm50_1920/spots/R1_c3_ROI.txt'\n",
    "    spot_mov=np.loadtxt(spotdir, delimiter=',')\n",
    "    moving_spots1 = spot_mov[spot_mov[:,4] == i][:,:3]\n",
    "    # change to zyx order\n",
    "    fixed_spots11 = np.transpose(np.array([fixed_spots1[:,2],fixed_spots1[:,1],fixed_spots1[:,0]]))\n",
    "    moving_spots11 = np.transpose(np.array([moving_spots1[:,2],moving_spots1[:,1],moving_spots1[:,0]]))\n",
    "    # convert to physical units\n",
    "    ccc = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "    fix_spots = (fixed_spots11 - ccc * fix_spacing)\n",
    "    fix_spots_new = fix_spots\n",
    "    ns = fix_spots.shape[0]\n",
    "    print(f'FIXED image: found {ns} key points')\n",
    "\n",
    "    dd = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "#     mov_spots_h = (moving_spots11/fix_spacing - dd).astype(int)\n",
    "    mov_spots = (moving_spots11 - dd * mov_spacing)\n",
    "    ns = mov_spots.shape[0]\n",
    "    print(f'MOVING image: found {ns} key points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_affine(segmentation1,segmentation2,ROI_fixed,ROI_moving,\n",
    "               fixed_image,moving_image,\n",
    "               threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#     threshold_fixed=0.0001 #0.001 for c3 fix mov \n",
    "#     threshold_moving=0.0005 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "#     cc_r=12 \n",
    "#     match_threshold=0.5  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "#     align_threshold=3.0\n",
    "    \n",
    "    fix_spacing=np.array([0.42,0.23,0.23])\n",
    "    mov_spacing=fix_spacing\n",
    "    # fix_ds_spacing = fix_spacing/zoom\n",
    "    min_radius=6\n",
    "    max_radius=12\n",
    "    cc_radius=cc_r # used for radius pixel of context information.\n",
    "    nspots=30000\n",
    "    num_sigma_max=6\n",
    "    seg_dir1='E:/Maxprobe_analysis/R2_R1_3tm50/copytostephan/'\n",
    "    neighbor_radius1 = 3\n",
    "    zoom=[2,4,4]\n",
    "\n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    fixed_ROI = fixed_image[min(AA[0])*zoom[0]:max(AA[0])*zoom[0],\n",
    "              min(AA[1])*zoom[1]:max(AA[1])*zoom[1],\n",
    "              min(AA[2])*zoom[2]:max(AA[2])*zoom[2]]\n",
    "    print(fixed_ROI.shape)\n",
    "\n",
    "    # enlarge the moving image ROI view\n",
    "    BB=np.where(segmentation2==ROI_moving)\n",
    "    En_pixels = 15 # Enlarged pixels \n",
    "    b1 = min(BB[0])*zoom[0] - En_pixels\n",
    "    b2 = max(BB[0])*zoom[0] + En_pixels\n",
    "    b3 = min(BB[1])*zoom[1] - En_pixels\n",
    "    b4 = max(BB[1])*zoom[1] + En_pixels\n",
    "    b5 = min(BB[2])*zoom[2] - En_pixels\n",
    "    b6 = max(BB[2])*zoom[2] + En_pixels\n",
    "    #Edges evaluation\n",
    "    def ROI_edge(b1,b2,b3,b4,b5,b6):        \n",
    "        if b1 <0:\n",
    "            b1 = 0\n",
    "        if b3 <0:\n",
    "            b3 = 0  \n",
    "        if b5 <0:\n",
    "            b5 = 0 \n",
    "        if b2 >= moving_image.shape[0]:\n",
    "            b2 = moving_image.shape[0] -1\n",
    "        if b4 >= moving_image.shape[1]:\n",
    "            b4 = moving_image.shape[1] -1 \n",
    "        if b6 >= moving_image.shape[2]:\n",
    "            b6 = moving_image.shape[2] -1     \n",
    "        return b1,b2,b3,b4,b5,b6\n",
    "\n",
    "    b1,b2,b3,b4,b5,b6 = ROI_edge(b1,b2,b3,b4,b5,b6)\n",
    "    moving_ROI = moving_image[b1:b2,b3:b4,b5:b6]\n",
    "    \n",
    "    print(moving_ROI.shape)\n",
    "    fix_ds = fixed_ROI\n",
    "    mov_ds = moving_ROI\n",
    "    \n",
    "    # get spots in pixels\n",
    "#     print('Getting key points')\n",
    "    fix_spots = blob_detection(\n",
    "        fix_ds, min_radius, max_radius,\n",
    "        num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "        threshold=threshold_fixed, exclude_border=cc_radius,\n",
    "    )\n",
    "    ns = fix_spots.shape[0]\n",
    "    print(f'FIXED image: found {ns} key points')\n",
    "    \n",
    "    mov_spots = blob_detection(\n",
    "        mov_ds, min_radius, max_radius,\n",
    "        num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "        threshold=threshold_moving, exclude_border=cc_radius,\n",
    "    )\n",
    "    ns = mov_spots.shape[0]\n",
    "    print(f'MOVING image: found {ns} key points')\n",
    "    # sort\n",
    "    sort_idx = np.argsort(fix_spots[:, 3])[::-1]\n",
    "    fix_spots = fix_spots[sort_idx, :3][:nspots]\n",
    "    sort_idx = np.argsort(mov_spots[:, 3])[::-1]\n",
    "    mov_spots = mov_spots[sort_idx, :3][:nspots]\n",
    "    # convert to physical units\n",
    "    fix_spots = fix_spots * fix_spacing\n",
    "    mov_spots = mov_spots * mov_spacing\n",
    "    \n",
    "    # remove spots outside of segmenation_mini\n",
    "    # change spot location back to segmentation mask in pixels\n",
    "    segmentation_mini=imread(seg_dir1+'mask_all_R2.tif')\n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    cc = [min(AA[0]),min(AA[1]),min(AA[2])]\n",
    "    fix_spots_new = get_spot_inside(fix_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     mov_spots_new = get_spot_inside(mov_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    mov_spots_new = mov_spots\n",
    "\n",
    "    # get contexts\n",
    "    fix_spots0 = features.get_spot_context(\n",
    "        fix_ds, fix_spots_new, fix_spacing, cc_r,\n",
    "    )\n",
    "    mov_spots0 = features.get_spot_context(\n",
    "        mov_ds, mov_spots_new, mov_spacing, cc_r,\n",
    "    )\n",
    "    \n",
    "    # get point correspondences may change to mutual information\n",
    "    correlations = features.pairwise_correlation(\n",
    "        fix_spots0, mov_spots0,\n",
    "    )\n",
    "    \n",
    "    fix_spots1, mov_spots1 = features.match_points(\n",
    "        fix_spots0, mov_spots0,\n",
    "        correlations, match_threshold,\n",
    "    )\n",
    "    \n",
    "    print(f'Found {fix_spots1.shape[0]} matched fixed points')\n",
    "\n",
    "    global_affine = ransac_align_points(fix_spots1, mov_spots1, align_threshold,)\n",
    "#     print(global_affine)    \n",
    "    inv_affine = ransac_align_points(mov_spots1, fix_spots1, align_threshold,)\n",
    "    \n",
    "#     print(\"Affine invtransformation matrix:\\n\", inv_affine)\n",
    "    points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "\n",
    "    warp_spots = points.dot(inv_affine.T)\n",
    "#     print(f'Found {warp_spots.shape[0]} warp points')\n",
    "    \n",
    "    mov_affine = transform.apply_global_affine(\n",
    "    fix_ds, mov_ds,\n",
    "    fix_spacing, fix_spacing,\n",
    "    global_affine,)\n",
    "    \n",
    "    print('colocalization of all spots before ransac affine') \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(fix_spots_new,mov_spots_new,neighbor_radius1)  # return in pixel\n",
    "    print(f'Distance: {np.mean(cloud_distance(fix_spots_new,mov_spots_new))}')\n",
    "    \n",
    "    print('colocalization of all inside spots after ransac affine') \n",
    "    spot_fix = fix_spots_new\n",
    "#     spot_mov = get_spot_inside(warp_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    spot_mov = warp_spots\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov,neighbor_radius1)  # return in pixel\n",
    "    print(f'Distance: {np.mean(cloud_distance(spot_fix,spot_mov))}')\n",
    "    \n",
    "    print('registration of all inside spots with ICP')\n",
    "    A = spot_fix[:,:3]\n",
    "    B = spot_mov[:,:3]\n",
    "    print(f'{A.shape[0]} icp fix points')\n",
    "    print(f'{B.shape[0]} icp mov points')\n",
    "    \n",
    "    Transform, distances1 = icp(A, B)\n",
    "    inv_Transform, distances2 = icp(B, A)\n",
    "    print(f'Distance_AB: {np.mean(distances1)}')\n",
    "    print(f'Distance_BA: {np.mean(distances2)}')\n",
    "    np.set_printoptions(precision=3,suppress=True)\n",
    "#     print (Transform)\n",
    "    # functions for applying transforms are in bigstream.transform. apply the ICP affine to the moved image\n",
    "    ICP_affine = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine,\n",
    "        fix_spacing, fix_spacing,\n",
    "        Transform,)\n",
    "    ICP_affine_inv = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine,\n",
    "        fix_spacing, fix_spacing,\n",
    "        inv_Transform,)\n",
    "\n",
    "    #     print (inv_Transform)\n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "    C = p.dot(inv_Transform.T)\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    spot_fix = fix_spots\n",
    "    warp_spots_new = get_spot_inside(C,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     warp_spots_new = C\n",
    "    spot_mov = warp_spots_new\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov,neighbor_radius1)  # return in pixel\n",
    "    distances3 = cloud_distance(spot_fix,spot_mov)\n",
    "    print(f'Distance: {np.mean(distances3)}')\n",
    "    \n",
    "    return np.mean(eucldist(lipo_c0,lipo_c1)),global_affine, mov_affine, fixed_ROI, moving_ROI, inv_affine,inv_Transform,fix_spots_new,mov_spots_new,spot_fix,warp_spots_new,ICP_affine,ICP_affine_inv,cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_affine_aligntrack(segmentation1,segmentation2,ROI_fixed,ROI_moving,\n",
    "               fixed_image,moving_image,\n",
    "               threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "               track_affine,global_affine_0,inv_Transform_0):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#     threshold_fixed=0.0001 #0.001 for c3 fix mov \n",
    "#     threshold_moving=0.0005 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "#     cc_r=12 \n",
    "#     match_threshold=0.5  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "#     align_threshold=3.0\n",
    "    \n",
    "    fix_spacing=np.array([0.42,0.23,0.23])\n",
    "    mov_spacing=fix_spacing\n",
    "    # fix_ds_spacing = fix_spacing/zoom\n",
    "    min_radius=6\n",
    "    max_radius=12\n",
    "    cc_radius=cc_r # used for radius pixel of context information.\n",
    "    nspots=30000\n",
    "    num_sigma_max=6\n",
    "    seg_dir1='E:/Maxprobe_analysis/R2_R1_3tm50/copytostephan/'\n",
    "    neighbor_radius1 = 3\n",
    "    zoom=[2,4,4]\n",
    "    \n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    fixed_ROI = fixed_image[min(AA[0])*zoom[0]:max(AA[0])*zoom[0],\n",
    "              min(AA[1])*zoom[1]:max(AA[1])*zoom[1],\n",
    "              min(AA[2])*zoom[2]:max(AA[2])*zoom[2]]\n",
    "    print(fixed_ROI.shape)\n",
    "\n",
    "   # enlarge the moving image ROI view\n",
    "    BB=np.where(segmentation2==ROI_moving)\n",
    "    En_pixels = 15 # Enlarged pixels \n",
    "    b1 = min(BB[0])*zoom[0] - En_pixels\n",
    "    b2 = max(BB[0])*zoom[0] + En_pixels\n",
    "    b3 = min(BB[1])*zoom[1] - En_pixels\n",
    "    b4 = max(BB[1])*zoom[1] + En_pixels\n",
    "    b5 = min(BB[2])*zoom[2] - En_pixels\n",
    "    b6 = max(BB[2])*zoom[2] + En_pixels\n",
    "    #Edges evaluation\n",
    "    def ROI_edge(b1,b2,b3,b4,b5,b6):        \n",
    "        if b1 <0:\n",
    "            b1 = 0\n",
    "        if b3 <0:\n",
    "            b3 = 0  \n",
    "        if b5 <0:\n",
    "            b5 = 0 \n",
    "        if b2 >= moving_image.shape[0]:\n",
    "            b2 = moving_image.shape[0] -1\n",
    "        if b4 >= moving_image.shape[1]:\n",
    "            b4 = moving_image.shape[1] -1 \n",
    "        if b6 >= moving_image.shape[2]:\n",
    "            b6 = moving_image.shape[2] -1     \n",
    "        return b1,b2,b3,b4,b5,b6\n",
    "\n",
    "    b1,b2,b3,b4,b5,b6 = ROI_edge(b1,b2,b3,b4,b5,b6)\n",
    "    moving_ROI = moving_image[b1:b2,b3:b4,b5:b6]\n",
    "    \n",
    "    print(moving_ROI.shape)\n",
    "    fix_ds = fixed_ROI\n",
    "        \n",
    "    if track_affine > 0:             ###################################  \n",
    "#         mov_ds = moving_ROI        \n",
    "        mov_affine_0 = transform.apply_global_affine(\n",
    "        fix_ds, moving_ROI,\n",
    "        fix_spacing, fix_spacing,\n",
    "        global_affine_0,)\n",
    "        \n",
    "        mov_ds = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine_0,\n",
    "        fix_spacing, fix_spacing,\n",
    "        inv_Transform_0,)       \n",
    "    else:\n",
    "        mov_ds = moving_ROI\n",
    "              \n",
    "    # get spots in pixels\n",
    "#     print('Getting key points')\n",
    "    fix_spots = blob_detection(\n",
    "        fix_ds, min_radius, max_radius,\n",
    "        num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "        threshold=threshold_fixed, exclude_border=cc_radius,\n",
    "    )\n",
    "    ns = fix_spots.shape[0]\n",
    "    print(f'FIXED image: found {ns} key points')\n",
    "\n",
    "    mov_spots = blob_detection(\n",
    "        mov_ds, min_radius, max_radius,\n",
    "        num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "        threshold=threshold_moving, exclude_border=cc_radius,\n",
    "    )\n",
    "    ns = mov_spots.shape[0]\n",
    "    print(f'MOVING image: found {ns} key points')\n",
    "    # sort\n",
    "    sort_idx = np.argsort(fix_spots[:, 3])[::-1]\n",
    "    fix_spots = fix_spots[sort_idx, :3][:nspots]\n",
    "    sort_idx = np.argsort(mov_spots[:, 3])[::-1]\n",
    "    mov_spots = mov_spots[sort_idx, :3][:nspots]\n",
    "    \n",
    "    # convert to physical units\n",
    "    fix_spots = fix_spots * fix_spacing\n",
    "    mov_spots = mov_spots * mov_spacing\n",
    "\n",
    "    # remove spots outside of segmenation_mini\n",
    "    # change spot location back to segmentation mask in pixels\n",
    "    segmentation_mini=imread(seg_dir1+'mask_all_R2.tif')\n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    cc = [min(AA[0]),min(AA[1]),min(AA[2])]\n",
    "    \n",
    "    fix_spots_new = get_spot_inside(fix_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     mov_spots_new = get_spot_inside(mov_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    mov_spots_new = mov_spots\n",
    "    \n",
    "    print('registration of all inside spots with ICP')\n",
    "    A = fix_spots_new[:,:3]\n",
    "    B = mov_spots_new[:,:3]\n",
    "    print(f'{A.shape[0]} icp fix points')\n",
    "    print(f'{B.shape[0]} icp mov points')\n",
    "    Transform, distances1 = icp(A, B)\n",
    "    inv_Transform, distances2 = icp(B, A)\n",
    "    print(f'Distance_AB: {np.mean(distances1)}')\n",
    "    print(f'Distance_BA: {np.mean(distances2)}')\n",
    "    np.set_printoptions(precision=3,suppress=True)\n",
    "    # functions for applying transforms are in bigstream.transform. apply the ICP affine to the moved image\n",
    "    ICP_affine = transform.apply_global_affine(\n",
    "        fix_ds, mov_ds,\n",
    "        fix_spacing, fix_spacing,\n",
    "        Transform,)\n",
    "    ICP_affine_inv = transform.apply_global_affine(\n",
    "        fix_ds, mov_ds,\n",
    "        fix_spacing, fix_spacing,\n",
    "        inv_Transform,)\n",
    "    #     print (inv_Transform)\n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "    C = p.dot(inv_Transform.T)[:,:3]\n",
    "    print(fix_spots_new.shape)\n",
    "    print(C.shape)\n",
    "    \n",
    "#     # Test ICP distance change. Minor increased performance\n",
    "    \n",
    "#         # get contexts\n",
    "#     fix_spots0 = features.get_spot_context(\n",
    "#         fix_ds, fix_spots_new, fix_spacing, cc_r,\n",
    "#     )\n",
    "#     mov_spots0 = features.get_spot_context(\n",
    "#         mov_ds, C, mov_spacing, cc_r,\n",
    "#     )\n",
    "\n",
    "#     # get point correspondences may change to mutual information\n",
    "#     correlations = features.pairwise_correlation(\n",
    "#         fix_spots0, mov_spots0,\n",
    "#     )\n",
    "\n",
    "#     fix_spots1, mov_spots1 = features.match_points(\n",
    "#         fix_spots0, mov_spots0,\n",
    "#         correlations, match_threshold,\n",
    "#     )\n",
    "    fix_spots1, mov_spots1,true_pos_c0,true_pos_c1,dist = colocalization(A,C,neighbor_radius1)\n",
    "\n",
    "    print(f'Found {fix_spots1.shape[0]} matched fixed points')\n",
    "\n",
    "    global_affine = ransac_align_points(fix_spots1, mov_spots1, align_threshold,)\n",
    "#     print(global_affine)    \n",
    "    inv_affine = ransac_align_points(mov_spots1, fix_spots1, align_threshold,)\n",
    "\n",
    "    print(\"Affine invtransformation matrix:\\n\", inv_affine)\n",
    "    points = np.append(C, np.ones((C.shape[0],1)), axis=1)\n",
    "    warp_spots = points.dot(inv_affine.T)\n",
    "\n",
    "    mov_affine = transform.apply_global_affine(\n",
    "    fix_ds, ICP_affine,\n",
    "    fix_spacing, fix_spacing,\n",
    "    global_affine,)\n",
    "\n",
    "    print('colocalization of all spots before ransac affine') \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(fix_spots_new,mov_spots_new,neighbor_radius1)  # return in pixel\n",
    "    print(f'Distance: {np.mean(cloud_distance(fix_spots_new,mov_spots_new))}')\n",
    "\n",
    "    print('colocalization of inside spots after ransac affine') \n",
    "    spot_fix = get_spot_inside(fix_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     spot_mov = get_spot_inside(warp_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    warp_spots_new = get_spot_inside(warp_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    spot_mov = warp_spots_new \n",
    "    \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov,neighbor_radius1)  # return in pixel\n",
    "    print(f'Distance: {np.mean(cloud_distance(lipo_c0,lipo_c1))}')\n",
    "    \n",
    "#     warp_spots_new = get_spot_inside(C,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     spot_mov = warp_spots_new \n",
    "#     lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#     distances3 = cloud_distance(spot_fix,spot_mov)\n",
    "#     print(f'Distance: {np.mean(distances3)}')\n",
    "                             \n",
    "    return np.mean(eucldist(lipo_c0,lipo_c1)),global_affine, mov_affine, fixed_ROI, mov_ds, moving_ROI, inv_affine,Transform,inv_Transform,fix_spots_new,mov_spots_new,spot_fix,warp_spots,warp_spots_new,ICP_affine,ICP_affine_inv,cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_affine_aligntrack1(segmentation1,segmentation2,ROI_fixed,ROI_moving,\n",
    "               fixed_image,moving_image,\n",
    "               threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "               track_affine,global_affine_0,inv_Transform_0):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#     threshold_fixed=0.0001 #0.001 for c3 fix mov \n",
    "#     threshold_moving=0.0005 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "#     cc_r=12 \n",
    "#     match_threshold=0.5  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "#     align_threshold=3.0\n",
    "    \n",
    "    fix_spacing=np.array([0.42,0.23,0.23])\n",
    "    mov_spacing=fix_spacing\n",
    "    # fix_ds_spacing = fix_spacing/zoom\n",
    "    min_radius=6\n",
    "    max_radius=12\n",
    "    cc_radius=cc_r # used for radius pixel of context information.\n",
    "    nspots=30000\n",
    "    num_sigma_max=6\n",
    "    seg_dir1='E:/Maxprobe_analysis/R2_R1_3tm50/copytostephan/'\n",
    "    neighbor_radius1 = 3\n",
    "    zoom=[2,4,4]\n",
    "    \n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    fixed_ROI = fixed_image[min(AA[0])*zoom[0]:max(AA[0])*zoom[0],\n",
    "              min(AA[1])*zoom[1]:max(AA[1])*zoom[1],\n",
    "              min(AA[2])*zoom[2]:max(AA[2])*zoom[2]]\n",
    "    print(fixed_ROI.shape)\n",
    "\n",
    "   # enlarge the moving image ROI view\n",
    "    BB=np.where(segmentation2==ROI_moving)\n",
    "    En_pixels = 15 # Enlarged pixels \n",
    "    b1 = min(BB[0])*zoom[0] - En_pixels\n",
    "    b2 = max(BB[0])*zoom[0] + En_pixels\n",
    "    b3 = min(BB[1])*zoom[1] - En_pixels\n",
    "    b4 = max(BB[1])*zoom[1] + En_pixels\n",
    "    b5 = min(BB[2])*zoom[2] - En_pixels\n",
    "    b6 = max(BB[2])*zoom[2] + En_pixels\n",
    "    #Edges evaluation\n",
    "    def ROI_edge(b1,b2,b3,b4,b5,b6):        \n",
    "        if b1 <0:\n",
    "            b1 = 0\n",
    "        if b3 <0:\n",
    "            b3 = 0  \n",
    "        if b5 <0:\n",
    "            b5 = 0 \n",
    "        if b2 >= moving_image.shape[0]:\n",
    "            b2 = moving_image.shape[0] -1\n",
    "        if b4 >= moving_image.shape[1]:\n",
    "            b4 = moving_image.shape[1] -1 \n",
    "        if b6 >= moving_image.shape[2]:\n",
    "            b6 = moving_image.shape[2] -1     \n",
    "        return b1,b2,b3,b4,b5,b6\n",
    "\n",
    "    b1,b2,b3,b4,b5,b6 = ROI_edge(b1,b2,b3,b4,b5,b6)\n",
    "    moving_ROI = moving_image[b1:b2,b3:b4,b5:b6]\n",
    "    \n",
    "    print(moving_ROI.shape)\n",
    "    fix_ds = fixed_ROI\n",
    "        \n",
    "    if track_affine > 0:             ###################################  \n",
    "#         mov_ds = moving_ROI        \n",
    "        mov_affine_0 = transform.apply_global_affine(\n",
    "        fix_ds, moving_ROI,\n",
    "        fix_spacing, fix_spacing,\n",
    "        global_affine_0,)\n",
    "        \n",
    "        mov_ds = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine_0,\n",
    "        fix_spacing, fix_spacing,\n",
    "        inv_Transform_0,)       \n",
    "    else:\n",
    "        mov_ds = moving_ROI\n",
    "              \n",
    "    # get spots in pixels\n",
    "#     print('Getting key points')\n",
    "    fix_spots = blob_detection(\n",
    "        fix_ds, min_radius, max_radius,\n",
    "        num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "        threshold=threshold_fixed, exclude_border=cc_radius,\n",
    "    )\n",
    "    ns = fix_spots.shape[0]\n",
    "    print(f'FIXED image: found {ns} key points')\n",
    "\n",
    "    mov_spots = features1.blob_detection(\n",
    "        mov_ds, min_radius, max_radius,\n",
    "        num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "        threshold=threshold_moving, exclude_border=cc_radius,\n",
    "    )\n",
    "    ns = mov_spots.shape[0]\n",
    "    print(f'MOVING image: found {ns} key points')\n",
    "    # sort\n",
    "    sort_idx = np.argsort(fix_spots[:, 3])[::-1]\n",
    "    fix_spots = fix_spots[sort_idx, :3][:nspots]\n",
    "    sort_idx = np.argsort(mov_spots[:, 3])[::-1]\n",
    "    mov_spots = mov_spots[sort_idx, :3][:nspots]\n",
    "    \n",
    "    # convert to physical units\n",
    "    fix_spots = fix_spots * fix_spacing\n",
    "    mov_spots = mov_spots * mov_spacing\n",
    "\n",
    "    # remove spots outside of segmenation_mini\n",
    "    # change spot location back to segmentation mask in pixels\n",
    "    segmentation_mini=imread(seg_dir1+'mask_all_R2.tif')\n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    cc = [min(AA[0]),min(AA[1]),min(AA[2])]\n",
    "    fix_spots_new = get_spot_inside(fix_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     mov_spots_new = get_spot_inside(mov_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    mov_spots_new = mov_spots\n",
    "    \n",
    "    # get contexts\n",
    "    fix_spots0 = features.get_spot_context(\n",
    "        fix_ds, fix_spots_new, fix_spacing, cc_r,\n",
    "    )\n",
    "    mov_spots0 = features.get_spot_context(\n",
    "        mov_ds, mov_spots_new, mov_spacing, cc_r,\n",
    "    )\n",
    "\n",
    "    # get point correspondences may change to mutual information\n",
    "    correlations = features.pairwise_correlation(\n",
    "        fix_spots0, mov_spots0,\n",
    "    )\n",
    "\n",
    "    fix_spots1, mov_spots1 = features.match_points(\n",
    "        fix_spots0, mov_spots0,\n",
    "        correlations, match_threshold,\n",
    "    )\n",
    "    print(f'Found {fix_spots1.shape[0]} matched fixed points')\n",
    "\n",
    "    global_affine = ransac_align_points(fix_spots1, mov_spots1, align_threshold,)\n",
    "#     print(global_affine)    \n",
    "    inv_affine = ransac_align_points(mov_spots1, fix_spots1, align_threshold,)\n",
    "\n",
    "    print(\"Affine invtransformation matrix:\\n\", inv_affine)\n",
    "    points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "    warp_spots = points.dot(inv_affine.T)\n",
    "\n",
    "    mov_affine = transform.apply_global_affine(\n",
    "    fix_ds, mov_ds,\n",
    "    fix_spacing, fix_spacing,\n",
    "    global_affine,)\n",
    "\n",
    "    print('colocalization of all spots before ransac affine') \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(fix_spots_new,mov_spots_new,neighbor_radius1)  # return in pixel\n",
    "    print(f'Distance: {np.mean(cloud_distance(fix_spots_new,mov_spots_new))}')\n",
    "\n",
    "    print('colocalization of inside spots after ransac affine') \n",
    "    spot_fix = get_spot_inside(fix_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     spot_mov = get_spot_inside(warp_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     spot_mov = warp_spots\n",
    "    ###################################\n",
    "    spot_mov = mov_spots_new\n",
    "    \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov, neighbor_radius1)  # return in pixel\n",
    "    print(f'Distance: {np.mean(cloud_distance(spot_fix,spot_mov))}')\n",
    "\n",
    "    print('registration of all inside spots with ICP')\n",
    "    A = spot_fix[:,:3]\n",
    "    B = spot_mov[:,:3]\n",
    "    print(f'{A.shape[0]} icp fix points')\n",
    "    print(f'{B.shape[0]} icp mov points')\n",
    "    Transform, distances1 = icp(A, B)\n",
    "    inv_Transform, distances2 = icp(B, A)\n",
    "    print(f'Distance_AB: {np.mean(distances1)}')\n",
    "    print(f'Distance_BA: {np.mean(distances2)}')\n",
    "    np.set_printoptions(precision=3,suppress=True)\n",
    "#     print (Transform)\n",
    "    # functions for applying transforms are in bigstream.transform. apply the ICP affine to the moved image\n",
    "    ICP_affine = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine,\n",
    "        fix_spacing, fix_spacing,\n",
    "        Transform,)\n",
    "    ICP_affine_inv = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine,\n",
    "        fix_spacing, fix_spacing,\n",
    "        inv_Transform,)\n",
    "    #     print (inv_Transform)\n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "    C = p.dot(inv_Transform.T)\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    warp_spots_new = get_spot_inside(C,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    spot_mov = warp_spots_new \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "    distances3 = cloud_distance(spot_fix,spot_mov)\n",
    "    print(f'Distance: {np.mean(distances3)}')\n",
    "                             \n",
    "    return np.mean(distances1),global_affine, mov_affine, fixed_ROI, mov_ds, moving_ROI, inv_affine,Transform,inv_Transform,fix_spots_new,mov_spots_new,spot_fix,warp_spots,warp_spots_new,ICP_affine,ICP_affine_inv,cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_affine_aligntrack0(segmentation1,segmentation2,ROI_fixed,ROI_moving,\n",
    "               fixed_image,moving_image,\n",
    "               threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "               track_affine,global_affine_0,inv_Transform_0):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#     threshold_fixed=0.0001 #0.001 for c3 fix mov \n",
    "#     threshold_moving=0.0005 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "#     cc_r=12 \n",
    "#     match_threshold=0.5  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "#     align_threshold=3.0\n",
    "    \n",
    "    fix_spacing=np.array([0.42,0.23,0.23])\n",
    "    mov_spacing=fix_spacing\n",
    "    # fix_ds_spacing = fix_spacing/zoom\n",
    "    min_radius=6\n",
    "    max_radius=12\n",
    "    cc_radius=cc_r # used for radius pixel of context information.\n",
    "    nspots=30000\n",
    "    num_sigma_max=6\n",
    "    seg_dir1='E:/Maxprobe_analysis/R2_R1_3tm50/copytostephan/'\n",
    "    neighbor_radius1 = 3\n",
    "    zoom=[2,4,4]\n",
    "    \n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    fixed_ROI = fixed_image[min(AA[0])*zoom[0]:max(AA[0])*zoom[0],\n",
    "              min(AA[1])*zoom[1]:max(AA[1])*zoom[1],\n",
    "              min(AA[2])*zoom[2]:max(AA[2])*zoom[2]]\n",
    "    print(fixed_ROI.shape)\n",
    "\n",
    "   # enlarge the moving image ROI view\n",
    "    BB=np.where(segmentation2==ROI_moving)\n",
    "    En_pixels = 15 # Enlarged pixels \n",
    "    b1 = min(BB[0])*zoom[0] - En_pixels\n",
    "    b2 = max(BB[0])*zoom[0] + En_pixels\n",
    "    b3 = min(BB[1])*zoom[1] - En_pixels\n",
    "    b4 = max(BB[1])*zoom[1] + En_pixels\n",
    "    b5 = min(BB[2])*zoom[2] - En_pixels\n",
    "    b6 = max(BB[2])*zoom[2] + En_pixels\n",
    "    #Edges evaluation\n",
    "    def ROI_edge(b1,b2,b3,b4,b5,b6):        \n",
    "        if b1 <0:\n",
    "            b1 = 0\n",
    "        if b3 <0:\n",
    "            b3 = 0  \n",
    "        if b5 <0:\n",
    "            b5 = 0 \n",
    "        if b2 >= moving_image.shape[0]:\n",
    "            b2 = moving_image.shape[0] -1\n",
    "        if b4 >= moving_image.shape[1]:\n",
    "            b4 = moving_image.shape[1] -1 \n",
    "        if b6 >= moving_image.shape[2]:\n",
    "            b6 = moving_image.shape[2] -1     \n",
    "        return b1,b2,b3,b4,b5,b6\n",
    "\n",
    "    b1,b2,b3,b4,b5,b6 = ROI_edge(b1,b2,b3,b4,b5,b6)\n",
    "    moving_ROI = moving_image[b1:b2,b3:b4,b5:b6]\n",
    "    \n",
    "    print(moving_ROI.shape)\n",
    "    fix_ds = fixed_ROI\n",
    "        \n",
    "    if track_affine > 0:             ###################################  \n",
    "#         mov_ds = moving_ROI        \n",
    "        mov_affine_0 = transform.apply_global_affine(\n",
    "        fix_ds, moving_ROI,\n",
    "        fix_spacing, fix_spacing,\n",
    "        global_affine_0,)\n",
    "        \n",
    "        mov_ds = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine_0,\n",
    "        fix_spacing, fix_spacing,\n",
    "        inv_Transform_0,)       \n",
    "    else:\n",
    "        mov_ds = moving_ROI\n",
    "              \n",
    "    # get spots in pixels\n",
    "#     print('Getting key points')\n",
    "    fix_spots = blob_detection(\n",
    "        fix_ds, min_radius, max_radius,\n",
    "        num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "        threshold=threshold_fixed, exclude_border=cc_radius,\n",
    "    )\n",
    "    ns = fix_spots.shape[0]\n",
    "    print(f'FIXED image: found {ns} key points')\n",
    "\n",
    "    mov_spots = features1.blob_detection(\n",
    "        mov_ds, min_radius, max_radius,\n",
    "        num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "        threshold=threshold_moving, exclude_border=cc_radius,\n",
    "    )\n",
    "    ns = mov_spots.shape[0]\n",
    "    print(f'MOVING image: found {ns} key points')\n",
    "    # sort\n",
    "    sort_idx = np.argsort(fix_spots[:, 3])[::-1]\n",
    "    fix_spots = fix_spots[sort_idx, :3][:nspots]\n",
    "    sort_idx = np.argsort(mov_spots[:, 3])[::-1]\n",
    "    mov_spots = mov_spots[sort_idx, :3][:nspots]\n",
    "    \n",
    "    # convert to physical units\n",
    "    fix_spots = fix_spots * fix_spacing\n",
    "    mov_spots = mov_spots * mov_spacing\n",
    "\n",
    "    # remove spots outside of segmenation_mini\n",
    "    # change spot location back to segmentation mask in pixels\n",
    "    segmentation_mini=imread(seg_dir1+'mask_all_R2.tif')\n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    cc = [min(AA[0]),min(AA[1]),min(AA[2])]\n",
    "    fix_spots_new = get_spot_inside(fix_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     mov_spots_new = get_spot_inside(mov_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    mov_spots_new = mov_spots\n",
    "    \n",
    "    # get contexts\n",
    "    fix_spots0 = features.get_spot_context(\n",
    "        fix_ds, fix_spots_new, fix_spacing, cc_r,\n",
    "    )\n",
    "    mov_spots0 = features.get_spot_context(\n",
    "        mov_ds, mov_spots_new, mov_spacing, cc_r,\n",
    "    )\n",
    "\n",
    "    # get point correspondences may change to mutual information\n",
    "    correlations = features.pairwise_correlation(\n",
    "        fix_spots0, mov_spots0,\n",
    "    )\n",
    "\n",
    "    fix_spots1, mov_spots1 = features.match_points(\n",
    "        fix_spots0, mov_spots0,\n",
    "        correlations, match_threshold,\n",
    "    )\n",
    "    print(f'Found {fix_spots1.shape[0]} matched fixed points')\n",
    "\n",
    "    global_affine = ransac_align_points(fix_spots1, mov_spots1, align_threshold,)\n",
    "#     print(global_affine)    \n",
    "    inv_affine = ransac_align_points(mov_spots1, fix_spots1, align_threshold,)\n",
    "\n",
    "    print(\"Affine invtransformation matrix:\\n\", inv_affine)\n",
    "    points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "    warp_spots = points.dot(inv_affine.T)\n",
    "\n",
    "    mov_affine = transform.apply_global_affine(\n",
    "    fix_ds, mov_ds,\n",
    "    fix_spacing, fix_spacing,\n",
    "    global_affine,)\n",
    "\n",
    "    print('colocalization of all spots before ransac affine') \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(fix_spots_new,mov_spots_new,neighbor_radius1)  # return in pixel\n",
    "    print(f'Distance: {np.mean(cloud_distance(fix_spots_new,mov_spots_new))}')\n",
    "\n",
    "    print('colocalization of inside spots after ransac affine') \n",
    "    spot_fix = get_spot_inside(fix_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "#     spot_mov = get_spot_inside(warp_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    spot_mov = warp_spots\n",
    "    \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov, neighbor_radius1)  # return in pixel\n",
    "    print(f'Distance: {np.mean(cloud_distance(spot_fix,spot_mov))}')\n",
    "\n",
    "    print('registration of all inside spots with ICP')\n",
    "    A = spot_fix[:,:3]\n",
    "    B = spot_mov[:,:3]\n",
    "    print(f'{A.shape[0]} icp fix points')\n",
    "    print(f'{B.shape[0]} icp mov points')\n",
    "    Transform, distances1 = icp(A, B)\n",
    "    inv_Transform, distances2 = icp(B, A)\n",
    "    print(f'Distance_AB: {np.mean(distances1)}')\n",
    "    print(f'Distance_BA: {np.mean(distances2)}')\n",
    "    np.set_printoptions(precision=3,suppress=True)\n",
    "#     print (Transform)\n",
    "    # functions for applying transforms are in bigstream.transform. apply the ICP affine to the moved image\n",
    "    ICP_affine = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine,\n",
    "        fix_spacing, fix_spacing,\n",
    "        Transform,)\n",
    "    ICP_affine_inv = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine,\n",
    "        fix_spacing, fix_spacing,\n",
    "        inv_Transform,)\n",
    "    #     print (inv_Transform)\n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "    C = p.dot(inv_Transform.T)\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    warp_spots_new = get_spot_inside(C,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "    spot_mov = warp_spots_new \n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "    distances3 = cloud_distance(spot_fix,spot_mov)\n",
    "    print(f'Distance: {np.mean(distances3)}')\n",
    "                             \n",
    "    return np.mean(distances1),global_affine, mov_affine, fixed_ROI, mov_ds, moving_ROI, inv_affine,Transform,inv_Transform,fix_spots_new,mov_spots_new,spot_fix,warp_spots,warp_spots_new,ICP_affine,ICP_affine_inv,cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "We load the images of 2 channels of two rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # file paths to bigstrem REGISTERED data N5 files(include deform)\n",
    "# create Zarr file object using N5Stores\n",
    "# Analyze the below images ## image is in zyx order\n",
    "fix_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/stitching/export.n5/c0/s0'  # R2_CO\n",
    "fix_zarr = zarr.open(store=zarr.N5Store(fix_path), mode='r')\n",
    "fixed = fix_zarr[...]\n",
    "fix3_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/stitching/export.n5/c3/s0' # R2_C3\n",
    "fix3_zarr = zarr.open(store=zarr.N5Store(fix3_path), mode='r')\n",
    "fixed3 = fix3_zarr[...]\n",
    "print(fixed3.shape)\n",
    "\n",
    "# mov_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R1_3tm50_1920/registration/python/warped_pre10162021/warped/c0/s0'  # R1_CO\n",
    "# mov_zarr = zarr.open(store=zarr.N5Store(mov_path), mode='r')\n",
    "# moving = mov_zarr[...]\n",
    "# mov3_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R1_3tm50_1920/registration/python/warped_pre10162021/warped/c3/s0' # R1_C3\n",
    "# mov3_zarr = zarr.open(store=zarr.N5Store(mov3_path), mode='r')\n",
    "# moving3 = mov3_zarr[...]\n",
    "\n",
    "## file paths to RAW data N5 files\n",
    "mov_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R1_3tm50_1920/stitching/export.n5/c0/s0' # R1_C3\n",
    "mov3_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R1_3tm50_1920/stitching/export.n5/c3/s0' # R2_C3\n",
    "mov_zarr = zarr.open(store=zarr.N5Store(mov_path), mode='r')\n",
    "mov3_zarr = zarr.open(store=zarr.N5Store(mov3_path), mode='r')\n",
    "moving = mov_zarr[...]\n",
    "moving3 = mov3_zarr[...]\n",
    "print(moving3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input:\n",
    "##### enlarged fixed ROIs, fixed image, moving image;\n",
    "##### fixed spot extraction parameters;\n",
    "##### moved spot extraction parameters;\n",
    "\n",
    "### output:\n",
    "#### visualization for example ROIs\n",
    "##### enlarged fixed ROIs_fixed image, moving image, affined image;\n",
    "##### fixed spots, moved spots, affined spots by fishspots\n",
    "\n",
    "#### analyze spot location, remove spots outside of ROI, relocate the xyz coordinate to the orginal images\n",
    "\n",
    "### refine ransac_affine or use other methods, and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piece-wise affine \n",
    "### Select segmented ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # UNREGISTERED\n",
    "zoom=[2,4,4]\n",
    "seg_dir='E:/Maxprobe_analysis/R2_R1_3tm50/copytostephan/'\n",
    "# segmentation1=imread(seg_dir+'mask_GAD1_R2.tif') # \n",
    "# segmentation2=imread(seg_dir+'mask_GAD1_R1.tif') # Before bigstream\n",
    "segmentation2=imread(seg_dir+'mask_all_R1.tif') # Before bigstream\n",
    "\n",
    "# # Registered and enlarged ROI\n",
    "seg_dir1='E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/segmentation/'\n",
    "# segmentation1=imread(seg_dir1+'mask_GAD111.tif')\n",
    "segmentation1=imread(seg_dir+'mask_all_R2.tif')\n",
    "# segmentation_mini=imread(seg_dir1+'mask_GAD11.tif')\n",
    "\n",
    "# apply the global affine to the moving segmented ROI\n",
    "# segmentation2_affine = transform.apply_global_affine()\n",
    "\n",
    "# viewer.add_image(segmentation1,colormap='green',blending='additive') #load image data into napari\n",
    "# viewer.add_image(segmentation2,colormap='red',blending='additive') #load image data into napari\n",
    "# viewer.add_image(segmentation2_affine,colormap='magenta',blending='additive') #load image data into napari\n",
    "# viewer.add_image(segmentation_mini,colormap='magenta',blending='additive') #load image data into napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # all spots show: key spots           \n",
    "# # affine alignment functions are in bigstream.affine\n",
    "\n",
    "# fix_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/stitching/export.n5/c2/s2'  # R2_CO\n",
    "# fix_zarr = zarr.open(store=zarr.N5Store(fix_path), mode='r')\n",
    "# fix_ds = fix_zarr[...]\n",
    "\n",
    "# mov_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R1_3tm50_1920/stitching/export.n5/c2/s2' # R1_C3\n",
    "# mov_zarr = zarr.open(store=zarr.N5Store(mov_path), mode='r')\n",
    "# mov_ds = mov_zarr[...]\n",
    "\n",
    "# zoom=np.array([0.5,0.25,0.25])\n",
    "# fix_spacing=np.array([0.42,0.23,0.23])\n",
    "# fix_ds_spacing = fix_spacing/zoom\n",
    "\n",
    "# from bigstream import affine\n",
    "# # see below for explanation of parameters\n",
    "# global_affine = affine.ransac_affine(\n",
    "#     fix_ds, mov_ds,\n",
    "#     fix_ds_spacing, fix_ds_spacing,\n",
    "#     min_radius=12, max_radius=16, match_threshold=0.50,\n",
    "#     cc_radius=12, \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/stitching/export.n5/c2/s0'  # R2_CO\n",
    "# fix_zarr = zarr.open(store=zarr.N5Store(fix_path), mode='r')\n",
    "# fix_ds = fix_zarr[...]\n",
    "\n",
    "# mov_path = 'E:/Maxprobe_analysis/R2_R1_3tm50/R1_3tm50_1920/stitching/export.n5/c2/s0' # R1_C3\n",
    "# mov_zarr = zarr.open(store=zarr.N5Store(mov_path), mode='r')\n",
    "# mov_ds = mov_zarr[...]\n",
    "\n",
    "# fix_ds_spacing = fix_spacing\n",
    "# global_affine_ds = transform.apply_global_affine(\n",
    "#     fix_ds, mov_ds,\n",
    "#     fix_spacing, fix_spacing,\n",
    "#     global_affine,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize specific ROIs and FISH images\n",
    "# # 603(less spots in c0c3),124(edge),516(edge),660(fixed roi: only a small cut),827(not exsit)\n",
    "\n",
    "# viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "# napari.run()\n",
    "\n",
    "# def ROI_edge(b1,b2,b3,b4,b5,b6):        \n",
    "#     if b1 <0:\n",
    "#         b1 = 0\n",
    "#     if b3 <0:\n",
    "#         b3 = 0  \n",
    "#     if b5 <0:\n",
    "#         b5 = 0\n",
    "#     if b2 >= moving.shape[0]:\n",
    "#         b2 = moving.shape[0] -1\n",
    "#     if b4 >= moving.shape[1]:\n",
    "#         b4 = moving.shape[1] -1 \n",
    "#     if b6 >= moving.shape[2]:\n",
    "#         b6 = moving.shape[2] -1     \n",
    "#     return b1,b2,b3,b4,b5,b6\n",
    "\n",
    "# froi_vis = 70\n",
    "# mroi_vis = df.loc[df['fix'].astype(int) == froi_vis]['mov'].values[0].astype(int) #379\n",
    "\n",
    "# AA=np.where(segmentation1==froi_vis)\n",
    "# fixed_ROI = fixed[min(AA[0])*zoom[0]:max(AA[0])*zoom[0],\n",
    "#           min(AA[1])*zoom[1]:max(AA[1])*zoom[1],\n",
    "#           min(AA[2])*zoom[2]:max(AA[2])*zoom[2]]\n",
    "# print(fixed_ROI.shape)\n",
    "# BB=np.where(segmentation2==mroi_vis)\n",
    "# En_pixels = 15 # Enlarged pixels \n",
    "# b1 = min(BB[0])*zoom[0] - En_pixels\n",
    "# b2 = max(BB[0])*zoom[0] + En_pixels\n",
    "# b3 = min(BB[1])*zoom[1] - En_pixels\n",
    "# b4 = max(BB[1])*zoom[1] + En_pixels\n",
    "# b5 = min(BB[2])*zoom[2] - En_pixels\n",
    "# b6 = max(BB[2])*zoom[2] + En_pixels\n",
    "# #Edges evaluation\n",
    "\n",
    "# b1,b2,b3,b4,b5,b6 = ROI_edge(b1,b2,b3,b4,b5,b6)\n",
    "# moving_ROI = moving[b1:b2,b3:b4,b5:b6]\n",
    "# print(moving_ROI.shape)\n",
    "# viewer.add_image(fixed_ROI,colormap='green',blending='additive') #load image data into napari\n",
    "# viewer.add_image(moving_ROI,colormap='red',blending='additive') #load image data into napari\n",
    "# viewer.layers['fixed_ROI'].contrast_limits=(200, 300)\n",
    "# viewer.layers['moving_ROI'].contrast_limits=(200, 300)\n",
    "\n",
    "\n",
    "# fixed_ROI3 = fixed3[min(AA[0])*zoom[0]:max(AA[0])*zoom[0],\n",
    "#           min(AA[1])*zoom[1]:max(AA[1])*zoom[1],\n",
    "#           min(AA[2])*zoom[2]:max(AA[2])*zoom[2]]\n",
    "\n",
    "\n",
    "# BB=np.where(segmentation2==mroi_vis)\n",
    "# b1 = min(BB[0])*zoom[0] - En_pixels\n",
    "# b2 = max(BB[0])*zoom[0] + En_pixels\n",
    "# b3 = min(BB[1])*zoom[1] - En_pixels\n",
    "# b4 = max(BB[1])*zoom[1] + En_pixels\n",
    "# b5 = min(BB[2])*zoom[2] - En_pixels\n",
    "# b6 = max(BB[2])*zoom[2] + En_pixels\n",
    "# #Edges evaluation\n",
    "\n",
    "# b1,b2,b3,b4,b5,b6 = ROI_edge(b1,b2,b3,b4,b5,b6)\n",
    "# moving_ROI3 = moving3[b1:b2,b3:b4,b5:b6]\n",
    "    \n",
    "# viewer.add_image(fixed_ROI3,colormap='green',blending='additive') #load image data into napari\n",
    "# viewer.add_image(moving_ROI3,colormap='red',blending='additive') #load image data into napari\n",
    "# viewer.layers['fixed_ROI3'].contrast_limits=(200, 600)\n",
    "# viewer.layers['moving_ROI3'].contrast_limits=(200, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from libtiff import TIFF\n",
    "# from scipy import misc\n",
    " \n",
    "# ##tiff文件解析成图像序列\n",
    "# ##tiff_image_name: tiff文件名；\n",
    "# ##out_folder：保存图像序列的文件夹\n",
    "# ##out_type：保存图像的类型，如.jpg、.png、.bmp等\n",
    "# def tiff_to_image_array(tiff_image_name, out_folder, out_type): \n",
    "          \n",
    "#     tif = TIFF.open(tiff_image_name, mode = \"r\")\n",
    "#     idx = 0\n",
    "#     for im in list(tif.iter_images()):\n",
    "# \t\t#\n",
    "#         im_name = out_folder + str(idx) + out_type\n",
    "#         misc.imsave(im_name, im)\n",
    "# #         print im_name, 'successfully saved!!!'\n",
    "#         idx = idx + 1\n",
    "#     return\n",
    " \n",
    "# ##图像序列保存成tiff文件\n",
    "# ##image_dir：图像序列所在文件夹\n",
    "# ##file_name：要保存的tiff文件名\n",
    "# ##image_type:图像序列的类型\n",
    "# ##image_num:要保存的图像数目\n",
    "# def image_array_to_tiff(image_dir, file_name, image_type, image_num):\n",
    " \n",
    "#     out_tiff = TIFF.open(file_name, mode = 'w')\n",
    "#     for i in range(0, image_num):\n",
    "#         image_name = image_dir + str(i) + image_type\n",
    "#         image_array = Image.open(image_name)\n",
    "# #         img = image_array.resize((480, 480), Image.ANTIALIAS)\n",
    "#         out_tiff.write_image(img, compression = None, write_rgb = True)\n",
    "#     out_tiff.close()\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## load all ROIs\n",
    "# roi_dir = seg_dir + 'GAD1_R1_R2.csv'   # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "# roi_list = pd.read_csv(roi_dir,sep=',', index_col=0)\n",
    "# viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "# napari.run()\n",
    "\n",
    "# find all area of that fix ROI \n",
    "segmentation_mini=imread(seg_dir1+'mask_GAD11.tif')\n",
    "roi = np.unique(segmentation_mini[segmentation_mini != 0])\n",
    "roi = roi.astype(int)\n",
    "roi = roi[np.where(roi!=[603])[0]]\n",
    "roi = roi[np.where(roi!=[124])[0]]\n",
    "roi = roi[np.where(roi!=[172])[0]] # few spots in c0 r2\n",
    "roi = roi[np.where(roi!=[516])[0]]\n",
    "roi = roi[np.where(roi!=[660])[0]]\n",
    "roi = roi[np.where(roi!=[734])[0]] # only small part\n",
    "roi = roi[np.where(roi!=[827])[0]]\n",
    "print(roi)\n",
    "\n",
    "roi_dir = seg_dir + 'allroi_matched.csv'   # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "df = pd.read_csv(roi_dir)\n",
    "\n",
    "spot_fix_c3_all = np.zeros((1, 4))\n",
    "warp_spots_c3_all = np.zeros((1, 4))\n",
    "spot_fix_c0_all = np.zeros((1, 4))\n",
    "warp_spots_c0_all = np.zeros((1, 4))\n",
    "fix_spacing=np.array([0.42,0.23,0.23])\n",
    "i=0\n",
    "Dist_sum_1 = np.zeros((len(roi), 4))\n",
    "\n",
    "# all ROI\n",
    "for aa in roi:\n",
    "    \n",
    "    # examplar ROI\n",
    "#     aa = 505\n",
    "    ROI_fixed = aa  #505\n",
    "    print(f'fixed_ROI: #{ROI_fixed}')\n",
    "    ROI_moving = df.loc[df['fix'].astype(int) == aa]['mov'].values[0].astype(int) #379\n",
    "    print(f'moving_ROI: #{ROI_moving}')\n",
    "    # run the ROI_ransac\n",
    "    \n",
    "    # #R2_C3 * R1_C3*; return new R1_C3\n",
    "    threshold_fixed=0.0001 #0.001 for c3 fix mov \n",
    "    threshold_moving=0.0015 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "    cc_r=12 \n",
    "    match_threshold=0.7  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "    align_threshold=1\n",
    "    distances_3,global_affine3, mov_affine3, fixed_ROI3, moving_ROI3, inv_affine3, inv_Transform3,fix_spots_new3,mov_spots_new3,fix_spots3, warp_spots_new3,ICP_affine3,ICP_affine_inv3,cc3 = ROI_affine(\n",
    "        segmentation1,segmentation2,ROI_fixed,ROI_moving,fixed3,moving3,threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold)\n",
    "    \n",
    "    spot_fix = fix_spots3/fix_spacing + [2*cc3[0],4*cc3[1],4*cc3[2]]  # in phsical distance of S2\n",
    "    spot_fix_c3 = np.column_stack((spot_fix,np.ones(len(spot_fix)).dot(aa)))\n",
    "    spot_fix_c3_all = np.row_stack((spot_fix_c3_all,spot_fix_c3))\n",
    "    warp_spots_3 = warp_spots_new3[:,:3]/fix_spacing + [2*cc3[0],4*cc3[1],4*cc3[2]]  # in pixels of S2\n",
    "    warp_spots_new_c3 = np.column_stack((warp_spots_3,np.ones(len(warp_spots_new3)).dot(aa)))\n",
    "    warp_spots_c3_all = np.row_stack((warp_spots_c3_all,warp_spots_new_c3))\n",
    "    \n",
    "    \n",
    "    # #R2_C0 * R1_C0*; return new R1_C0\n",
    "    threshold_fixed=0.00005 #0.001 for c3 fix mov \n",
    "    threshold_moving=0.0005 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "    cc_r=12 \n",
    "    match_threshold=0.5  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "    align_threshold=3  # spots are sparsed\n",
    "    \n",
    "    ############################## apply c3 affine to c0 if track_affine == 1\n",
    "    track_affine = 1\n",
    "    \n",
    "    distances_0,global_affine, mov_affine, fixed_ROI, mov_ds, moving_ROI, inv_affine,Transform,inv_Transform,fix_spots_new0,mov_spots_new0,fix_spots, warp_spots,warp_spots_new, ICP_affine,ICP_affine_inv,cc = ROI_affine_aligntrack(\n",
    "            segmentation1,segmentation2,ROI_fixed,ROI_moving,fixed,moving,threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "            track_affine,global_affine3,inv_Transform3)\n",
    "    \n",
    "    # save every spots, global affine, warp affine.\n",
    "    spot_fix = fix_spots/fix_spacing + [2*cc[0],4*cc[1],4*cc[2]]  # in phsical distance of S2\n",
    "    spot_fix_c0 = np.column_stack((spot_fix,np.ones(len(spot_fix)).dot(aa)))\n",
    "    spot_fix_c0_all = np.row_stack((spot_fix_c0_all,spot_fix_c0))\n",
    "    warp_spots_0 = warp_spots_new[:,:3]/fix_spacing + [2*cc[0],4*cc[1],4*cc[2]]  # in pixels of S2\n",
    "    warp_spots_new_c0 = np.column_stack((warp_spots_0,np.ones(len(warp_spots_new)).dot(aa)))\n",
    "    warp_spots_c0_all = np.row_stack((warp_spots_c0_all,warp_spots_new_c0))\n",
    "    # remember to remove the first 000 coordinates\n",
    "    Dist_sum_1[i,:] = [ROI_fixed,distances_3,ROI_moving,distances_0]\n",
    "        \n",
    "#     roi_dir = 'ROI_affine/' + str(aa) + '/fix_c0.tif'\n",
    "#     im_name = seg_dir + roi_dir\n",
    "#     imsave(im_name, fixed_ROI)\n",
    "    \n",
    "#     roi_dir = 'ROI_affine/' + str(aa) + '/mov_c0.tif'\n",
    "#     im_name = seg_dir + roi_dir\n",
    "#     imsave(im_name, ICP_affine)\n",
    "\n",
    "    a_rgb = np.zeros(fixed_ROI3.shape + (4,))\n",
    "    a_rgb[..., 0] = fixed_ROI.astype(np.uint16)\n",
    "    a_rgb[..., 1] = ICP_affine.astype(np.uint16)\n",
    "    a_rgb[..., 2] = fixed_ROI3.astype(np.uint16)\n",
    "    a_rgb[..., 3] = ICP_affine3.astype(np.uint16)\n",
    "    roi_dir = 'ROI_affine/' + str(aa) + '_rgb.tif'\n",
    "    im_name = seg_dir + roi_dir\n",
    "    imsave(im_name, a_rgb)\n",
    "    \n",
    "    i = i + 1 \n",
    "    print(f'Remaining ROI: {len(roi)- i}')\n",
    "#     viewer.add_image(fixed_ROI,colormap='green',blending='additive') #load image data into napari\n",
    "#     viewer.layers['fixed_ROI'].contrast_limits=(200, 600)\n",
    "#     viewer.add_image(ICP_affine,colormap='magenta',blending='additive') #load image data into napari\n",
    "#     viewer.layers['ICP_affine'].contrast_limits=(200, 600)\n",
    "#     viewer.add_image(fixed_ROI3,colormap='green',blending='additive') #load image data into napari\n",
    "#     viewer.layers['fixed_ROI3'].contrast_limits=(200, 3400)\n",
    "#     viewer.add_image(ICP_affine3,colormap='magenta',blending='additive') #load image data into napari\n",
    "#     viewer.layers['ICP_affine3'].contrast_limits=(200, 3400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## load all ROIs\n",
    "# roi_dir = seg_dir + 'GAD1_R1_R2.csv'   # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "# roi_list = pd.read_csv(roi_dir,sep=',', index_col=0)\n",
    "# viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "# napari.run()\n",
    "\n",
    "# find all area of that fix ROI \n",
    "segmentation_mini=imread(seg_dir1+'mask_GAD11.tif')\n",
    "roi = np.unique(segmentation_mini[segmentation_mini != 0])\n",
    "roi = roi.astype(int)\n",
    "roi = roi[np.where(roi!=[603])[0]]\n",
    "roi = roi[np.where(roi!=[124])[0]]\n",
    "roi = roi[np.where(roi!=[172])[0]] # few spots in c0 r2\n",
    "roi = roi[np.where(roi!=[516])[0]]\n",
    "roi = roi[np.where(roi!=[660])[0]]\n",
    "roi = roi[np.where(roi!=[734])[0]] # only small part\n",
    "roi = roi[np.where(roi!=[827])[0]]\n",
    "print(roi)\n",
    "\n",
    "roi_dir = seg_dir + 'allroi_matched.csv'   # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "df = pd.read_csv(roi_dir)\n",
    "\n",
    "spot_fix_c3_all = np.zeros((1, 4))\n",
    "warp_spots_c3_all = np.zeros((1, 4))\n",
    "spot_fix_c0_all = np.zeros((1, 4))\n",
    "warp_spots_c0_all = np.zeros((1, 4))\n",
    "fix_spacing=np.array([0.42,0.23,0.23])\n",
    "i=0\n",
    "Dist_sum_1 = np.zeros((len(roi), 4))\n",
    "\n",
    "# all ROI\n",
    "for aa in roi:\n",
    "    \n",
    "    # examplar ROI\n",
    "#     aa = 85\n",
    "    ROI_fixed = aa  #505\n",
    "    print(f'fixed_ROI: #{ROI_fixed}')\n",
    "    ROI_moving = df.loc[df['fix'].astype(int) == aa]['mov'].values[0].astype(int) #379\n",
    "    print(f'moving_ROI: #{ROI_moving}')\n",
    "    # run the ROI_ransac\n",
    "    \n",
    "    # #R2_C3 * R1_C3*; return new R1_C3\n",
    "    threshold_fixed=0.0001 #0.001 for c3 fix mov \n",
    "    threshold_moving=0.0015 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "    cc_r=12 \n",
    "    match_threshold=0.7  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "    align_threshold=1\n",
    "    distances_3,global_affine3, mov_affine3, fixed_ROI3, moving_ROI3, inv_affine3, inv_Transform3,fix_spots_new3,mov_spots_new3,fix_spots3, warp_spots_new3,ICP_affine3,ICP_affine_inv3,cc3 = ROI_affine(\n",
    "        segmentation1,segmentation2,ROI_fixed,ROI_moving,fixed3,moving3,threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold)\n",
    "    \n",
    "    spot_fix = fix_spots3/fix_spacing + [2*cc3[0],4*cc3[1],4*cc3[2]]  # in phsical distance of S2\n",
    "    spot_fix_c3 = np.column_stack((spot_fix,np.ones(len(spot_fix)).dot(aa)))\n",
    "    spot_fix_c3_all = np.row_stack((spot_fix_c3_all,spot_fix_c3))\n",
    "    warp_spots_3 = warp_spots_new3[:,:3]/fix_spacing + [2*cc3[0],4*cc3[1],4*cc3[2]]  # in pixels of S2\n",
    "    warp_spots_new_c3 = np.column_stack((warp_spots_3,np.ones(len(warp_spots_new3)).dot(aa)))\n",
    "    warp_spots_c3_all = np.row_stack((warp_spots_c3_all,warp_spots_new_c3))\n",
    "    \n",
    "    # #R2_C0 * R1_C0*; return new R1_C0\n",
    "    threshold_fixed=0.00005 #0.001 for c3 fix mov \n",
    "    threshold_moving=0.0005 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "    cc_r=12 \n",
    "    match_threshold=0.5  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "    align_threshold=3  # spots are sparsed\n",
    "    \n",
    "    ############################## apply c3 affine to c0 if track_affine == 1\n",
    "    track_affine = 1\n",
    "    \n",
    "    distances_0,global_affine, mov_affine, fixed_ROI, mov_ds, moving_ROI, inv_affine,Transform,inv_Transform,fix_spots_new0,mov_spots_new0,fix_spots, warp_spots,warp_spots_new, ICP_affine,ICP_affine_inv,cc = ROI_affine_aligntrack(\n",
    "            segmentation1,segmentation2,ROI_fixed,ROI_moving,fixed,moving,threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "            track_affine,global_affine3,inv_Transform3)\n",
    "    \n",
    "    # save every spots, global affine, warp affine.\n",
    "    spot_fix = fix_spots/fix_spacing + [2*cc[0],4*cc[1],4*cc[2]]  # in phsical distance of S2\n",
    "    spot_fix_c0 = np.column_stack((spot_fix,np.ones(len(spot_fix)).dot(aa)))\n",
    "    spot_fix_c0_all = np.row_stack((spot_fix_c0_all,spot_fix_c0))\n",
    "    warp_spots_0 = warp_spots_new[:,:3]/fix_spacing + [2*cc[0],4*cc[1],4*cc[2]]  # in pixels of S2\n",
    "    warp_spots_new_c0 = np.column_stack((warp_spots_0,np.ones(len(warp_spots_new)).dot(aa)))\n",
    "    warp_spots_c0_all = np.row_stack((warp_spots_c0_all,warp_spots_new_c0))\n",
    "    # remember to remove the first 000 coordinates\n",
    "    \n",
    "    Dist_sum_1[i,:] = [ROI_fixed,distances_3,ROI_moving,distances_0]\n",
    "    i = i + 1 \n",
    "    print(f'Remaining ROI: {len(roi)- i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Dist_sum_1[:-2,3]))\n",
    "print(np.mean(Dist_sum_1[:-2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### napari viewer for single ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ROI_napari(mov_affine3, fixed_ROI3, moving_ROI3, fix_spots3, warp_spots_new3,ICP_affine3,fix_spacing)\n",
    "# ROI_napari(mov_affine, fixed_ROI, moving_ROI, fix_spots, warp_spots_new,ICP_affine,fix_spacing)\n",
    "viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "napari.run()\n",
    "viewer.add_image(fixed_ROI,colormap='green',blending='additive') #load image data into napari\n",
    "viewer.add_image(moving_ROI,colormap='red',blending='additive') #load image data into napari\n",
    "viewer.layers['fixed_ROI'].contrast_limits=(200, 600)\n",
    "viewer.layers['moving_ROI'].contrast_limits=(200, 600)\n",
    "viewer.add_image(mov_ds,colormap='yellow',blending='additive') #load image data into napari\n",
    "viewer.layers['mov_ds'].contrast_limits=(200, 600)\n",
    "viewer.add_image(mov_affine,colormap='yellow',blending='additive') #load image data into napari\n",
    "viewer.layers['mov_affine'].contrast_limits=(200, 600)\n",
    "viewer.add_image(ICP_affine,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['ICP_affine'].contrast_limits=(200, 600)\n",
    "viewer.add_image(ICP_affine_inv,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['ICP_affine_inv'].contrast_limits=(200, 600)\n",
    "s=fix_spots[:,:3]/fix_spacing#convert spot physical coordinates to pixel coordinates\n",
    "viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c0_fixed_match', size=1,\n",
    "                  face_color='green',edge_color='green',blending='opaque') \n",
    "C = warp_spots_new\n",
    "viewer.add_points(np.transpose(np.array([C[:,0]/fix_spacing[0],C[:,1]/fix_spacing[1],C[:,2]/fix_spacing[2]])),name ='warp_spots_new', size=1,\n",
    "                  face_color='yellow',edge_color='yellow',blending='opaque') \n",
    "C = warp_spots\n",
    "viewer.add_points(np.transpose(np.array([C[:,0]/fix_spacing[0],C[:,1]/fix_spacing[1],C[:,2]/fix_spacing[2]])),name ='C', size=1,\n",
    "                  face_color='yellow',edge_color='yellow',blending='opaque') \n",
    "\n",
    "viewer.add_image(fixed_ROI3,colormap='green',blending='additive') #load image data into napari\n",
    "viewer.add_image(moving_ROI3,colormap='red',blending='additive') #load image data into napari\n",
    "viewer.layers['fixed_ROI3'].contrast_limits=(200, 3400)\n",
    "viewer.layers['moving_ROI3'].contrast_limits=(200, 3400)\n",
    "# viewer.add_image(mov_affine3,colormap='yellow',blending='additive') #load image data into napari\n",
    "# viewer.layers['mov_affine3'].contrast_limits=(200, 3400)\n",
    "viewer.add_image(ICP_affine3,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['ICP_affine3'].contrast_limits=(200, 3400)\n",
    "# viewer.add_image(ICP_affine_inv3,colormap='magenta',blending='additive') #load image data into napari\n",
    "# viewer.layers['ICP_affine_inv3'].contrast_limits=(200, 3400)\n",
    "# s=fix_spots3[:,:3]/fix_spacing#convert spot physical coordinates to pixel coordinates\n",
    "# viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c3_fixed_match', size=1,\n",
    "#                   face_color='green',edge_color='green',blending='opaque') \n",
    "# C3 = warp_spots_new3\n",
    "# viewer.add_points(np.transpose(np.array([C3[:,0]/fix_spacing[0],C3[:,1]/fix_spacing[1],C3[:,2]/fix_spacing[2]])),name ='C3', size=1,\n",
    "#                   face_color='yellow',edge_color='yellow',blending='opaque') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = fix_spots[:,:3]\n",
    "print(A[0]) \n",
    "B = warp_spots[:,:3]\n",
    "print(B[0]) \n",
    "\n",
    "Transform, distances1 = icp(A, B)\n",
    "inv_Transform, distances2 = icp(B, A)\n",
    "    \n",
    "p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "print(p.dot(inv_Transform.T)[:,:3][0])\n",
    "print(p.dot(Transform.T)[:,:3][0]) \n",
    "\n",
    "print(np.mean(cloud_distance(p.dot(inv_Transform.T)[:,:3],B)))\n",
    "print(np.mean(cloud_distance(p.dot(Transform.T)[:,:3],B)))\n",
    "\n",
    "\n",
    "p = np.append(A, np.ones((A.shape[0],1)), axis=1)\n",
    "print(p.dot(inv_Transform.T)[:,:3][0])\n",
    "print(p.dot(Transform.T)[:,:3][0]) \n",
    "\n",
    "print(np.mean(cloud_distance(p.dot(inv_Transform.T)[:,:3],A)))\n",
    "print(np.mean(cloud_distance(p.dot(Transform.T)[:,:3],A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_affine_0 = transform.apply_global_affine(\n",
    "fixed_ROI, moving_ROI,\n",
    "fix_spacing, fix_spacing,\n",
    "global_affine3,)\n",
    "\n",
    "mov_ds = transform.apply_global_affine(\n",
    "fixed_ROI, mov_affine_0,\n",
    "fix_spacing, fix_spacing,\n",
    "inv_Transform3,) \n",
    "\n",
    "viewer.add_image(mov_affine_0,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['mov_affine_0'].contrast_limits=(200, 400)\n",
    "\n",
    "viewer.add_image(mov_ds,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['mov_ds'].contrast_limits=(200, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Napari view all spots inside ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "napari.run()\n",
    "# xyz 1882 2500 2500 \n",
    "zoom=[2,4,4]\n",
    "s=spot_fix_c0_all[:,:3]#convert spot physical coordinates to pixel coordinates\n",
    "#load spots into napari, pixel positions in xyz order\n",
    "viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c0_fixed', size=1,\n",
    "                  face_color='yellow',edge_color='yellow',blending='opaque') \n",
    "s=warp_spots_c0_all[:,:3]#convert spot physical coordinates to pixel coordinates\n",
    "#load spots into napari, pixel positions in xyz order\n",
    "viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c0_warp', size=1,\n",
    "                  face_color='green',edge_color='green',blending='opaque') \n",
    "\n",
    "s=spot_fix_c3_all[:,:3]#convert spot physical coordinates to pixel coordinates\n",
    "#load spots into napari, pixel positions in xyz order\n",
    "viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c3_fixed', size=1,\n",
    "                  face_color='yellow',edge_color='yellow',blending='opaque') \n",
    "s=warp_spots_c3_all[:,:3]#convert spot physical coordinates to pixel coordinates\n",
    "#load spots into napari, pixel positions in xyz order\n",
    "viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c3_warp', size=1,\n",
    "                  face_color='green',edge_color='green',blending='opaque') \n",
    "\n",
    "# plot images\n",
    "planes = 0\n",
    "a=50\n",
    "fix_ds = fixed3[planes:planes+a ,:,:]\n",
    "mov_ds = moving3[planes:planes+a ,:,:]\n",
    "fix_spacing=np.array([0.42,0.23,0.23])\n",
    "zoom_image=np.array([1,1,1])\n",
    "fix_ds_spacing = fix_spacing/zoom_image\n",
    "viewer.add_image(fix_ds,colormap='green',blending='additive') \n",
    "viewer.layers['fix_ds'].contrast_limits=(200, 1000)\n",
    "viewer.add_image(mov_ds,colormap='red',blending='additive') \n",
    "viewer.layers['mov_ds'].contrast_limits=(200, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances, indices = nearest_neighbor(warp_spots_new[:,0:3],fix_spots[:,0:3])\n",
    "# print(distances)\n",
    "# print(indices) \n",
    "# print(warp_spots_new[:,0:3].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import open3d as o3\n",
    "from probreg import cpd\n",
    "import transforms3d as t3d\n",
    "\n",
    "def estimate_normals(pcd, params):\n",
    "    pcd.estimate_normals(search_param=params)\n",
    "    pcd.orient_normals_to_align_with_direction()# load source and target point cloud\n",
    "\n",
    "source = o3.io.read_point_cloud('D:/0_software/github/probreg/examples/bunny.pcd')\n",
    "source.remove_non_finite_points()\n",
    "target = copy.deepcopy(source)\n",
    "\n",
    "# read points of # point cloud\n",
    "# xyz = np.asarray(result.points)\n",
    "\n",
    "A = fix_spots_new0\n",
    "B = mov_spots_new0\n",
    "\n",
    "# Pass xyz to Open3D.o3d.geometry.PointCloud and visualize\n",
    "# pcd = o3.geometry.PointCloud()\n",
    "target.points = o3.utility.Vector3dVector(A)\n",
    "source.points = o3.utility.Vector3dVector(B)\n",
    "# o3.io.write_point_cloud(\"../../test_data/sync.ply\", pcd)\n",
    "# o3.visualization.draw_geometries(pcd)\n",
    "\n",
    "# register\n",
    "tf_param, _, _ = cpd.registration_cpd(source, target)\n",
    "result = copy.deepcopy(source)\n",
    "result.points = tf_param.transform(result.points)\n",
    "\n",
    "# draw result\n",
    "source.paint_uniform_color([1, 0, 0])\n",
    "target.paint_uniform_color([0, 1, 0])\n",
    "result.paint_uniform_color([0, 0.5, 1])\n",
    "# o3.visualization.draw_geometries([result,source])\n",
    "\n",
    "s=np.asarray(source.points)[:,:3]/fix_spacing#convert spot physical coordinates to pixel coordinates\n",
    "viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c0_src', size=1,\n",
    "                  face_color='green',edge_color='green',blending='opaque')\n",
    "s=np.asarray(target.points)[:,:3]/fix_spacing#convert spot physical coordinates to pixel coordinates\n",
    "viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c0_tar', size=1,\n",
    "                  face_color='yelow',edge_color='yellow',blending='opaque')\n",
    "s=np.asarray(result.points)[:,:3]/fix_spacing#convert spot physical coordinates to pixel coordinates\n",
    "viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c0_cpd', size=1,\n",
    "                  face_color='magenta',edge_color='magenta',blending='opaque')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.paint_uniform_color([1, 0, 0])\n",
    "target.paint_uniform_color([0, 1, 0])\n",
    "result.paint_uniform_color([0, 0.5, 1])\n",
    "threshold = 0.05 # how to set initially\n",
    "icp_iteration = 100\n",
    "for i in range(icp_iteration):\n",
    "    reg_p2p = o3.pipelines.registration.registration_icp(result, target, threshold,\n",
    "                np.identity(4), o3.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "                o3.pipelines.registration.ICPConvergenceCriteria(max_iteration=1))\n",
    "    result.transform(reg_p2p.transformation)\n",
    "#     vis.update_geometry(source)\n",
    "#     vis.update_geometry(target)\n",
    "#     vis.update_geometry(result)\n",
    "#     vis.poll_events()\n",
    "# vis.run()\n",
    "o3.visualization.draw_geometries([result,source,target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigstitcher\n",
    "# R_dir ='E:/Maxprobe_analysis/R2_R1_3tm50/Bigstitcher'\n",
    "# imsave(R_dir + '/ID#5/fixed_ROI3.tif', fixed_ROI3)\n",
    "# imsave(R_dir + '/ID#5/moving_ROI3.tif', moving_ROI3)\n",
    "# imsave(R_dir + '/ID#5/fixed_ROI.tif', fixed_ROI)\n",
    "# imsave(R_dir + '/ID#5/moving_ROI.tif', moving_ROI)\n",
    "\n",
    "# global_affine_bs=np.eye(4)\n",
    "# global_affine_bs[0]=[1.0003, 0.0194, -0.059, 1.7654]\n",
    "# global_affine_bs[1]=[-0.031, 1.0568, -0.0156, -10.1989]\n",
    "# global_affine_bs[2]=[-0.0035, -0.0051, 0.9936, 0.5553]\n",
    "# # Scaling: 1.0008, 1.057, 0.9955\n",
    "# bs_affine = transform.apply_global_affine(\n",
    "# moving_ROI3,fixed_ROI3,\n",
    "# fix_spacing, fix_spacing,\n",
    "# global_affine_bs,)\n",
    "# viewer.add_image(bs_affine,colormap='magenta',blending='additive') #load image data into napari\n",
    "# viewer.layers['bs_affine'].contrast_limits=(200, 3400)\n",
    "\n",
    "# # fix_spots_new3\n",
    "# B = fix_spots_new3\n",
    "# p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "# C = p.dot(global_affine_bs.T)\n",
    "# s=C[:,:3]/fix_spacing#convert spot physical coordinates to pixel coordinates\n",
    "# viewer.add_points(np.transpose(np.array([s[:,0],s[:,1],s[:,2]])),name ='c3_fixed_BS_match', size=1,\n",
    "#                   face_color='magenta',edge_color='magenta',blending='opaque') \n",
    "\n",
    "distances = distances_3\n",
    "fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "plt.violinplot(distances)\n",
    "sns.despine() \n",
    "plt.xticks([])\n",
    "plt.xlabel('Spots:'+ str(distances.shape[0]))\n",
    "plt.ylabel('Distance/um')\n",
    "ave=np.average(distances)\n",
    "plt.title(str(float('%.2f' % ave)))\n",
    "# plt.axis('off')\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "viewer.add_image(ICP_affine3,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['ICP_affine3'].contrast_limits=(200, 3400)\n",
    "\n",
    "distances = distances_0\n",
    "fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "plt.violinplot(distances)\n",
    "sns.despine() \n",
    "plt.xticks([])\n",
    "plt.xlabel('Spots:'+ str(distances.shape[0]))\n",
    "plt.ylabel('Distance/um')\n",
    "ave=np.average(distances)\n",
    "plt.title(str(float('%.2f' % ave)))\n",
    "# plt.axis('off')\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "viewer.add_image(ICP_affine,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['ICP_affine'].contrast_limits=(200, 3400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colocalization across rounds: R2/R1 C3; C0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_radius1 = 6\n",
    "print('colocalization of R2/R1 C3 spots')\n",
    "lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix_c3_all[:,:3],warp_spots_c3_all[:,:3],neighbor_radius1)  # return in pixel\n",
    "print(np.mean(eucldist(lipo_c0,lipo_c1)))\n",
    "\n",
    "# print('colocalization of R2/R1 C0 spots')\n",
    "# lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix_c0_all[:,:3],warp_spots_c0_all[:,:3],neighbor_radius1)  # return in pixel\n",
    "# print(np.mean(eucldist(lipo_c0,lipo_c1)))\n",
    "\n",
    "fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "plt.violinplot(eucldist(lipo_c0,lipo_c1))\n",
    "sns.despine() \n",
    "plt.xticks([])\n",
    "plt.ylim([0,neighbor_radius1*2])\n",
    "plt.xlabel('Spots:'+ str(eucldist(lipo_c0,lipo_c1).shape[0]))\n",
    "plt.ylabel('Distance/pixel')\n",
    "ave=np.average(eucldist(lipo_c0,lipo_c1))\n",
    "plt.title(str(float('%.2f' % ave)))\n",
    "# plt.axis('off')\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colocalization SAME rounds: R2 C3/C0;Non-registered; Registered R1 C3/C0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('colocalization of R2 C3/C0 spots')\n",
    "lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov,neighbor_radius1)  # return in pixel\n",
    "print(eucldist(lipo_c0,lipo_c1))\n",
    "\n",
    "print('colocalization of Non-registered R1 spots')\n",
    "lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov,neighbor_radius1)  # return in pixel\n",
    "print(eucldist(lipo_c0,lipo_c1))\n",
    "\n",
    "print('colocalization of registered R1 spots') \n",
    "lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov,neighbor_radius1)  # return in pixel\n",
    "print(eucldist(lipo_c0,lipo_c1))\n",
    "\n",
    "fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "plt.violinplot(eucldist_vectorized(lipo_c0,lipo_c1))\n",
    "sns.despine() \n",
    "plt.xticks([])\n",
    "plt.ylim([0,neighbor_radius1*2])\n",
    "plt.xlabel('Spots:'+ str(eucldist_vectorized(lipo_c0,lipo_c1).shape[0]))\n",
    "plt.ylabel('Distance/pixel')\n",
    "ave=np.average(eucldist_vectorized(lipo_c0,lipo_c1))\n",
    "plt.title(str(float('%.2f' % ave)))\n",
    "# plt.axis('off')\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For handling multiple channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planes = 0\n",
    "# a=50\n",
    "# fix_ds = fixed3[planes:planes+a ,:,:]\n",
    "# # mov_ds = moving3[planes:planes+a ,:,:]\n",
    "# fix_spacing=np.array([0.42,0.23,0.23])\n",
    "# # zoom=np.array([0.5,0.25,0.25])\n",
    "# zoom_image=np.array([1,1,1])\n",
    "# fix_ds_spacing = fix_spacing/zoom_image\n",
    "\n",
    "# # plot images\n",
    "# viewer.add_image(fix_ds,colormap='green',blending='additive') \n",
    "# viewer.layers['fix_ds'].contrast_limits=(200, 1000)\n",
    "# # viewer.add_image(mov_ds,colormap='red',blending='additive') \n",
    "# # viewer.layers['mov_ds'].contrast_limits=(200, 1000)\n",
    "\n",
    "# # global_affine_all = affine.ransac_affine(\n",
    "# #     fix_ds, mov_ds,\n",
    "# #     fix_ds_spacing, fix_ds_spacing,\n",
    "# #     min_radius=6, max_radius=12, match_threshold=0.40,\n",
    "# #     cc_radius=12, \n",
    "# # )\n",
    "\n",
    "# # # or from the bigstream results\n",
    "# # print(global_affine_all)\n",
    "# global_affine_all=np.eye(4)\n",
    "# global_affine_all[0]=[ 1.01452988, -0.01885208,  -0.03336844,  18.66071098]\n",
    "# global_affine_all[1]=[0.09519188,   1.00508661,  -0.09667662, -17.6666447 ]\n",
    "# global_affine_all[2]=[-0.07341534,  0.06896605,   0.97213685,   9.59959212]\n",
    "\n",
    "# # apply the global affine to the moving image\n",
    "# mov_affine_all = transform.apply_global_affine(\n",
    "#     fix_ds, mov_ds,\n",
    "#     fix_ds_spacing, fix_ds_spacing,\n",
    "#     global_affine_all,\n",
    "# )\n",
    "\n",
    "# viewer.add_image(mov_affine_all,colormap='magenta',blending='additive') \n",
    "# viewer.layers['mov_affine_all'].contrast_limits=(200, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI_Ransac from Bigstream\n",
    "### Spots can be choosed from bigstream extracted spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Airlocolize spots data\n",
    "fix_spacing=np.array([0.42,0.23,0.23])\n",
    "mov_spacing=fix_spacing\n",
    "# fix_ds_spacing = fix_spacing/zoom\n",
    "min_radius=6\n",
    "max_radius=12\n",
    "cc_r=12\n",
    "cc_radius=cc_r # used for radius pixel of context information. \n",
    "match_threshold=0.5  #0.7 for c3, 0.4 for c0c3, 0.5 for c0\n",
    "nspots=30000\n",
    "num_sigma_max=6\n",
    "align_threshold=3.0\n",
    "threshold_fixed=0.0001 #0.001 for c3 fix mov \n",
    "threshold_moving=0.0005 #0.0001 for c0 fix; 0.0005 for c0 moving;\n",
    "\n",
    "AA=np.where(segmentation1==ROI_fixed)\n",
    "fixed_ROI = fixed[min(AA[0])*zoom[0]:max(AA[0])*zoom[0],\n",
    "          min(AA[1])*zoom[1]:max(AA[1])*zoom[1],\n",
    "          min(AA[2])*zoom[2]:max(AA[2])*zoom[2]]\n",
    "print(fixed_ROI.shape)\n",
    "\n",
    "BB=np.where(segmentation1==ROI_moving)\n",
    "moving_ROI = moving[min(BB[0])*zoom[0]:max(BB[0])*zoom[0],\n",
    "          min(BB[1])*zoom[1]:max(BB[1])*zoom[1],\n",
    "          min(BB[2])*zoom[2]:max(BB[2])*zoom[2]]\n",
    "print(moving_ROI.shape)\n",
    "fix_ds = fixed_ROI\n",
    "mov_ds = moving_ROI\n",
    "# get spots\n",
    "print('Getting key points')\n",
    "\n",
    "# use import spots or not. If yes, the spot should align with images checked with Napari\n",
    "hAir = 0\n",
    "# Adapt ROI from images or from hAirlocalize\n",
    "if hAir < 1:\n",
    "    print(f'hAirlocalize points')\n",
    "    # read spot data into memory as numpy arrays  Airlocolize spots data in xyz order: physical distance\n",
    "    spotdir = 'E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/spots/R2_c3_ROI.txt'\n",
    "    spot_fix=np.loadtxt(spotdir, delimiter=',')\n",
    "    fixed_spots1 = spot_fix[spot_fix[:,4] == i][:,:3]\n",
    "    spotdir = 'E:/Maxprobe_analysis/R2_R1_3tm50/R1_3tm50_1920/spots/R1_c3_ROI.txt'\n",
    "    spot_mov=np.loadtxt(spotdir, delimiter=',')\n",
    "    moving_spots1 = spot_mov[spot_mov[:,4] == i][:,:3]\n",
    "    # change to zyx order\n",
    "    fixed_spots11 = np.transpose(np.array([fixed_spots1[:,2],fixed_spots1[:,1],fixed_spots1[:,0]]))\n",
    "    moving_spots11 = np.transpose(np.array([moving_spots1[:,2],moving_spots1[:,1],moving_spots1[:,0]]))\n",
    "    # convert to physical units\n",
    "    ccc = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "    fix_spots = (fixed_spots11 - ccc * fix_spacing)\n",
    "    fix_spots_new = fix_spots\n",
    "    ns = fix_spots.shape[0]\n",
    "    print(f'FIXED image: found {ns} key points')\n",
    "\n",
    "    dd = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "#     mov_spots_h = (moving_spots11/fix_spacing - dd).astype(int)\n",
    "    mov_spots = (moving_spots11 - dd * mov_spacing)\n",
    "    ns = mov_spots.shape[0]\n",
    "    print(f'MOVING image: found {ns} key points')\n",
    "    \n",
    "    # get contexts\n",
    "    fix_spots0 = features.get_spot_context(\n",
    "        fixed3, fixed_spots11, fix_spacing, cc_r,\n",
    "    )\n",
    "    mov_spots0 = features.get_spot_context(\n",
    "        moving3, moving_spots11, mov_spacing, cc_r,\n",
    "    )\n",
    "\n",
    "    print(f'get contexts')\n",
    "\n",
    "    # get point correspondences may change to mutual information\n",
    "    correlations = features.pairwise_correlation(\n",
    "        fix_spots0, mov_spots0,\n",
    "    )\n",
    "    print(f'correlations')\n",
    "    fix_spots1, mov_spots1 = features.match_points(\n",
    "        fix_spots0, mov_spots0,\n",
    "        correlations, match_threshold,\n",
    "    )\n",
    "\n",
    "    ns = fix_spots1.shape[0]\n",
    "    print(f'MATCHED points: found {ns} matched points')\n",
    "\n",
    "    global_affine = ransac.ransac_align_points(fix_spots1 - cc * fix_spacing, mov_spots1 - dd * mov_spacing, align_threshold,)\n",
    "    print(global_affine)\n",
    "\n",
    "    inv_affine = ransac.ransac_align_points(mov_spots1 - dd * mov_spacing, fix_spots1 - cc * fix_spacing, align_threshold,)\n",
    "#     print(inv_affine)\n",
    "\n",
    "# functions for applying transforms are in bigstream.transform. apply the global affine to the moving image\n",
    "mov_affine = transform.apply_global_affine(\n",
    "    fix_ds, mov_ds,\n",
    "    fix_spacing, fix_spacing,\n",
    "    global_affine,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use ICP to register point clouds of an example ROI dataset. \n",
    "#### spots data were generated by Airlocolize of the multiFISH pipeline\n",
    "These spots have not been registered at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transform spots\n",
    "if __name__ == \"__main__\":\n",
    "    A = fix_spots\n",
    "    B = mov_spots\n",
    "    B = warp_spots_new[:,:3]\n",
    "    #     A = np.random.randint(0,101,(20,3))  # 20 points for test\n",
    "    #     rotz = lambda theta: np.array([[np.cos(theta),-np.sin(theta),0],\n",
    "    #                                        [np.sin(theta),np.cos(theta),0],\n",
    "    #                                        [0,0,1]])\n",
    "    #     trans = np.array([2.12,-0.2,1.3])\n",
    "    #     B = A.dot(rotz(np.pi/4).T) + trans \n",
    "\n",
    "    Transform, distances = icp(A, B)\n",
    "    inv_Transform, distances = icp(B, A)\n",
    "    print(np.mean(distances))\n",
    "    np.set_printoptions(precision=3,suppress=True)\n",
    "    print (Transform)\n",
    "    # functions for applying transforms are in bigstream.transform. apply the global affine to the moving image\n",
    "    ICP_affine = transform.apply_global_affine(\n",
    "        fix_ds, mov_affine,\n",
    "        fix_spacing, fix_spacing,\n",
    "        Transform,)\n",
    "    #     print (inv_Transform)\n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "    C = p.dot(inv_Transform.T)\n",
    "\n",
    "    #     viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "    #     napari.run()\n",
    "    viewer.add_image(ICP_affine,colormap='red',blending='additive') #load image data into napari\n",
    "    viewer.layers['ICP_affine'].contrast_limits=(200, 3400)  \n",
    "\n",
    "    viewer.add_points(np.transpose(np.array([A[:,0]/fix_spacing[0],A[:,1]/fix_spacing[1],A[:,2]/fix_spacing[2]])),name ='A', size=1,\n",
    "                      face_color='green',edge_color='green',blending='opaque') \n",
    "    viewer.add_points(np.transpose(np.array([B[:,0]/fix_spacing[0],B[:,1]/fix_spacing[1],B[:,2]/fix_spacing[2]])),name ='B', size=1, \n",
    "                      face_color='red',edge_color='red',blending='opaque') \n",
    "    viewer.add_points(np.transpose(np.array([C[:,0]/fix_spacing[0],C[:,1]/fix_spacing[1],C[:,2]/fix_spacing[2]])),name ='C', size=1,\n",
    "                      face_color='yellow',edge_color='yellow',blending='opaque') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ICP distance change. Minor increased performance\n",
    "spot_fix = fix_spots\n",
    "warp_spots_new = get_spot_inside(warp_spots,segmentation_mini,fix_spacing,ROI_fixed,cc)\n",
    "spot_mov = C\n",
    "lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist = colocalization(spot_fix,spot_mov,neighbor_radius1)  # return in pixel\n",
    "\n",
    "# find and remove spots outside of this ROI\n",
    "c0=spot_fix[:,:3].copy()\n",
    "c1=spot_mov[:,:3].copy()\n",
    "kdtree_c0 = cKDTree(c0)\n",
    "kdtree_c1 = cKDTree(c1)\n",
    "dist2,idx2 = kdtree_c0.query(c1, k=3)\n",
    "\n",
    "fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "plt.violinplot(dist2[:,0])\n",
    "sns.despine() \n",
    "plt.xticks([])\n",
    "plt.ylim([0,neighbor_radius1*2])\n",
    "plt.xlabel('Spots:'+ str(dist2[:,0].shape[0]))\n",
    "plt.ylabel('Distance/pixel')\n",
    "ave=np.average(dist2[:,0])\n",
    "plt.title(str(float('%.2f' % ave)))\n",
    "# plt.axis('off')\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need correlational method that calculates the mutual information, not only the intensity of blobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab and flatten context\n",
    "a_con = np.array( [a[1].flatten() for a in fix_spots0] , dtype=object)\n",
    "b_con = np.array( [b[1].flatten() for b in mov_spots0] , dtype=object)\n",
    "\n",
    "# get means and std for all contexts, center contexts\n",
    "a_mean, a_std = _stats(a_con)\n",
    "b_mean, b_std = _stats(b_con)\n",
    "a_con = a_con - a_mean[..., None]\n",
    "b_con = b_con - b_mean[..., None]\n",
    "\n",
    "# compute pairwise correlations\n",
    "corr = np.matmul(a_con, b_con.T)\n",
    "corr = corr / a_std[..., None]\n",
    "corr = corr / b_std[None, ...]\n",
    "corr = corr / a_con.shape[1]\n",
    "\n",
    "# contexts with no variability are nan, set to 0\n",
    "corr[np.isnan(corr)] = 0\n",
    "correlations = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(R1C3_aligned,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['R1C3_aligned'].contrast_limits=(200, 1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsave(seg_dir + 'R1C3_aligned_505_0.7_8.tif',R1C3_aligned)\n",
    "# imsave(seg_dir + 'R2C3_ROI.tif',R2C3_ROI)\n",
    "# imsave(seg_dir + 'R1C3_ROI.tif',R1C3_ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(R2C3_ROI,colormap='green',blending='additive') #load image data into napari\n",
    "viewer.add_image(R1C3_ROI,colormap='red',blending='additive') #load image data into napari\n",
    "viewer.add_image(R1C3_aligned,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.layers['R2C3_ROI'].contrast_limits=(200, 1400)\n",
    "viewer.layers['R1C3_ROI'].contrast_limits=(200, 1400)\n",
    "viewer.layers['R1C3_aligned'].contrast_limits=(200, 1400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize aligned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(R2C3_ROI,colormap='green',blending='additive') #load image data into napari\n",
    "viewer.add_image(R1C3_aligned,colormap='red',blending='additive') #load image data into napari\n",
    "viewer.add_image(R2C0_aligned,colormap='magenta',blending='additive') #load image data into napari\n",
    "viewer.add_image(R1C0_aligned,colormap='yellow',blending='additive') #load image data into napari\n",
    "viewer.layers['R2C3_ROI'].contrast_limits=(200, 1400)\n",
    "viewer.layers['R1C3_aligned'].contrast_limits=(200, 1400)\n",
    "viewer.layers['R2C0_aligned'].contrast_limits=(200, 400)\n",
    "viewer.layers['R1C0_aligned'].contrast_limits=(200, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another round of registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the same parameters will not make the images getting better registered. Removed it.\n",
    "# apply the global affine to the moving image\n",
    "global_affine2 = affine.ransac_affine(\n",
    "    R2C3_ROI, R1C3_aligned,\n",
    "    fix_ds_spacing, fix_ds_spacing,\n",
    "    min_radius=2, max_radius=8, match_threshold=0.5,\n",
    "    cc_radius=8\n",
    ")\n",
    "# functions for applying transforms are in bigstream.transform\n",
    "# apply the global affine to the moving image\n",
    "R1C3_aligned2 = transform.apply_global_affine(\n",
    "    R2C3_ROI, R1C3_aligned,\n",
    "    fix_ds_spacing, fix_ds_spacing,\n",
    "    global_affine2,\n",
    ")\n",
    "\n",
    "viewer.add_image(R1C3_aligned2,colormap='red',blending='additive') #load image data into napari\n",
    "viewer.layers['R1C3_aligned2'].contrast_limits=(200, 1400)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deformable registration\n",
    "# Not find a good way to get fine results yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bigstream import deform\n",
    "warps = deform.deformable_align(\n",
    "    fix_ds, mov_affine,\n",
    "    fix_ds_spacing, fix_ds_spacing,\n",
    "    iterations=[500,250,100,1],\n",
    "    shrink_factors=[8,4,2,1],\n",
    "    smooth_sigmas=[16,8,4,2],\n",
    ")\n",
    "    \n",
    "from CircuitSeeker import defreg as csdr\n",
    "# local_warps = local_warps.squeeze()\n",
    "\n",
    "aligned = csdr.applyTransformToImage(\n",
    "    fix_ds, mov_affine,\n",
    "    fix_ds_spacing, fix_ds_spacing,\n",
    "    transform_list=[warps,]\n",
    ")\n",
    "print(aligned.shape)\n",
    "viewer.add_image(aligned,colormap='red',blending='additive') #load image data into napari\n",
    "viewer.layers['aligned'].contrast_limits=(200, 1400)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easifish",
   "language": "python",
   "name": "easifish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
