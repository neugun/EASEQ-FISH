{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ransac affine for point cloud alignment\n",
    "After starfinity for finding ROI and ROI_affine_2masks for affineing ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will learn to align several point clouds from the ROI using two variants of the ransac affine and ICP algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequistes:\n",
    "1. starfinity for finding ROI\n",
    "2. ### ROI_affine_2masks for warping ROIs.Inspect invalid ROIs, extract ROI_SPOTS \n",
    "\n",
    "Steps\n",
    "1. import spots location if using RS-FISH, checked with Napari images\n",
    "2. load images that the same as the registered or unregistered mask \n",
    "3. select each mask, load spot location of ROI (FISHSPOTS,RS-FISH, or starfish), perform\n",
    "ransac affine, ICP affine for each channels of two rounds\n",
    "4. ### Inspect invalid ROIs, perform another affine, export spots location of every ROIs. \n",
    "5. Visualization of spots of multiple channels and rounds\n",
    "6. Decode spots with knn neighbor or other 3d seqFISH methods.\n",
    "\n",
    "For later:Trying to implement other better non-rigid methods, local descriptor methods.\n",
    "\n",
    "bash\n",
    "1. for each channel, rounds, and # numbers of ROI (e.g., every 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with loading the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pools\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from math import pi, sin, cos, sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from matplotlib import cm\n",
    "from scipy import ndimage\n",
    "import scipy.io\n",
    "from skimage import data\n",
    "from skimage.io import imread, imsave\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from cv2 import estimateTranslation3D\n",
    "import tifffile\n",
    "import seaborn as sns\n",
    "\n",
    "# import bigstream library\n",
    "import zarr\n",
    "import z5py\n",
    "from bigstream import features\n",
    "#from bigstream import features1\n",
    "from bigstream import ransac\n",
    "from bigstream import affine\n",
    "#from bigstream import affine1\n",
    "from bigstream import transform\n",
    "from fishspot.filter import white_tophat\n",
    "from fishspot.detect import detect_spots_log\n",
    "\n",
    "# napari\n",
    "%gui qt5\n",
    "import napari\n",
    "# viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "# napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with loading the required modules for ransac."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colocalization filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucldist(coords1, coords2):\n",
    "    \"\"\" Calculates the euclidean distance between 2 lists of coordinates. \"\"\"\n",
    "    dist = np.zeros(len(coords1))\n",
    "    i = 0\n",
    "    for (x, y) in zip(coords1, coords2):\n",
    "        p1 = x\n",
    "        p2 = y\n",
    "        squared_dist = (p1[0]-p2[0])**2+(p1[1]-p2[1])**2+(p1[2]-p2[2])**2\n",
    "        dist[i] = np.sqrt(squared_dist)\n",
    "        i = i+1\n",
    "    return dist\n",
    "\n",
    "def cloud_distance(spot_fix,spot_mov):\n",
    "    \"\"\"compute distance of nearest spot cloud by KNN.\n",
    "    \"\"\"\n",
    "    c0=spot_fix[:,:3].copy()\n",
    "    c1=spot_mov[:,:3].copy()\n",
    "    kdtree_c0 = cKDTree(c0)\n",
    "    kdtree_c1 = cKDTree(c1)\n",
    "    dist2,idx2 = kdtree_c0.query(c1, k=3)\n",
    "    [Idx_unique, I] = np.unique(idx2,return_index=True)  \n",
    "    return dist2[:,0]\n",
    "\n",
    "def colocalization(spot_c0,spot_c1,neighbor_radius):\n",
    "    #vox=[0.23,0.23,0.38]\n",
    "    c0=spot_c0[:,:3].copy()\n",
    "    c1=spot_c1[:,:3].copy()\n",
    "\n",
    "    kdtree_c0 = cKDTree(c0)\n",
    "    kdtree_c1 = cKDTree(c1)\n",
    "    neighbors = kdtree_c0.query_ball_tree(kdtree_c1, neighbor_radius)\n",
    "    dist2,idx2 = kdtree_c0.query(c1, k=3)\n",
    "    [Idx_unique, I] = np.unique(idx2,return_index=True) \n",
    "    ## find the smallest repeated value location, and delete the others\n",
    "    for i in range(Idx_unique.shape[0]):  # should repeat for only once\n",
    "    #     print(Idx_unique[i])\n",
    "        Loc_rep=np.where(idx2==Idx_unique[i])    \n",
    "    #     print(Loc_rep[0])\n",
    "        A=dist2[Loc_rep[0],Loc_rep[1]]\n",
    "        minposition = min(A)\n",
    "        Loc_min = np.where(A==minposition)[0]\n",
    "    #     print(Loc_min)\n",
    "    #     Loc_rep_min=Loc_rep[0][Loc_min[0]]    \n",
    "        Loc_rep_nouse=np.delete(range(len(Loc_rep[0])),Loc_min)\n",
    "        dist2[Loc_rep[0][Loc_rep_nouse],Loc_rep[1][Loc_rep_nouse]]=neighbor_radius*2 \n",
    "    ## find the results that are less than radius; used later column data \n",
    "    # when only first row is not exist use latter column, or just dispose it. \n",
    "    co_loc=np.where(dist2>neighbor_radius)\n",
    "\n",
    "    for j in range(dist2.shape[0]):\n",
    "         if dist2[j,0] < neighbor_radius:\n",
    "                dist2[j,1] = neighbor_radius*2\n",
    "    for j in range(dist2.shape[0]):            \n",
    "         if dist2[j,0] <neighbor_radius or dist2[j,1] <neighbor_radius:\n",
    "                dist2[j,2] = neighbor_radius*2       \n",
    "    row_c1 = np.where(dist2<neighbor_radius)\n",
    "#     print(len(row_c1[0]))\n",
    "\n",
    "    # lipo spot_c1 is row_c1\n",
    "    pBind = row_c1[0]\n",
    "    # print(idx2)\n",
    "    # lipo spot_c1 is idx2\n",
    "    pAind = [(idx2[row_c1[0][x], row_c1[1][x]]) for x in range(len(row_c1[0]))]\n",
    "    lipo_c0 = spot_c0[pAind]\n",
    "    lipo_c1 = spot_c1[pBind]\n",
    "\n",
    "#     print(np.unique(pAind).shape) \n",
    "    true_pos_c0 = np.delete(spot_c0, pAind, axis=0)\n",
    "    true_pos_c1 = np.delete(spot_c1, pBind, axis=0) #true\n",
    "\n",
    "    if spot_c0.shape[0]>0:\n",
    "        P1 = (lipo_c0.shape[0] / spot_c0.shape[0])*100   # % mov spots from  previous images  /spot_c0.shape\n",
    "    else:\n",
    "        P1 = 0\n",
    "        \n",
    "    if spot_c1.shape[0]>0:\n",
    "        P2 = (lipo_c1.shape[0] / spot_c1.shape[0])*100  # % fixed spots can be found in later mov images  /spot_c0.shape\n",
    "    else:\n",
    "        P2 = 0\n",
    "#     print('% P1: ',str(P1) + ';  % P2: ',str(P2)) \n",
    "    Dist = np.mean(eucldist(lipo_c0,lipo_c1))\n",
    "\n",
    "    return lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,Dist,P1,P2\n",
    "\n",
    "def get_spot_inside(all_spots,segmentation_mini,fix_spacing,ROI_fixed,cc):\n",
    "    \"\"\"remove spots outside of a segmenation mask\n",
    "       change spot location back to segmentation mask in pixels\n",
    "    \"\"\"\n",
    "    fix_spots_mini = all_spots[:,:3] / fix_spacing * [0.5,0.25,0.25] + cc\n",
    "    spot_mini = np.zeros(len(fix_spots_mini))\n",
    "    rounded_spot = fix_spots_mini.astype('int') \n",
    "    for i in range(0, len(fix_spots_mini)):          \n",
    "        Coord = rounded_spot[i]\n",
    "        if Coord[0]<0: Coord[0] = 0\n",
    "        if Coord[1]<0: Coord[1] = 0\n",
    "        if Coord[2]<0: Coord[2] = 0\n",
    "        if Coord[0]>segmentation_mini.shape[0]: Coord[0] = segmentation_mini.shape[0]\n",
    "        if Coord[1]>segmentation_mini.shape[1]: Coord[1] = segmentation_mini.shape[1]            \n",
    "        if Coord[2]>segmentation_mini.shape[2]: Coord[2] = segmentation_mini.shape[2]\n",
    "        idx = segmentation_mini[Coord[0]-1, Coord[1]-1, Coord[2]-1]   # roi id\n",
    "        if idx == ROI_fixed:\n",
    "            spot_mini[i] = idx  # add ROI number  \n",
    "    spots_in = all_spots[np.where(spot_mini==ROI_fixed)]\n",
    "    spots_out = all_spots[np.where(spot_mini==0)]\n",
    "    \n",
    "    spots_in_index = np.where(spot_mini==ROI_fixed)\n",
    "    ns = spots_in.shape[0]\n",
    "#     print(f'Image: found {ns} key points inside ROI')\n",
    "    print(f'Image: found {spots_out.shape[0]} key points outside ROI')\n",
    "    return spots_in,spots_in_index\n",
    "\n",
    "## ICP\n",
    "def nearest_neighbor(src, dst):\n",
    "    '''\n",
    "    Find the nearest (Euclidean) neighbor in dst for each point in src\n",
    "    Input:\n",
    "        src: Nx3 array of points\n",
    "        dst: Nx3 array of points\n",
    "    Output:\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "        indecies: dst indecies of the nearest neighbor\n",
    "    '''\n",
    "    indecies = np.zeros(src.shape[0], dtype=np.int)\n",
    "    distances = np.zeros(src.shape[0])\n",
    "    for i, s in enumerate(src):\n",
    "        min_dist = np.inf\n",
    "        for j, d in enumerate(dst):\n",
    "            dist = np.linalg.norm(s-d)\n",
    "            # find Nearest dst[j] to src[i]\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                indecies[i] = j\n",
    "                distances[i] = dist\n",
    "    return distances, indecies  \n",
    "\n",
    "def get_scale(A,B):\n",
    "    dis_A=get_all_side_length(np.array(A))\n",
    "    dis_B=get_all_side_length(np.array(B))\n",
    "    scale = np.abs(dis_B/dis_A)\n",
    "    mask=np.abs(scale)>0.0001\n",
    "    scale_sort=np.sort(scale[mask].reshape(-1))\n",
    "    d_n=len(scale_sort)\n",
    "    s_mean=scale_sort[int(d_n/4):int(d_n*3/4)].mean() #only use medium data\n",
    "    return s_mean\n",
    "\n",
    "def best_fit_transform(A, B):\n",
    "    '''\n",
    "    Calculates the least-squares best-fit transform between corresponding 3D points A->B\n",
    "    Input:\n",
    "      A: Nx3 numpy array of corresponding 3D points\n",
    "      B: Nx3 numpy array of corresponding 3D points\n",
    "    Returns:\n",
    "      T: 4x4 homogeneous transformation matrix\n",
    "      R: 3x3 rotation matrix\n",
    "      t: 3x1 column vector\n",
    "    '''\n",
    "    assert len(A) == len(B)\n",
    "\n",
    "    # translate points to their centroids\n",
    "    centroid_A = np.mean(A, axis=0) \n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # rotation matrix\n",
    "    W = np.dot(BB.T, AA)\n",
    "    U, s, VT = np.linalg.svd(W, full_matrices=True, compute_uv=True)\n",
    "    R = np.dot(U, VT)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        VT[2,:] *= -1\n",
    "        R = np.dot(U, VT)\n",
    "\n",
    "    # translation\n",
    "    t = centroid_B.T - np.dot(R,centroid_A.T)\n",
    "\n",
    "    #scale \n",
    "#     s_mean=get_scale(A,B)\n",
    "    s_mean=1\n",
    "    \n",
    "    # homogeneous transformation\n",
    "    T = np.identity(4)\n",
    "#     T[0:3, 0:3] = s_mean * R\n",
    "    T[0:3, 0:3] = R\n",
    "    T[0:3, 3] = t\n",
    "    \n",
    "    return T, R, t, s_mean\n",
    "       \n",
    "def icp(A0, B0,distance_forICP,init_pose = None, max_iterations=200, tolerance=0.0001):\n",
    "    '''\n",
    "    The Iterative Closest Point method\n",
    "    Input:\n",
    "        A: Nx3 numpy array of source 3D points\n",
    "        B: Nx3 numpy array of destination 3D point\n",
    "        init_pose: 4x4 homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "    '''\n",
    "    #  select points\n",
    "#     distance_forICP = 3\n",
    "\n",
    "    A,B,_,_,dist,_,_ = colocalization(A0,B0,distance_forICP)\n",
    "    \n",
    "    # make points homogeneous, copy them so as to maintain the originals\n",
    "    src = np.ones((4,A.shape[0]))  #(4, A.shape[0])\n",
    "    dst = np.ones((4,B.shape[0]))\n",
    "    src[0:3,:] = np.copy(A.T)  # A.T shape (3,20)\n",
    "    dst[0:3,:] = np.copy(B.T) # FIX\n",
    "    \n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    prev_error = np.inf\n",
    "    distances_iter = np.zeros((max_iterations,1))\n",
    "    for i in range(max_iterations):\n",
    "        # find the nearest neighbours between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[0:3,:].T, dst[0:3,:].T)\n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T,R,t,s_mean = best_fit_transform(src[0:3,:].T, dst[0:3,indices].T)  #Sort dst[] by indices\n",
    "        src = np.dot(T, src)\n",
    "        # check error\n",
    "        mean_error = np.sum(distances) / distances.size\n",
    "        if abs(prev_error-mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "        distances_iter[i] = mean_error\n",
    "        print(f'No.{i} iter icp error:{mean_error}')\n",
    "    T,R,t,s_mean = best_fit_transform(A, src[0:3,:].T)\n",
    "    \n",
    "    src_1 = np.ones((4,A0.shape[0]))  #(4, A.shape[0])\n",
    "    src_1[0:3,:] = np.copy(A0.T)  # A.T shape (3,20)    \n",
    "    C = np.dot(T, src_1) # A transform\n",
    "    C =  C[0:3,:].T      # save file as the same order \n",
    "    \n",
    "    return T, distances, C \n",
    "\n",
    "def get_all_side_length(points):\n",
    "    all_dis=[]\n",
    "    for i in range(len(points)-1):\n",
    "        for j in range(i+1,len(points)):\n",
    "            all_dis.append(points[i]-points[j])\n",
    "    all_dis=np.array(all_dis)\n",
    "    return np.linalg.norm(all_dis,axis=1)\n",
    "\n",
    "def estimate_similarity_transform_3D(A, B):\n",
    "                 \n",
    "    assert len(A) == len(B)\n",
    "    N = A.shape[0];\n",
    "    mu_A = mean(A, axis=0)\n",
    "    mu_B = mean(B, axis=0)\n",
    "\n",
    "    AA = A - tile(mu_A, (N, 1))\n",
    "    BB = B - tile(mu_B, (N, 1))\n",
    "    H = transpose(AA) * BB\n",
    "    U, S, Vt = linalg.svd(H)\n",
    "    R = Vt.T * U.T\n",
    "                 \n",
    "    if linalg.det(R) < 0:\n",
    "        print (\"Reflection detected\")\n",
    "        Vt[2, :] *= -1\n",
    "        R = Vt.T * U.T\n",
    "    s_mean=get_scale(A,B)\n",
    "    t = -s_mean * R * mu_A.T + mu_B.T\n",
    "\n",
    "    return R, t\t,s_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RANSAC modules #c\n",
    "def get_random_sample(data,n_items: int) -> np.ndarray:\n",
    "    indices = np.random.choice(len(data), n_items, replace=False)\n",
    "    return indices\n",
    "\n",
    "def estimate_n_trials_needed(n_sample_points, inlier_ratio: float = 0.8, probability: float = 0.95) -> int:\n",
    "    \"\"\"\n",
    "    Estimate number of trials needed to select only true inliers with RANSAC.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    inlier_ratio : number of inliers / number of all points\n",
    "    n_sample_points :number of selected point in each iteration\n",
    "    probability : desired probability of success.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Estimated number of trials needed.\n",
    "    \"\"\"\n",
    "    return int(np.log(1 - probability) / np.log(1 - inlier_ratio ** n_sample_points))\n",
    "\n",
    "#main\n",
    "def ransac_remove_outliers(\n",
    "    observation,reference,error_threshold,current_indices,inlier_ratio=0.9,n_sample_points=25,\n",
    "    inlier_threshold=0,fit_with_final_inliers=True\n",
    "): \n",
    "    '''\n",
    "    This is to remove outliers after each iteration of ICP\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observation - a set of points need to be registered to the ref\n",
    "    inlier_ratio : number of inliers / number of all point\n",
    "    error_threshold – threshold value to determine when a data point fits a model\n",
    "    n_sample_points- number of selected point in each iteration\n",
    "    fit_with_final_inliers: Fit final model with final inliers solved by the algorithm.\n",
    "    inlier_threshold – minimum number of data points required to fit the model\n",
    "  \n",
    "    max_trials – maximum number of iterations allowed in the algorithm\n",
    "    \n",
    "    #not set # d – number of close data points required to assert that a model fits well to data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    inlier indices\n",
    "    '''\n",
    "    # initialization\n",
    "    inlier_indices_candidate = None\n",
    "    inlier_indices = None\n",
    "    trial_number = 0\n",
    "    best_score = -np.inf\n",
    "    best_error = np.inf\n",
    "    best_model = None\n",
    "    max_trials = None\n",
    "\n",
    "    is_termination = None #if iteration should be terminated.\n",
    "    is_solution_valid = None #if solution valid or not.\n",
    "    \n",
    "    max_trials = estimate_n_trials_needed(n_sample_points)\n",
    "    if max_trials>100:\n",
    "        max_trials=100\n",
    "    print(max_trials)\n",
    "    \n",
    "    #fit\n",
    "    for trial in range(max_trials):\n",
    "        src=observation\n",
    "        trial_number = trial\n",
    "        sample = get_random_sample(src.T,n_sample_points) #get data\n",
    "        srcsample = src[:,sample]\n",
    "        #distances, indices = nearest_neighbor(srcsample[0:3,:].T,reference[0:3,:].T)\n",
    "        indices=current_indices[sample]\n",
    "        currentT,R,t,s_mean = best_fit_transform(srcsample[0:3,:].T,reference[0:3,indices].T)\n",
    "        \n",
    "        src= np.dot(currentT,src)\n",
    "        \n",
    "        model_distance, indice = nearest_neighbor(src[0:3,:].T, reference[0:3,:].T)\n",
    "        \n",
    "        #get inliers\n",
    "        in_indices = np.where(model_distance <= error_threshold)\n",
    "        in_indices = np.asarray(in_indices)\n",
    "        inlier_indices_candidate = in_indices #find inliers\n",
    "        \n",
    "        score=inlier_indices_candidate.size\n",
    "        \n",
    "        #Verify if the current model is valid\n",
    "        if score >= inlier_threshold:\n",
    "            is_valid_solution = True\n",
    "        else:\n",
    "            is_valid_solution = False\n",
    "\n",
    "        if not is_valid_solution:\n",
    "            continue\n",
    "        \n",
    "#         error = np.sum(model_distance[indice]) / model_distance[indice].size\n",
    "        \n",
    "#         # Update solution if best so far\n",
    "#         if (error<best_error):\n",
    "#             inlier_indices = inlier_indices_candidate.copy()\n",
    "#             print(f'inliers number:{score},error:{error}')\n",
    "#             best_error = error\n",
    "#             best_score=score\n",
    "#             T_rs=currentT\n",
    "#             RSdistance=model_distance\n",
    "            \n",
    "        p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "        D = p.dot(np.linalg.inv(currentT).T)        ## B->A spots (right) with B->A transform (right)\n",
    "        C = D[:,:3]\n",
    "        \n",
    "        #Test ICP distance change. Minor increased performance\n",
    "        lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist_ICP_RS,_,_ = colocalization(observation,C,neighbor_radius2) \n",
    "        if (dist_ICP<best_error):\n",
    "            inlier_indices = inlier_indices_candidate.copy()\n",
    "            print(f'inliers number:{score},error:{dist_ICP}')\n",
    "            best_error = dist_ICP\n",
    "            best_score = score\n",
    "            T_rs = currentT\n",
    "            RSdistance = model_distance\n",
    "            \n",
    "#     if fit_with_final_inliers:\n",
    "#         inliers = observation[0:3,inlier_indices]\n",
    "#         inliers = np.squeeze(inliers)\n",
    "#         distances, indices = nearest_neighbor(inliers[0:3,:].T, reference[0:3,:].T)\n",
    "#         T_rs,_,_,_= best_fit_transform(inliers[0:3,:].T,reference[0:3,indices].T)\n",
    "#         RSsrc= np.dot(T_rs,observation)\n",
    "#         RSdistances,_ = nearest_neighbor(RSsrc[0:3,:].T, reference[0:3,:].T)\n",
    "#         output_error = np.sum(RSdistances) / RSdistances.size\n",
    "#     if output_error==best_error:\n",
    "#         print(f'yes match best')\n",
    "#     else:\n",
    "#         print(f'output=!best')\n",
    "\n",
    "    return T_rs,RSdistance,best_error\n",
    "\n",
    "def RANSAC_ICP(\n",
    " A0, B0, distance_forICP,init_pose = None, max_iterations=200, tolerance=0.001\n",
    "):\n",
    "    '''\n",
    "    The Iterative Closest Point with RANSAC\n",
    "    Input:\n",
    "        A: Nx3 numpy array of source 3D points\n",
    "        B: Nx3 numpy array of destination 3D point\n",
    "        distance_forICP\n",
    "        init_pose: 4x4 homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "    '''\n",
    "    # select points\n",
    "    # distance_forICP = 3\n",
    "    A,B,_,_,dist,_,_ = colocalization(A0,B0,distance_forICP)\n",
    "    \n",
    "    # make points homogeneous, copy them so as to maintain the originals\n",
    "    src = np.ones((4,A.shape[0])) #(4, A.shape[0])\n",
    "    dst = np.ones((4,B.shape[0]))\n",
    "    src[0:3,:] = np.copy(A.T) # A.T shape (3,20)\n",
    "    dst[0:3,:] = np.copy(B.T)\n",
    "    \n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    error = np.inf\n",
    "    prev_error_rc =np.inf\n",
    "    distances_iter = np.zeros((max_iterations,1))\n",
    "    RSthreshold=1\n",
    "                \n",
    "    distances, indices = nearest_neighbor(src[0:3,:].T, dst[0:3,:].T)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # add RANSAC to remove outliers #Shiqi Wang\n",
    "        #determine threshold\n",
    "        if i>0:\n",
    "            RSthreshold=np.quantile(distances, .95)\n",
    "            #RSthreshold=0.95\n",
    "            print(f'RSthreshold:{RSthreshold}')\n",
    "\n",
    "        T1,distancesRS,errorRS = ransac_remove_outliers(src,dst,RSthreshold,indices)\n",
    "        src1 = np.dot(T1, src)\n",
    "        distances1, indices1 = nearest_neighbor(src1[0:3,:].T, dst[0:3,:].T)\n",
    "        # check error of RS\n",
    "        mean_error = np.sum(distances) / distances.size\n",
    "        mean_error_RS=np.sum(distances1) / distances1.size\n",
    "        \n",
    "        if mean_error_RS<mean_error:\n",
    "            print(f'RANSACpass,mean_error_RANSAC: {mean_error_RS}')\n",
    "            src=np.copy(src1)\n",
    "            distances=distances1\n",
    "            indices=indices1\n",
    "            error=mean_error_RS\n",
    "        else:\n",
    "            print(f'Ignore RS.')\n",
    "            error=mean_error\n",
    "  \n",
    "        # find the nearest neighbours between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[0:3,:].T, dst[0:3,:].T)\n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T0,R,t,s_mean = best_fit_transform(src[0:3,:].T, dst[0:3,indices].T)  #Sort dst[] by indices\n",
    "        # update the current source\n",
    "        # refer to \"Introduction to Robotics\" Chapter2 P28. Spatial description and transformations\n",
    "\n",
    "        # check error\n",
    "        mean_error = np.sum(distances) / distances.size\n",
    "        print(f'No.{i} iter icp error:{mean_error}')\n",
    "        \n",
    "        if mean_error <= error:\n",
    "            error = mean_error\n",
    "            distances_iter[i] = mean_error\n",
    "            src = np.dot(T0, src)\n",
    "            \n",
    "        if abs(prev_error_rc-error) < tolerance:\n",
    "            break\n",
    "        prev_error_rc = error\n",
    "\n",
    "    T,R,t,s_mean = best_fit_transform(A, src[0:3,:].T)\n",
    "    distances_iter=distances_iter[np.argwhere(distances_iter)]\n",
    "    src_1 = np.ones((4,A.shape[0]))  #(4, A.shape[0])\n",
    "    src_1[0:3,:] = np.copy(A.T)  # A.T shape (3,20)    \n",
    "    C = np.dot(T, src_1) # A transform\n",
    "    C =  C[0:3,:].T     \n",
    "\n",
    "#     fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "#     plt.plot(distances_iter[:20])\n",
    "#     sns.despine() \n",
    "#     plt.xlabel('Spots:'+ str(distances_iter[:20].shape[0]))\n",
    "#     plt.ylabel('Distance/pixel')\n",
    "#     ave=np.average(distances_iter[:20])\n",
    "#     plt.title(str(float('%.2f' % ave)))\n",
    "#     plt.show()\n",
    "    print(f'distance_iter:{distances_iter}')\n",
    "    return T,distances,C\n",
    "\n",
    "\n",
    "def ICP_RANSAC(\n",
    "    A0, B0, distance_forICP,init_pose = None, max_iterations=200, tolerance=0.001\n",
    "):\n",
    "    '''\n",
    "    The Iterative Closest Point with RANSAC\n",
    "    Input:\n",
    "        A: Nx3 numpy array of source 3D points\n",
    "        B: Nx3 numpy array of destination 3D point\n",
    "        distance_forICP\n",
    "        init_pose: 4x4 homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "    '''\n",
    "    #  select points\n",
    "#     distance_forICP = 3\n",
    "    A,B,_,_,dist,_,_ = colocalization(A0,B0,distance_forICP)\n",
    "    \n",
    "    # make points homogeneous, copy them so as to maintain the originals\n",
    "    src = np.ones((4,A.shape[0])) #(4, A.shape[0])\n",
    "    dst = np.ones((4,B.shape[0]))\n",
    "    src[0:3,:] = np.copy(A.T) # A.T shape (3,20)\n",
    "    dst[0:3,:] = np.copy(B.T)\n",
    "    \n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    error = np.inf #best error\n",
    "    prev_error_rc =np.inf\n",
    "    distances_iter = np.zeros((max_iterations,1))\n",
    "    RSthreshold=1\n",
    "    \n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        \n",
    "        \n",
    "        # find the nearest neighbours between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[0:3,:].T, dst[0:3,:].T)\n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T0,R,t,s_mean = best_fit_transform(src[0:3,:].T, dst[0:3,indices].T)  #Sort dst[] by indices\n",
    "        # update the current source\n",
    "        # refer to \"Introduction to Robotics\" Chapter2 P28. Spatial description and transformations\n",
    "        \n",
    "        # check error\n",
    "        mean_error = np.sum(distances) / distances.size\n",
    "        print(f'No.{i} iter icp error:{mean_error}')\n",
    "        \n",
    "        if mean_error <= error:\n",
    "            error = mean_error\n",
    "            distances_iter[i] = mean_error\n",
    "        \n",
    "        # add RANSAC to remove outliers #Shiqi Wang\n",
    "        #determine threshold\n",
    "        RSthreshold=np.quantile(distances, .95)\n",
    "        #RSthreshold=0.95\n",
    "        print(f'RSthreshold:{RSthreshold}')\n",
    "        \n",
    "        T1,distancesRS,errorRS = ransac_remove_outliers(src,dst,RSthreshold,indices)\n",
    "        \n",
    "        # check error of RS\n",
    "        print(f'mean_error_RANSAC: {errorRS}')\n",
    "        if errorRS < error:\n",
    "            print(f'RANSACpass')\n",
    "            error = errorRS\n",
    "            distances_iter[i] = errorRS\n",
    "            src= np.dot(T1, src)\n",
    "        else:\n",
    "            print(f'Ignore RS.')\n",
    "            src = np.dot(T0, src)\n",
    "        \n",
    "        if abs(prev_error_rc-error) < tolerance:\n",
    "            break\n",
    "        prev_error_rc = error\n",
    "            \n",
    "    T,R,t,s_mean = best_fit_transform(A, src[0:3,:].T)\n",
    "    distances_iter=distances_iter[np.argwhere(distances_iter)]\n",
    "    src_1 = np.ones((4,A.shape[0]))  #(4, A.shape[0])\n",
    "    src_1[0:3,:] = np.copy(A.T)  # A.T shape (3,20)    \n",
    "    C = np.dot(T, src_1) # A transform\n",
    "    C =  C[0:3,:].T     \n",
    "\n",
    "#     fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "#     plt.plot(distances_iter[:20])\n",
    "#     sns.despine() \n",
    "#     plt.xlabel('Spots:'+ str(distances_iter[:20].shape[0]))\n",
    "#     plt.ylabel('Distance/pixel')\n",
    "#     ave=np.average(distances_iter[:20])\n",
    "#     plt.title(str(float('%.2f' % ave)))\n",
    "#     plt.show()\n",
    "    print(f'distance_iter:{distances_iter}')\n",
    "    return T,distances,C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_trackaffine_bash(segmentation1,segmentation2,ROI_fixed,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,\n",
    "                         threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,ransac_affine,global_affine_0,\n",
    "                         inv_affine_0,Transform_0,inv_Transform_0,Chn,global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots):\n",
    "    \"\"\"\n",
    "    default: apply DAPI channel to the FISH channels\n",
    "    \"\"\"\n",
    "    seg_dir = 'E:/Maxprobe_analysis/R2_R1_3tm50/'\n",
    "    fix_spacing=np.array([0.42,0.23,0.23])\n",
    "    mov_spacing=fix_spacing\n",
    "    min_radius=6\n",
    "    max_radius=12\n",
    "    cc_radius=cc_r # used for radius pixel of context information.\n",
    "    nspots=30000\n",
    "    num_sigma_max=6\n",
    "#     neighbor_radius0 = 12  # 12 : used to find nearest match spots for later local affine\n",
    "    neighbor_radius1 = 3    # 3 used to find nearest match spots in the validation \n",
    "    neighbor_radius2 = neighbor_radius1/3  # /3 used to for ICP\n",
    "#     image_ransac = 1 # >0 is to get point correspondences from image; or o is to find nearest neighbors\n",
    "    \n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    cc = [min(AA[0]),min(AA[1]),min(AA[2])]\n",
    "    BB=np.where(segmentation2==ROI_moving)\n",
    "    dd = [min(BB[0]),min(BB[1]),min(BB[2])]   \n",
    "    fix_ds = fixed_ROI\n",
    "    \n",
    "    # transform DAPI image\n",
    "    mov_affine_0 = transform.apply_global_affine(fix_ds, moving_ROI,fix_spacing, fix_spacing, global_affine_0,)\n",
    "    mov_ds = transform.apply_global_affine(fix_ds, mov_affine_0,fix_spacing, fix_spacing,Transform_0,) # inv_Transform_0\n",
    "#     print(global_affine_0)\n",
    "#     mov_affine_0 = scipy.ndimage.affine_transform(moving_ROI,np.linalg.inv(global_affine_0)) \n",
    "#     mov_ds = scipy.ndimage.affine_transform(mov_affine_0,np.linalg.inv(inv_Transform_0)) \n",
    "    \n",
    "    # if global_detection = 1, Adapt spots of ROI from hAirlocalize(um) or RS-FISH(pixel).\n",
    "    if global_detection > 0:\n",
    "        zoom=[2,4,4]\n",
    "        if hAir == 1:\n",
    "            # read spot data into memory as numpy arrays  Airlocolize spots data in xyz order: um\n",
    "            print(f'hAirlocalize points')\n",
    "            # find specific fixed roi\n",
    "            spotdir = seg_dir + 'hAir/R2_' + Chn + '_ROI.txt'\n",
    "            spot_fix=np.loadtxt(spotdir, delimiter=',')\n",
    "            fixed_spots1 = spot_fix[spot_fix[:,4] == ROI_fixed][:,:3]\n",
    "    #         print(fixed_spots1)\n",
    "            # find specific moving roi\n",
    "            spotdir = seg_dir + 'hAir/R1_' + Chn + '_ROI.txt'\n",
    "            spot_mov=np.loadtxt(spotdir, delimiter=',')\n",
    "            moving_spots1 = spot_mov[spot_mov[:,4] == ROI_moving][:,:3]       \n",
    "            # change to zyx order\n",
    "            fixed_spots11 = np.transpose(np.array([fixed_spots1[:,2],fixed_spots1[:,1],fixed_spots1[:,0]]))\n",
    "            moving_spots11 = np.transpose(np.array([moving_spots1[:,2],moving_spots1[:,1],moving_spots1[:,0]]))\n",
    "            # convert to physical units\n",
    "            ccc = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "            fix_spots = (fixed_spots11 - ccc * fix_spacing)\n",
    "            ddd = [min(BB[0])*zoom[0],min(BB[1])*zoom[1],min(BB[2])*zoom[2]]\n",
    "            mov_spots = (moving_spots11 - ddd * mov_spacing)\n",
    "           \n",
    "        else:\n",
    "        ##RS-FISH\n",
    "            print(f'RS-FISH points from cluster')\n",
    "            spotdir = seg_dir + 'RS-FISH/R2_' + Chn + '_ROI.txt'\n",
    "            spot_fix = np.loadtxt(spotdir, delimiter=',')\n",
    "            fixed_spots1 = spot_fix[spot_fix[:,4] == ROI_fixed][:,:3]\n",
    "#             print(fixed_spots1.shape)\n",
    "            spotdir = seg_dir + 'RS-FISH/R1_' + Chn + '_ROI.txt'\n",
    "            spot_mov = np.loadtxt(spotdir, delimiter=',')\n",
    "            moving_spots1 = spot_mov[spot_mov[:,4] == ROI_moving][:,:3] \n",
    "\n",
    "            fixed_spots11 = np.transpose(np.array([fixed_spots1[:,2],fixed_spots1[:,1],fixed_spots1[:,0]]))\n",
    "            moving_spots11 = np.transpose(np.array([moving_spots1[:,2],moving_spots1[:,1],moving_spots1[:,0]]))\n",
    "            # convert to physical units\n",
    "            ccc = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "            fix_spots = (fixed_spots11 - ccc * fix_spacing)\n",
    "            ddd = [min(BB[0])*zoom[0],min(BB[1])*zoom[1],min(BB[2])*zoom[2]]\n",
    "            mov_spots = (moving_spots11 - ddd * mov_spacing)\n",
    "\n",
    "    #         print(f'RS-FISH points from FIJI')\n",
    "    #         spotdir = seg_dir + 'R2_3tm50_1920/ICP_111_C3C1/5_R2_C3_0.txt'\n",
    "    #         spot_fix=np.loadtxt(spotdir, delimiter='\\t')\n",
    "    #         spotdir = seg_dir + 'R2_3tm50_1920/ICP_111_C3C1/5_R1_C3_1.txt'\n",
    "    #         spot_mov=np.loadtxt(spotdir, delimiter='\\t')\n",
    "    #         fixed_spots11 = np.transpose(np.array([spot_fix[:,2],spot_fix[:,1],spot_fix[:,0]]))\n",
    "    #         moving_spots11 = np.transpose(np.array([spot_mov[:,2],spot_mov[:,1],spot_mov[:,0]]))\n",
    "    #         fix_spots =  fixed_spots11* fix_spacing\n",
    "    #         mov_spots =  moving_spots11* fix_spacing\n",
    "        \n",
    "        mov_spots,_ = spots_random_shuffled(moving_ROI_c2,segmentation2,BB,ROI_moving,mov_spots,Shuffle_spots)\n",
    "        \n",
    "        ## apply dapi affine\n",
    "        mov_spots_x = mov_spots\n",
    "        points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine_0,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "#         warp_spots_1 = points.dot(inv_affine_0.T)\n",
    "        warp_spots_1 = points.dot(np.linalg.inv(inv_Transform).T)\n",
    "        \n",
    "        points = np.append(warp_spots_1[:,:3], np.ones((warp_spots_1.shape[0],1)), axis=1)\n",
    "#         mov_spots = points.dot(inv_Transform_0.T)\n",
    "        mov_spots = points.dot(np.linalg.inv(Transform_0.T))\n",
    "        \n",
    "        mov_spots = mov_spots[:,:3]\n",
    "        fix_spots_new = fix_spots\n",
    "        ns1 = fix_spots.shape[0]\n",
    "        ns2 = mov_spots.shape[0]    \n",
    "        print(f'FIXED: found {ns1} key points; MOVING: found {ns2} key points')  \n",
    "    else: \n",
    "        # get spots in pixels\n",
    "        print('Getting FISH spots from image: disabled now')\n",
    "         \n",
    "    # return fix_spots,mov_spots\n",
    "\n",
    "    # remove spots outside of segmenation_mini\n",
    "    # change spot location back to segmentation mask in pixels\n",
    "    fix_spots_new,_ = get_spot_inside(fix_spots,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "    spot_fix = fix_spots_new\n",
    "    mov_spots_new = mov_spots\n",
    "    # print('colocalization of all spots before ransac affine') \n",
    "    lipo_c0,lipo_c1,_,_,dist1,_,_ = colocalization(fix_spots_new,mov_spots_new,neighbor_radius1)  # return in pixel\n",
    "    print(f'pre-ransac_Distance: {np.mean(dist1)}')\n",
    "    \n",
    "    ######################### if no spot detected.\n",
    "    if ns1 >= 10 and ns2 >= 10:\n",
    "        fix_spots1,mov_spots1,_,_,_,_,_ = colocalization(fix_spots_new,mov_spots_new,neighbor_radius0)  # return in pixel\n",
    "        print(f'Found {fix_spots1.shape[0]} matched fixed points')\n",
    "        if ransac_affine == 0:\n",
    "            global_affine = np.eye(4)[:3]\n",
    "            inv_affine = np.eye(4)[:3]\n",
    "        else:\n",
    "            global_affine = ransac_align_points(fix_spots1, mov_spots1, align_threshold,)  \n",
    "            inv_affine = ransac_align_points(mov_spots1, fix_spots1, align_threshold,)\n",
    "\n",
    "        points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "#         warp_spots = points.dot(inv_affine.T)\n",
    "        warp_spots = points.dot(np.linalg.inv(inv_Transform).T)   \n",
    "        \n",
    "#         print('colocalization of inside spots after ransac affine') \n",
    "        spot_mov = warp_spots\n",
    "        lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(fix_spots_new,spot_mov,neighbor_radius1)  # return in pixel\n",
    "        print(f'ransac_Distance: {np.mean(eucldist(lipo_c0,lipo_c1))}')\n",
    " \n",
    "        # image_ransac = 1 is to get point correspondences from image; or 0 is to find nearest neighbors\n",
    "        if image_ransac != 0 and np.mean(eucldist(lipo_c0,lipo_c1)) > image_ransac:\n",
    "            \n",
    "            print(\"local matching again by correlation of intensities in images\")\n",
    "            fix_spots_img =features1.blob_detection(fix_ds, min_radius, max_radius,\n",
    "                num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "                threshold=threshold_fixed, exclude_border=cc_radius,)\n",
    "            mov_spots_img = features1.blob_detection(mov_ds, min_radius, max_radius,\n",
    "                num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "                threshold=threshold_moving, exclude_border=cc_radius,)\n",
    "            \n",
    "            sort_idx = np.argsort(fix_spots_img[:, 3])[::-1]\n",
    "            fix_spots_img = fix_spots_img[sort_idx, :3][:nspots]\n",
    "            sort_idx = np.argsort(mov_spots_img[:, 3])[::-1]\n",
    "            mov_spots_img = mov_spots_img[sort_idx, :3][:nspots]\n",
    "            # convert to physical units(um)\n",
    "            fix_spots_img = fix_spots_img* fix_spacing\n",
    "            mov_spots_img = mov_spots_img* mov_spacing\n",
    "            fix_spots_img,_ = get_spot_inside(fix_spots_img,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "            # get contexts\n",
    "            ns1 = fix_spots_img.shape[0]\n",
    "            ns2 = mov_spots_img.shape[0]  \n",
    "            print(f'FIXED image: found {ns1} key points; MOVING image: found {ns2} key points')\n",
    "            fix_spots0_img = features.get_spot_context(\n",
    "                fix_ds, fix_spots_img, fix_spacing, cc_r,)\n",
    "            mov_spots0_img = features.get_spot_context(\n",
    "                mov_ds, mov_spots_img, mov_spacing, cc_r,)\n",
    "            \n",
    "            correlations = features.pairwise_correlation(\n",
    "                fix_spots0_img, mov_spots0_img,)\n",
    "            fix_spots1_img, mov_spots1_img = features.match_points(\n",
    "                fix_spots0_img, mov_spots0_img,\n",
    "                correlations, match_threshold,)\n",
    "            print(f'Found {fix_spots1_img.shape[0]} matched fixed points')\n",
    "            if ransac_affine == 0:\n",
    "                global_affine = np.eye(4)[:3]\n",
    "                inv_affine = np.eye(4)[:3]\n",
    "            else:\n",
    "                global_affine = ransac_align_points(fix_spots1_img, mov_spots1_img, align_threshold,)  \n",
    "                inv_affine = ransac_align_points(mov_spots1_img, fix_spots1_img, align_threshold,)\n",
    "            \n",
    "            warp_spots = []\n",
    "            points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "            inv_Transform = np.row_stack((global_affine,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "    #         warp_spots = points.dot(inv_affine.T)\n",
    "            warp_spots = points.dot(np.linalg.inv(inv_Transform).T)   \n",
    "            \n",
    "    #         print('colocalization of inside spots after ransac affine')\n",
    "            spot_mov = []\n",
    "            spot_mov = warp_spots\n",
    "            lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(fix_spots_new,spot_mov,neighbor_radius1)  # return in pixel\n",
    "            print(f'ransac_Distance_again: {np.mean(eucldist(lipo_c0,lipo_c1))}')\n",
    "                \n",
    "#         print('registration of all inside spots with ICP')\n",
    "#         A = spot_fix[:,:3]\n",
    "#         B = spot_mov[:,:3]\n",
    "# #         Transform, distances1,C = icp(A, B,neighbor_radius2)\n",
    "#         inv_Transform, distances2,C = icp(B, A,neighbor_radius2)\n",
    "#     #     print (Transform)\n",
    "#         # functions for applying transforms are in bigstream.transform. apply the ICP affine to the moved image\n",
    "#         ICP_affine = transform.apply_global_affine(\n",
    "#             fix_ds, mov_affine,\n",
    "#             fix_spacing, fix_spacing,\n",
    "#             Transform,)\n",
    "#         #     print (inv_Transform)\n",
    "#         p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "#         C = p.dot(inv_Transform.T)\n",
    "        \n",
    "        A = spot_fix[:,:3]\n",
    "        B = spot_mov[:,:3]\n",
    "        return A, B,neighbor_radius2\n",
    "    \n",
    "#         Transform,_,_ = icp(A, B,neighbor_radius2)\n",
    "        \n",
    "    \n",
    "#         # A->B \n",
    "#         inv_Transform, distances2, _ = icp(B, A,neighbor_radius2) # B->A\n",
    "#         Transform[np.isnan(Transform)] = 0\n",
    "#         inv_Transform[np.isnan(inv_Transform)] = 0\n",
    "#         p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "#         D = p.dot(np.linalg.inv(Transform).T)        ## B->A spots (right) with B->A transform (right)\n",
    "# #         ICP_affine = scipy.ndimage.affine_transform(mov_affine,np.linalg.inv(inv_Transform)) \n",
    "#         C = D[:,:3]\n",
    "        \n",
    "#         # Test ICP distance change. Minor increased performance\n",
    "#         warp_spots_new,_ = get_spot_inside(C,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#         spot_mov = warp_spots_new\n",
    "#         lipo_c0,lipo_c1,_,_,dist3,P1,P2 = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#         print('% P1: ',str(P1) + ';  % P2: ',str(P2))\n",
    "#         pair_dist = eucldist(lipo_c0,lipo_c1)\n",
    "#         print(f'ICP_Distance: {np.mean(pair_dist)}')\n",
    "        \n",
    "#         # functions for images\n",
    "# #         if image_ransac > 0:\n",
    "#     else:\n",
    "#         print(f'Not found enough matched fixed points')\n",
    "#         global_affine = np.eye(4)[:3]    \n",
    "#         inv_affine = np.eye(4)[:3]\n",
    "#         warp_spots = mov_spots\n",
    "#         lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(spot_fix,warp_spots,neighbor_radius1)  # return in pixel\n",
    "# #         print(f'Distance: {np.mean(cloud_distance(spot_fix,spot_mov))}')\n",
    "#         Transform = np.eye(4)[:4]\n",
    "#         inv_Transform = np.eye(4)[:4]\n",
    "#         C = warp_spots[:,:3]\n",
    "#         warp_spots_new,_ = get_spot_inside(C,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#         spot_mov = warp_spots_new\n",
    "#         lipo_c0,lipo_c1,_,_,dist3,P1,P2 = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#         print('% P1: ',str(P1) + ';  % P2: ',str(P2)) \n",
    "#         pair_dist = eucldist(lipo_c0,lipo_c1)\n",
    "#         print(f'ICP_Distance: {np.mean(pair_dist)}')\n",
    "    \n",
    "#     if Chn == \"C3\":\n",
    "#         # bleedthrough correction \n",
    "#         lo = np.percentile(np.ndarray.flatten(moving_ROI_c2),99.5) #Estimate fluorescence intensity of bright DAPI signals\n",
    "#         bg_dapi=np.percentile(np.ndarray.flatten(moving_ROI_c2[moving_ROI_c2!=0]),1) \n",
    "#         bg_data=np.percentile(np.ndarray.flatten(moving_ROI[moving_ROI!=0]),1) #Estimate background in AF546 channel\n",
    "#         dapi_factor=np.median((moving_ROI[moving_ROI_c2>lo] - bg_data)/(moving_ROI_c2[moving_ROI_c2>lo] - bg_dapi)) #Estimate % of signal bleedthrough\n",
    "#         moving_ROI_new  = np.maximum(0, moving_ROI - bg_data - dapi_factor * (moving_ROI_c2 - bg_dapi)).astype('float32')#subtract background and bleedthrough\n",
    "#         mov_affine_0 = transform.apply_global_affine(fix_ds, moving_ROI_new,fix_spacing, fix_spacing,global_affine_0,)\n",
    "#         mov_ds = transform.apply_global_affine(fix_ds, mov_affine_0,fix_spacing,fix_spacing,Transform_0,)  \n",
    "        \n",
    "# #     mov_affine = scipy.ndimage.affine_transform(mov_ds,np.linalg.inv(global_affine))\n",
    "# #     ICP_affine = scipy.ndimage.affine_transform(mov_affine,np.linalg.inv(inv_Transform)) \n",
    "#     mov_affine = transform.apply_global_affine(fix_ds, mov_ds, fix_spacing, fix_spacing,global_affine,)\n",
    "#     ICP_affine = transform.apply_global_affine(fix_ds, mov_affine, fix_spacing, fix_spacing,Transform,) \n",
    "\n",
    "#     return P1,P2,dist1,dist2,pair_dist,spot_fix,mov_spots,warp_spots_new,ICP_affine,mov_affine,cc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_trackaffine_cca_bash(segmentation1,segmentation2,ROI_fixed,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,\n",
    "                         threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,ransac_affine,\n",
    "                         global_affine_fix,inv_affine_fix,Transform_fix,global_affine_mov,inv_affine_mov,\n",
    "                        Transform_mov,global_affine_0,inv_affine_0,Transform_0,inv_Transform_0,Chn,global_detection,\n",
    "                         image_ransac,hAir,neighbor_radius0,Shuffle_spots):\n",
    "    \"\"\"\n",
    "    1.Transform the affine matrix to correct chromatic aberration of two tracks for each rounds. fix and moving. C0 C1\n",
    "    points: points.dot(inv_Transform_0.T)\n",
    "    images: transform.apply_global_affine\n",
    "    2.Transform the DAPI affine matrix: points and images. \n",
    "    3.Do ROI-affine\n",
    "    \n",
    "    default: apply DAPI channel affine matrix to the FISH channels\n",
    "    \"\"\"\n",
    "    seg_dir = 'E:/Maxprobe_analysis/R2_R1_3tm50/'\n",
    "    fix_spacing=np.array([0.42,0.23,0.23])\n",
    "    mov_spacing=fix_spacing\n",
    "    min_radius=6\n",
    "    max_radius=12\n",
    "    cc_radius=cc_r # used for radius pixel of context information.\n",
    "    nspots=30000\n",
    "    num_sigma_max=6\n",
    "#     neighbor_radius0 = 12  # 12 : used to find nearest match spots for later local affine\n",
    "    neighbor_radius1 = 3    # 3 used to find nearest match spots in the validation \n",
    "    neighbor_radius2 = neighbor_radius1/3  # /3 used to for ICP\n",
    "#     image_ransac = 1 # >0 is to get point correspondences from image; or o is to find nearest neighbors\n",
    "    \n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    cc = [min(AA[0]),min(AA[1]),min(AA[2])]\n",
    "    BB=np.where(segmentation2==ROI_moving)\n",
    "    dd = [min(BB[0]),min(BB[1]),min(BB[2])]\n",
    "    \n",
    "    \n",
    "    # transform cca for fixed images\n",
    "#     fix_ds = fixed_ROI\n",
    "    fix_affine_0 = transform.apply_global_affine(fixed_ROI,fixed_ROI,fix_spacing, fix_spacing, global_affine_fix,)\n",
    "    fix_ds = transform.apply_global_affine(fixed_ROI, fix_affine_0,fix_spacing, fix_spacing,Transform_fix,)\n",
    "#     fix_affine_0  = scipy.ndimage.affine_transform(fixed_ROI,np.linalg.inv(global_affine_fix)) \n",
    "#     fix_ds = scipy.ndimage.affine_transform(fix_affine_0 ,np.linalg.inv(inv_Transform_fix)) \n",
    "    \n",
    "    # transform cca and DAPI affine for moving images\n",
    "    mov_affine_cca = transform.apply_global_affine(moving_ROI,moving_ROI,fix_spacing, fix_spacing, global_affine_mov,)\n",
    "    mov_ds_cca = transform.apply_global_affine(moving_ROI, mov_affine_cca,fix_spacing, fix_spacing,Transform_mov,)\n",
    "#     mov_affine_cca  = scipy.ndimage.affine_transform(moving_ROI,np.linalg.inv(global_affine_mov)) \n",
    "#     mov_ds_cca = scipy.ndimage.affine_transform(mov_affine_cca,np.linalg.inv(inv_Transform_mov))     \n",
    "    # need to export and check colocalization\n",
    "    mov_affine_0 = transform.apply_global_affine(fix_ds, mov_ds_cca,fix_spacing, fix_spacing, global_affine_0,)\n",
    "    mov_ds = transform.apply_global_affine(fix_ds, mov_affine_0,fix_spacing, fix_spacing,Transform_0,)\n",
    "#     mov_affine_0  = scipy.ndimage.affine_transform(mov_ds_cca,np.linalg.inv(global_affine_0)) \n",
    "#     mov_ds = scipy.ndimage.affine_transform(mov_affine_0,np.linalg.inv(Transform_0)) \n",
    "    \n",
    "    # if global_detection = 1, Adapt spots of ROI from hAirlocalize(um) or RS-FISH(pixel).\n",
    "    if global_detection > 0:\n",
    "        zoom=[2,4,4]\n",
    "        if hAir == 1:\n",
    "            # read spot data into memory as numpy arrays  Airlocolize spots data in xyz order: um\n",
    "            print(f'hAirlocalize points')\n",
    "            spotdir1 = seg_dir + 'hAir/R2_' + Chn + '_ROI.txt'\n",
    "            spotdir2 = seg_dir + 'hAir/R1_' + Chn + '_ROI.txt'\n",
    "        else:\n",
    "            ##RS-FISH\n",
    "            print(f'RS-FISH points from cluster')\n",
    "            spotdir1 = seg_dir + 'RS-FISH/R2_' + Chn + '_ROI.txt'\n",
    "            spotdir2 = seg_dir + 'RS-FISH/R1_' + Chn + '_ROI.txt'\n",
    "\n",
    "        spot_fix=np.loadtxt(spotdir1, delimiter=',')\n",
    "        fixed_spots1 = spot_fix[spot_fix[:,4] == ROI_fixed][:,:3]\n",
    "        # find specific moving roi\n",
    "        spot_mov=np.loadtxt(spotdir2, delimiter=',')\n",
    "        moving_spots1 = spot_mov[spot_mov[:,4] == ROI_moving][:,:3]       \n",
    "        # change to zyx order\n",
    "        fixed_spots11 = np.transpose(np.array([fixed_spots1[:,2],fixed_spots1[:,1],fixed_spots1[:,0]]))\n",
    "        moving_spots11 = np.transpose(np.array([moving_spots1[:,2],moving_spots1[:,1],moving_spots1[:,0]]))\n",
    "        # convert to physical units\n",
    "        ccc = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "        fix_spots = (fixed_spots11 - ccc * fix_spacing)\n",
    "        ddd = [min(BB[0])*zoom[0],min(BB[1])*zoom[1],min(BB[2])*zoom[2]]\n",
    "        mov_spots = (moving_spots11 - ddd * mov_spacing)\n",
    "        \n",
    "        ########################################################################\n",
    "        ## apply cca affine for fix spots\n",
    "        \n",
    "        points1 = np.append(fix_spots, np.ones((fix_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine_fix,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "        warp_spots_1 = points1.dot(np.linalg.inv(inv_Transform).T)[:,:3] \n",
    "        points2 = np.append(warp_spots_1, np.ones((warp_spots_1.shape[0],1)), axis=1)\n",
    "        fix_spots = points2.dot(np.linalg.inv(Transform_fix).T)\n",
    "        fix_spots = fix_spots[:,:3]\n",
    "        \n",
    "        ## apply cca affine for mov spots\n",
    "        points2 = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine_mov,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "        warp_spots_2 = points2.dot(np.linalg.inv(inv_Transform).T)[:,:3]\n",
    "        points2 = np.append(warp_spots_2, np.ones((warp_spots_2.shape[0],1)), axis=1)\n",
    "        mov_spots_x = points2.dot(np.linalg.inv(Transform_mov).T)\n",
    "        mov_spots_x = mov_spots_x[:,:3]\n",
    "        ## apply dapi affine for mov \n",
    "        points3 = np.append(mov_spots_x, np.ones((mov_spots_x.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine_0,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "        warp_spots_3 = points3.dot(np.linalg.inv(inv_Transform).T)[:,:3]\n",
    "        points3 = np.append(warp_spots_3, np.ones((warp_spots_3.shape[0],1)), axis=1)\n",
    "        mov_spots = points3.dot(np.linalg.inv(Transform_0.T))\n",
    "        mov_spots = mov_spots[:,:3]\n",
    "        \n",
    "        ns1 = fix_spots.shape[0]\n",
    "        ns2 = mov_spots.shape[0]    \n",
    "        print(f'FIXED: found {ns1} key points; MOVING: found {ns2} key points')  \n",
    "    else: \n",
    "        # get spots in pixels\n",
    "        print('Getting FISH spots from image: disabled now')\n",
    "    \n",
    "    mov_spots,_ = spots_random_shuffled(moving_ROI_c2,segmentation2,BB,ROI_moving,mov_spots,Shuffle_spots)\n",
    "    \n",
    "    # remove spots outside of segmenation_mini\n",
    "    # change spot location back to segmentation mask in pixels\n",
    "    fix_spots_new,_ = get_spot_inside(fix_spots,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "    spot_fix = fix_spots_new\n",
    "    mov_spots_new = mov_spots\n",
    "    # print('colocalization of all spots before ransac affine') \n",
    "    lipo_c0,lipo_c1,_,_,dist1,_,_ = colocalization(fix_spots_new,mov_spots_new,neighbor_radius1)  # return in pixel\n",
    "    print(f'pre-ransac_Distance: {np.mean(dist1)}')\n",
    "    \n",
    "    ######################### if no spot detected.\n",
    "    if ns1 >= 10 and ns2 >= 10:\n",
    "        fix_spots1,mov_spots1,_,_,_,_,_ = colocalization(fix_spots_new,mov_spots_new,neighbor_radius0)  # return in pixel\n",
    "        print(f'Found {fix_spots1.shape[0]} matched fixed points')\n",
    "        if ransac_affine == 0:\n",
    "            global_affine = np.eye(4)[:3]\n",
    "            inv_affine = np.eye(4)[:3]\n",
    "        else:\n",
    "            global_affine = ransac_align_points(fix_spots1, mov_spots1, align_threshold,)  \n",
    "            inv_affine = ransac_align_points(mov_spots1, fix_spots1, align_threshold,)\n",
    "\n",
    "        points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine,np.array([[0,0,0,1]]))) #FIX->FIX_reg  \n",
    "        warp_spots = points.dot(np.linalg.inv(inv_Transform).T)\n",
    "#         print('colocalization of inside spots after ransac affine') \n",
    "        spot_mov = warp_spots\n",
    "        lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(fix_spots_new,spot_mov,neighbor_radius1)  # return in pixel\n",
    "        print(f'ransac_Distance: {np.mean(eucldist(lipo_c0,lipo_c1))}')\n",
    " \n",
    "        # image_ransac = 1 is to get point correspondences from image; or 0 is to find nearest neighbors\n",
    "        if image_ransac != 0 and np.mean(eucldist(lipo_c0,lipo_c1)) > image_ransac:\n",
    "            \n",
    "            print(\"local matching again by correlation of intensities in images\")\n",
    "            fix_spots_img =features1.blob_detection(fix_ds, min_radius, max_radius,\n",
    "                num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "                threshold=threshold_fixed, exclude_border=cc_radius,)\n",
    "            mov_spots_img = features1.blob_detection(mov_ds, min_radius, max_radius,\n",
    "                num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "                threshold=threshold_moving, exclude_border=cc_radius,)\n",
    "            \n",
    "            sort_idx = np.argsort(fix_spots_img[:, 3])[::-1]\n",
    "            fix_spots_img = fix_spots_img[sort_idx, :3][:nspots]\n",
    "            sort_idx = np.argsort(mov_spots_img[:, 3])[::-1]\n",
    "            mov_spots_img = mov_spots_img[sort_idx, :3][:nspots]\n",
    "            # convert to physical units(um)\n",
    "            fix_spots_img = fix_spots_img* fix_spacing\n",
    "            mov_spots_img = mov_spots_img* mov_spacing\n",
    "            fix_spots_img,_ = get_spot_inside(fix_spots_img,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#             mov_spots_new1 = get_spot_inside(mov_spots,segmentation2,fix_spacing,ROI_fixed,cc) ## avoid no features\n",
    "            # get contexts\n",
    "            ns1 = fix_spots_img.shape[0]\n",
    "            ns2 = mov_spots_img.shape[0]  \n",
    "            print(f'FIXED image: found {ns1} key points; MOVING image: found {ns2} key points')\n",
    "            fix_spots0_img = features.get_spot_context(\n",
    "                fix_ds, fix_spots_img, fix_spacing, cc_r,)\n",
    "            mov_spots0_img = features.get_spot_context(\n",
    "                mov_ds, mov_spots_img, mov_spacing, cc_r,)\n",
    "            \n",
    "            correlations = features.pairwise_correlation(\n",
    "                fix_spots0_img, mov_spots0_img,)\n",
    "            fix_spots1_img, mov_spots1_img = features.match_points(\n",
    "                fix_spots0_img, mov_spots0_img,\n",
    "                correlations, match_threshold,)\n",
    "            print(f'Found {fix_spots1_img.shape[0]} matched fixed points')\n",
    "            if ransac_affine == 0:\n",
    "                global_affine = np.eye(4)[:3]\n",
    "                inv_affine = np.eye(4)[:3]\n",
    "            else:\n",
    "                global_affine = ransac_align_points(fix_spots1_img, mov_spots1_img, align_threshold,)  \n",
    "                inv_affine = ransac_align_points(mov_spots1_img, fix_spots1_img, align_threshold,)\n",
    "            \n",
    "            points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "            inv_Transform = np.row_stack((global_affine,np.array([[0,0,0,1]]))) #FIX->FIX_reg  \n",
    "            warp_spots = points.dot(np.linalg.inv(inv_Transform).T)\n",
    "    #         print('colocalization of inside spots after ransac affine') \n",
    "            spot_mov = warp_spots\n",
    "            lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(fix_spots_new,spot_mov,neighbor_radius1)  # return in pixel\n",
    "            print(f'ransac_Distance_again: {np.mean(eucldist(lipo_c0,lipo_c1))}')\n",
    "                \n",
    "        A = fix_spots_new[:,:3]\n",
    "        B = spot_mov[:,:3]\n",
    "        Transform,_,_ = icp(A, B,neighbor_radius2)  # A->B \n",
    "        return A, B,neighbor_radius2\n",
    "    \n",
    "#         inv_Transform, distances2, _ = icp(B, A,neighbor_radius2) # B->A \n",
    "#         p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "#         D = p.dot(np.linalg.inv(Transform).T)        ## B->A spots (right) with B->A transform (right)\n",
    "# #         ICP_affine = scipy.ndimage.affine_transform(mov_affine,np.linalg.inv(inv_Transform)) \n",
    "#         C = D[:,:3]\n",
    "        \n",
    "#         # Test ICP distance change. Minor increased performance\n",
    "#         warp_spots_new,_ = get_spot_inside(C,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#         spot_mov = warp_spots_new\n",
    "#         lipo_c0,lipo_c1,_,_,dist3,P1,P2 = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#         print('% P1: ',str(P1) + ';  % P2: ',str(P2))\n",
    "#         pair_dist = eucldist(lipo_c0,lipo_c1)\n",
    "#         print(f'ICP_Distance: {np.mean(pair_dist)}')\n",
    "        \n",
    "#         # functions for images\n",
    "# #         if image_ransac > 0:\n",
    "#     else:\n",
    "#         print(f'Not found enough matched fixed points')\n",
    "#         global_affine = np.eye(4)[:3]    \n",
    "#         inv_affine = np.eye(4)[:3]\n",
    "#         warp_spots = mov_spots\n",
    "#         lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(spot_fix,warp_spots,neighbor_radius1)  # return in pixel\n",
    "# #         print(f'Distance: {np.mean(cloud_distance(spot_fix,spot_mov))}')\n",
    "#         Transform = np.eye(4)[:4]\n",
    "#         inv_Transform = np.eye(4)[:4]\n",
    "#         C = warp_spots[:,:3]\n",
    "#         warp_spots_new,_ = get_spot_inside(C,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#         spot_mov = warp_spots_new\n",
    "#         lipo_c0,lipo_c1,_,_,dist3,P1,P2 = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#         print('% P1: ',str(P1) + ';  % P2: ',str(P2)) \n",
    "#         pair_dist = eucldist(lipo_c0,lipo_c1)\n",
    "#         print(f'ICP_Distance: {np.mean(pair_dist)}')\n",
    "    \n",
    "#     if Chn == \"C3\":\n",
    "#         # bleedthrough correction \n",
    "#         lo = np.percentile(np.ndarray.flatten(moving_ROI_c2),99.5) #Estimate fluorescence intensity of bright DAPI signals\n",
    "#         bg_dapi=np.percentile(np.ndarray.flatten(moving_ROI_c2[moving_ROI_c2!=0]),1) \n",
    "#         bg_data=np.percentile(np.ndarray.flatten(moving_ROI[moving_ROI!=0]),1) #Estimate background in AF546 channel\n",
    "#         dapi_factor=np.median((moving_ROI[moving_ROI_c2>lo] - bg_data)/(moving_ROI_c2[moving_ROI_c2>lo] - bg_dapi)) #Estimate % of signal bleedthrough\n",
    "#         moving_ROI_new  = np.maximum(0, moving_ROI - bg_data - dapi_factor * (moving_ROI_c2 - bg_dapi)).astype('float32')#subtract background and bleedthrough\n",
    "#         mov_affine_0 = transform.apply_global_affine(fix_ds, moving_ROI_new,fix_spacing, fix_spacing,global_affine_0,)\n",
    "#         mov_ds = transform.apply_global_affine(fix_ds, mov_affine_0,fix_spacing,fix_spacing,Transform_0,)\n",
    "        \n",
    "# #     mov_affine = scipy.ndimage.affine_transform(mov_ds,np.linalg.inv(global_affine)) \n",
    "#     mov_affine = transform.apply_global_affine(fix_ds, mov_ds, fix_spacing, fix_spacing,global_affine,)\n",
    "#     ICP_affine = transform.apply_global_affine(fix_ds, mov_affine, fix_spacing, fix_spacing,Transform,) \n",
    "# #     ICP_affine = scipy.ndimage.affine_transform(mov_affine,np.linalg.inv(invTransform)) \n",
    "    \n",
    "#     return P1,P2,dist1,dist2,pair_dist,spot_fix,mov_spots,warp_spots_new,fix_ds,ICP_affine,mov_affine,cc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the raw images and segmented ROIs (registered)\n",
    "We load the images of 2 channels of two rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\FISH\\lib\\site-packages\\z5py\\file.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, use_zarr_format, dimension_separator)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEROFS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEROFS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;31m# if we don't have the file, create it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0m_z5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_zarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # file paths to bigstrem REGISTERED data N5 files(include deform)\n",
    "# create Zarr file object using N5Stores\n",
    "seg_dir='E:/Maxprobe_analysis/R2_R1_3tm50/' # Analyze the below images ## image is in zyx or\n",
    "im_fixed = z5py.File(seg_dir + 'R2_3tm50_1920/stitching/export.n5', use_zarr_format=False)\n",
    "im_moving = z5py.File(seg_dir + 'R1_3tm50_1920/stitching/export.n5', use_zarr_format=False)\n",
    "\n",
    "# # UNREGISTERED of two rounds\n",
    "segmentation1=imread(seg_dir + 'R2_filtered_mask.tif')\n",
    "# # Registered and enlarged ROI\n",
    "segmentation2=imread(seg_dir + 'R1_filtered_mask.tif')\n",
    "# viewer.add_image(segmentation1,colormap='green',blending='additive') #load image data into napari\n",
    "# viewer.add_image(segmentation2,colormap='red',blending='additive') #load image data into napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign_roi_images\n",
    "#### need to load big raw images for each tile if using distributed computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# t = time()\n",
    "En_pixels = 0\n",
    "tile_number = 5\n",
    "out_dir = seg_dir +'R1_3tm50_1920/registration/python/tiles/'\n",
    "fix_path = seg_dir + 'R2_3tm50_1920/ROI/'\n",
    "roi_dir = seg_dir + 'allroi_matched.csv'   # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "# assign_roi_images(tile_number,fix_path,out_dir,seg_dir,roi_dir,segmentation1,segmentation2,En_pixels)\n",
    "# print('tictoc：%.2fs' % (time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI_affine with image assisted cca on the true or shuffled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/Maxprobe_analysis/R2_R1_3tm50/allroi_matched.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\FISH\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\FISH\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\FISH\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\FISH\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\FISH\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1219\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\FISH\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/Maxprobe_analysis/R2_R1_3tm50/allroi_matched.csv'"
     ]
    }
   ],
   "source": [
    "%%time  \n",
    "#time: 60 images, 60 s for 4 images (c0-c3) if apply image ransac,40 s for 4 images (c0-c3) if not.\n",
    "tile_number = 5 #35\n",
    "seg_dir='E:/Maxprobe_analysis/R2_R1_3tm50/'\n",
    "roi_dir = seg_dir + 'allroi_matched.csv'   # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "df_allroi = pd.read_csv(roi_dir)\n",
    "spot_fix_c3_all = np.zeros((1, 4))\n",
    "warp_spots_c3_all = np.zeros((1, 4))\n",
    "spot_fix_c1_all = np.zeros((1, 4))\n",
    "warp_spots_c1_all = np.zeros((1, 4))\n",
    "spot_fix_c0_all = np.zeros((1, 4))\n",
    "warp_spots_c0_all = np.zeros((1, 4))\n",
    "fix_spacing=np.array([0.42,0.23,0.23])\n",
    "j=0\n",
    "Dist_sum_1 = np.zeros((len(df_allroi['fix']), 14)) # directory to file containing the registration stats\n",
    "affine_borrow = np.zeros((len(df_allroi['fix']), 6))\n",
    "# Dist_sum_1 = np.zeros((len(gad1_list), 14)) # when apply for GAD1 cells.\n",
    "# affine_borrow = np.zeros((len(gad1_list), 6))\n",
    "Shuffle_spots = 0\n",
    "\n",
    "for i in range(0, tile_number): # distributed\n",
    "#     i = 0\n",
    "#     seg_dir1='E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/segmentation/'\n",
    "#     segmentation1=imread(seg_dir+'mask_all_R2.tif')\n",
    "#     seg_dir='E:/Maxprobe_analysis/R2_R1_3tm50/copytostephan/'\n",
    "#     segmentation2=imread(seg_dir+'mask_all_R1.tif') # Before bigstream\n",
    "    roi_dir = seg_dir + 'allroi_matched.csv'       # directory to file containing the ROI correspondence\n",
    "    df_allroi = pd.read_csv(roi_dir)\n",
    "    fix3_path = seg_dir + 'R2_3tm50_1920/ROI/'\n",
    "    ROI_RGB_path = seg_dir + 'R2_3tm50_1920/ROI_RGB/'\n",
    "    if not os.path.exists(ROI_RGB_path): os.mkdir(ROI_RGB_path)\n",
    "    roi_dir = fix3_path + str(i) + '/ROI_id.csv'   # directory to file containing the ROI correspondence of single tile\n",
    "    df_tile_roi = pd.read_csv(roi_dir)\n",
    "    ROI_id = df_tile_roi['fix'].astype(int)\n",
    "#     ROI_id = ROI_all[roi_inc*i:(i+1)*roi_inc]\n",
    "    \n",
    "    for aa in ROI_id:\n",
    "#         if aa in gad1_list: # < 1106\n",
    "        if aa == 5: #81 c2 529 for shuffle?\n",
    "            roi_dir = fix3_path + str(i) + '/R2_' + str(aa) + '_C2.tif'\n",
    "            fixed_ROI_c2 = imread(roi_dir)\n",
    "#             ROI_moving = df_allroi.loc[df_allroi['fix'].astype(int) == aa]['mov'].values[0].astype(int) #379\n",
    "            ROI_moving = aa\n",
    "            print('ROI_fix: ' + str(aa) + '; ROI_moving: ' + str(ROI_moving))\n",
    "            roi_dir = fix3_path + str(i) + '/R1_' + str(ROI_moving) + '_C2.tif'\n",
    "            moving_ROI_c2 = imread(roi_dir)\n",
    "\n",
    "            #for dapi: ~50 blobs can be detected\n",
    "            print(\"DAPI\")\n",
    "            threshold_fixed=0.001/50 #/50\n",
    "            threshold_moving=0.001/5 #/5\n",
    "            cc_r=12 \n",
    "            match_threshold=0.6  #0.7\n",
    "            align_threshold=0.5\n",
    "            Global_detection = 0\n",
    "            image_ransac = 1 # 1 is to get point correspondences from image; or 0 is to use nearest neighbors for local ransac\n",
    "            P1_C2,P2_C2,_,_,distances_2,global_affine2,inv_affine2,Transform2,inv_Transform2,fix_spots_2,mov_spots_2,warp_spots_new_2,ICP_affine_2,cc_2 = ROI_affine_bash(\n",
    "            segmentation1,segmentation2,aa,ROI_moving,fixed_ROI_c2,moving_ROI_c2,threshold_fixed,threshold_moving,\n",
    "            cc_r,match_threshold,align_threshold,Global_detection,image_ransac)\n",
    "            \n",
    "            a_rgb = np.zeros(fixed_ROI_c2.shape + (4,))\n",
    "            a_rgb[..., 0] = fixed_ROI_c2.astype(np.uint16)\n",
    "            a_rgb[..., 1] = ICP_affine_2.astype(np.uint16)\n",
    "            \n",
    "            Global_detection = 1\n",
    "            ransac_affine = 1 ## 1 is to apply local ransac affine (not use image) before ICP,0 is used orginal point cloud for ICP.\n",
    "#             image_ransac = 1 # > 0 is to get point correspondences from image after using nearest neighbors ; or 0 is to use nearest neighbors for local ransac\n",
    "            hAir = 0 # 0 is RS-FISH; 1 is for hAirlocalize\n",
    "            # find affine for cca\n",
    "            spotdir = seg_dir + 'R2ROI_points_fix.txt'\n",
    "            Rounds = [\"R2\",\"R1\"]\n",
    "            global_affine_fix,inv_affine_fix,Transform_fix,global_affine_mov,inv_affine_mov,Transform_mov,affine_borrow_idx = cca(\n",
    "                seg_dir,spotdir,aa,Rounds) \n",
    "\n",
    "            for Chn in [\"C3\"]: # [\"C1\",\"C3\",\"C0\"]\n",
    "#                 Chn = \"C3\"\n",
    "                print(Chn)\n",
    "                roi_dir = fix3_path + str(i) + '/R2_' + str(aa) + '_'+ Chn + '.tif'\n",
    "                fixed_ROI = imread(roi_dir)\n",
    "                roi_dir = fix3_path + str(i) + '/R1_' + str(ROI_moving) + '_'+ Chn + '.tif'\n",
    "                moving_ROI = imread(roi_dir)\n",
    "                # save rgb images \n",
    "                if Chn == \"C1\":\n",
    "                    #for c1\n",
    "                    threshold_fixed=0.001/20 #/20\n",
    "                    threshold_moving=0.001/2 #/2\n",
    "                    match_threshold=0.5  #0.5\n",
    "                    align_threshold=0.5  # 0.5\n",
    "                    neighbor_radius0 = 12\n",
    "                    image_ransac = 1 # number is specific distance threshold\n",
    "                    P1_C1,P2_C1,_,_,pair_dist_1, fix_spots_1,mov_spots_1,warp_spots_new_1,fixed_ROI_c1,ICP_affine_1,moving_affine_1,cc_1 = ROI_trackaffine_cca_bash(\n",
    "                        segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,\n",
    "                        cc_r,match_threshold,align_threshold,ransac_affine,global_affine_fix,inv_affine_fix,Transform_fix,\n",
    "                        global_affine_mov,inv_affine_mov,Transform_mov,global_affine2,inv_affine2,Transform2,inv_Transform2,\n",
    "                        Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "                    \n",
    "                    distances_1 = np.mean(pair_dist_1)                   \n",
    "                    a_rgb[..., 2] = fixed_ROI_c1.astype(np.uint16)\n",
    "                    a_rgb[..., 3] = ICP_affine_1.astype(np.uint16)\n",
    "#                     a_rgb[..., 3] = moving_affine_1.astype(np.uint16)\n",
    "                    roi_dir = ROI_RGB_path + '/'+ str(aa) + '_' + 'C2' + Chn +'.tif'\n",
    "                    imsave(roi_dir, a_rgb)\n",
    "                    a_rgb = []\n",
    "\n",
    "                elif Chn == \"C3\":\n",
    "                    #for c3\n",
    "                    \n",
    "                    threshold_fixed=0.001/8 #/4\n",
    "                    threshold_moving=0.001/4 #/2\n",
    "                    match_threshold=0.5  #0.7\n",
    "                    align_threshold=0.5\n",
    "                    image_ransac = 1 # number is specific distance threshold \n",
    "                    neighbor_radius0 = 12\n",
    "                    P1_C3,P2_C3,dist1,dist2,pair_dist_3,fix_spots_3,mov_spots_3,warp_spots_new_3,ICP_affine_3,moving_affine_3,cc_3 = ROI_trackaffine_bash(\n",
    "                    segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "                    ransac_affine,global_affine2,inv_affine2,Transform2,inv_Transform2,Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "         \n",
    "                    distances_3 = np.mean(pair_dist_3)\n",
    "                    lo=np.percentile(np.ndarray.flatten(fixed_ROI_c2),99.5) #Estimate fluorescence intensity of bright DAPI signals\n",
    "                    bg_dapi=np.percentile(np.ndarray.flatten(fixed_ROI_c2[fixed_ROI_c2!=0]),1) \n",
    "                    bg_data=np.percentile(np.ndarray.flatten(fixed_ROI[fixed_ROI!=0]),1) #Estimate background in AF546 channel\n",
    "                    dapi_factor=np.median((fixed_ROI[fixed_ROI_c2>lo] - bg_data)/(fixed_ROI_c2[fixed_ROI_c2>lo] - bg_dapi)) #Estimate % of signal bleedthrough\n",
    "                    fixed_ROI  = np.maximum(0, fixed_ROI - bg_data - dapi_factor * (fixed_ROI_c2 -bg_dapi)).astype('float32')#subtract background and bleedthrough                   \n",
    "                    a_rgb = np.zeros(fixed_ROI.shape + (4,))\n",
    "                    a_rgb[..., 0] = fixed_ROI.astype(np.uint16)\n",
    "                    a_rgb[..., 1] = ICP_affine_3.astype(np.uint16)\n",
    "                    fixed_ROI_c3 = fixed_ROI\n",
    "                    \n",
    "                else:\n",
    "                    #for c0\n",
    "                    threshold_fixed=0.001/20 #/20\n",
    "                    threshold_moving=0.001/2 #/2\n",
    "                    match_threshold=0.5  #0.5\n",
    "                    align_threshold=0.5  #0.5\n",
    "                    image_ransac = 1 # number is specific distance threshold for non-dapi track\n",
    "                    neighbor_radius0 = 12\n",
    "                    P1_C0,P2_C0,_,_,pair_dist_0,fix_spots_0,mov_spots_0,warp_spots_new_0,fixed_ROI_c0,ICP_affine_0,moving_affine_0,cc_0 = ROI_trackaffine_cca_bash(\n",
    "                        segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,\n",
    "                        cc_r,match_threshold,align_threshold,ransac_affine,global_affine_fix,inv_affine_fix,Transform_fix,\n",
    "                        global_affine_mov,inv_affine_mov,Transform_mov,global_affine2,inv_affine2,Transform2,inv_Transform2,\n",
    "                        Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "             \n",
    "                    distances_0 = np.mean(pair_dist_0)\n",
    "                    a_rgb[..., 2] = fixed_ROI_c0.astype(np.uint16)\n",
    "                    a_rgb[..., 3] = ICP_affine_0.astype(np.uint16)\n",
    "#                     a_rgb[..., 3] = moving_affine_0.astype(np.uint16)\n",
    "                    roi_dir = ROI_RGB_path + '/'+ str(aa) + '_' + 'C3' + Chn +'.tif'\n",
    "                    imsave(roi_dir, a_rgb)\n",
    "                    a_rgb = []\n",
    "            stop\n",
    "            # save C3 spots, global affine, warp affine.        \n",
    "            spot_fix3 = fix_spots_3/fix_spacing + [2*cc_3[0],4*cc_3[1],4*cc_3[2]]  # pre:in um, post: in px[um to px + mask(0, in px)]\n",
    "            spot_fix_c3 = np.column_stack((spot_fix3,np.ones(len(spot_fix3)).dot(aa))) # add ROI_ID\n",
    "            spot_fix_c3_all = np.row_stack((spot_fix_c3_all,spot_fix_c3))   # for all ROIs\n",
    "            warp_spots_3 = warp_spots_new_3[:,:3]/fix_spacing + [2*cc_3[0],4*cc_3[1],4*cc_3[2]]  # in pixels of S2\n",
    "            warp_spots_new_c3 = np.column_stack((warp_spots_3,np.ones(len(warp_spots_new_3)).dot(aa)))\n",
    "            warp_spots_c3_all = np.row_stack((warp_spots_c3_all,warp_spots_new_c3))\n",
    "            \n",
    "            # save C1 spots, global affine, warp affine.\n",
    "            spot_fix1 = fix_spots_1/fix_spacing + [2*cc_1[0],4*cc_1[1],4*cc_1[2]]  # in phsical distance of S2\n",
    "            spot_fix_c1 = np.column_stack((spot_fix1,np.ones(len(spot_fix1)).dot(aa)))\n",
    "            spot_fix_c1_all = np.row_stack((spot_fix_c1_all,spot_fix_c1))\n",
    "            if warp_spots_new_1.shape[0] == 0:\n",
    "                warp_spots_c1_all = warp_spots_c1_all\n",
    "            else:\n",
    "                warp_spots_1 = warp_spots_new_1[:,:3]/fix_spacing + [2*cc_1[0],4*cc_1[1],4*cc_1[2]]  # in pixels of S2\n",
    "                warp_spots_new_c1 = np.column_stack((warp_spots_1,np.ones(len(warp_spots_new_1)).dot(aa)))\n",
    "                warp_spots_c1_all = np.row_stack((warp_spots_c1_all,warp_spots_new_c1))\n",
    "            \n",
    "            # save C0 spots, global affine, warp affine.\n",
    "            spot_fix0 = fix_spots_0/fix_spacing + [2*cc_0[0],4*cc_0[1],4*cc_0[2]]  # in phsical distance of S2\n",
    "            spot_fix_c0 = np.column_stack((spot_fix0,np.ones(len(spot_fix0)).dot(aa)))\n",
    "            spot_fix_c0_all = np.row_stack((spot_fix_c0_all,spot_fix_c0))\n",
    "            warp_spots_0 = warp_spots_new_0[:,:3]/fix_spacing + [2*cc_0[0],4*cc_0[1],4*cc_0[2]]  # in pixels of S2\n",
    "            warp_spots_new_c0 = np.column_stack((warp_spots_0,np.ones(len(warp_spots_new_0)).dot(aa)))\n",
    "            warp_spots_c0_all = np.row_stack((warp_spots_c0_all,warp_spots_new_c0))\n",
    "            \n",
    "            affine_borrow[j,:] = affine_borrow_idx\n",
    "            # remember to remove the first 000 coordinates\n",
    "            Dist_sum_1[j,:] = [aa,ROI_moving,distances_0,P1_C0,P2_C0,\n",
    "                               distances_1,P1_C1,P2_C1,distances_2,P1_C2,P2_C2,\n",
    "                               distances_3,P1_C3,P2_C3]\n",
    "            j = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export RANSAC result spots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A,B,neighbor_radius2 = ROI_trackaffine_cca_bash(\n",
    "#                         segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,\n",
    "#                         cc_r,match_threshold,align_threshold,ransac_affine,global_affine_fix,inv_affine_fix,Transform_fix,\n",
    "#                         global_affine_mov,inv_affine_mov,Transform_mov,global_affine2,inv_affine2,Transform2,inv_Transform2,\n",
    "#                         Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "\n",
    "# spot_extraction = ['hAir/','RS-FISH/affine_cca/'][1]\n",
    "# np.savetxt(seg_dir + spot_extraction + '5#_RANSAC_R2_c0_spots.txt',A,delimiter=',')\n",
    "# np.savetxt(seg_dir + spot_extraction + '5#_RANSAC_R1_c0_spots.txt',B,delimiter=',')\n",
    "\n",
    "# A,B,neighbor_radius2 = ROI_trackaffine_bash(\n",
    "#                     segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "#                     ransac_affine,global_affine2,inv_affine2,Transform2,inv_Transform2,Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "\n",
    "# spot_extraction = ['hAir/','RS-FISH/affine_cca/'][1]\n",
    "# np.savetxt(seg_dir + spot_extraction + '5#_RANSAC_R2_c3_spots.txt',A,delimiter=',')\n",
    "# np.savetxt(seg_dir + spot_extraction + '5#_RANSAC_R1_c3_spots.txt',B,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test part for Shiqi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use ICP to register point clouds of an example ROI dataset. \n",
    "These spots have been corasely registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\FISH\\lib\\site-packages\\napari\\_qt\\qt_resources\\_icons.py:387: UserWarning: Unable to save qt-resources: [Errno 13] Permission denied: 'D:\\\\Anaconda3\\\\envs\\\\FISH\\\\lib\\\\site-packages\\\\napari\\\\_qt\\\\qt_resources\\\\_qt_resources_PyQt5_5_15_2_735669436b5db7ec73a1cc411fb6f05b.py'\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "neighbor_radius2 =1\n",
    "viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Charlotte\\AppData\\Local\\Temp\\ipykernel_22552\\4178655402.py:123: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indecies = np.zeros(src.shape[0], dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0 iter icp error:0.4594901660203081\n",
      "No.1 iter icp error:0.44604218120599903\n",
      "0.642628220679892\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fix_spacing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\Charlotte\\AppData\\Local\\Temp\\ipykernel_22552\\3919734196.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     viewer.add_points(np.transpose(np.array([A[:,0]/fix_spacing[0],A[:,1]/fix_spacing[1],A[:,2]/fix_spacing[2]])),name ='A', size=1,\n\u001b[0m\u001b[0;32m     22\u001b[0m                       face_color='green',edge_color='green',blending='opaque') \n\u001b[0;32m     23\u001b[0m     viewer.add_points(np.transpose(np.array([B[:,0]/fix_spacing[0],B[:,1]/fix_spacing[1],B[:,2]/fix_spacing[2]])),name ='B', size=1, \n",
      "\u001b[1;31mNameError\u001b[0m: name 'fix_spacing' is not defined"
     ]
    }
   ],
   "source": [
    "#ICP\n",
    "# if __name__ == \"__main__\":\n",
    "#     spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R2_c3_spots.txt'\n",
    "#     A = np.loadtxt(spotdir, delimiter=',')\n",
    "#     spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R1_c3_spots.txt'\n",
    "#     B = np.loadtxt(spotdir, delimiter=',')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    A = np.loadtxt('D:/Users/Charlotte/OneDrive - International Campus, Zhejiang University/Sternson Lab/seqFISH Project/220717_test files/5#_RANSAC_R2_c3_spots.txt',delimiter=',')\n",
    "    B = np.loadtxt('D:/Users/Charlotte/OneDrive - International Campus, Zhejiang University/Sternson Lab/seqFISH Project/220717_test files/5#_RANSAC_R1_c3_spots.txt',delimiter=',')\n",
    "    \n",
    "    Transform,_,_ = icp(A, B,neighbor_radius2)  # A->B \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist,_,_ = colocalization(A,C,neighbor_radius2*3)  # return in pixel\n",
    "    \n",
    "    print(dist)\n",
    "\n",
    "    viewer.add_points(np.transpose(np.array([A[:,0]/fix_spacing[0],A[:,1]/fix_spacing[1],A[:,2]/fix_spacing[2]])),name ='A', size=1,\n",
    "                      face_color='green',edge_color='green',blending='opaque') \n",
    "    viewer.add_points(np.transpose(np.array([B[:,0]/fix_spacing[0],B[:,1]/fix_spacing[1],B[:,2]/fix_spacing[2]])),name ='B', size=1, \n",
    "                      face_color='red',edge_color='red',blending='opaque') \n",
    "    viewer.add_points(np.transpose(np.array([C[:,0]/fix_spacing[0],C[:,1]/fix_spacing[1],C[:,2]/fix_spacing[2]])),name ='C', size=1,\n",
    "                      face_color='yellow',edge_color='yellow',blending='opaque') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANSAC ICP \n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#     spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R2_c3_spots.txt'\n",
    "#     A = np.loadtxt(spotdir, delimiter=',')\n",
    "#     spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R1_c3_spots.txt'\n",
    "#     B = np.loadtxt(spotdir, delimiter=',')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    A = np.loadtxt('D:/Users/Charlotte/OneDrive - International Campus, Zhejiang University/Sternson Lab/seqFISH Project/220717_test files/5#_RANSAC_R2_c3_spots.txt',delimiter=',')\n",
    "    B = np.loadtxt('D:/Users/Charlotte/OneDrive - International Campus, Zhejiang University/Sternson Lab/seqFISH Project/220717_test files/5#_RANSAC_R1_c3_spots.txt',delimiter=',')\n",
    "    \n",
    "    Transform,_,_ = ICP_RANSAC(A, B,neighbor_radius2)  # A->B \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist,_,_ = colocalization(A,C,neighbor_radius2*3)  # return in pixel\n",
    "\n",
    "    print(dist)\n",
    "    viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "    napari.run()\n",
    "    viewer.add_points(np.transpose(np.array([D[:,0]/fix_spacing[0],D[:,1]/fix_spacing[1],D[:,2]/fix_spacing[2]])),name ='D', size=1,\n",
    "                      face_color='yellow',edge_color='yellow',blending='opaque') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icp start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Charlotte\\AppData\\Local\\Temp\\ipykernel_22552\\4178655402.py:123: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indecies = np.zeros(src.shape[0], dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0 iter icp error:0.4594901660203081\n",
      "No.1 iter icp error:0.44604218120599903\n",
      "icp ransac start\n",
      "No.0 iter icp error:0.4594901660203081\n",
      "RSthreshold:0.9037132823659157\n",
      "100\n",
      "inliers number:781,error:0.44593923945291863\n",
      "mean_error_RANSAC: 0.44593923945291863\n",
      "RANSACpass\n",
      "No.1 iter icp error:0.46420055824408096\n",
      "RSthreshold:0.9288345798740351\n",
      "100\n",
      "inliers number:779,error:0.44593923945291863\n",
      "mean_error_RANSAC: 0.44593923945291863\n",
      "Ignore RS.\n",
      "distance_iter:[[[0.44593924]\n",
      "  [0.44593924]]]\n",
      "ransac icp start\n",
      "100\n",
      "inliers number:816,error:0.44593923945291863\n",
      "Ignore RS.\n",
      "No.0 iter icp error:0.4594901660203081\n",
      "RSthreshold:0.9037132823659157\n",
      "100\n",
      "inliers number:789,error:0.44593923945291863\n",
      "Ignore RS.\n",
      "No.1 iter icp error:0.44604218120599903\n",
      "RSthreshold:0.9056729171601697\n",
      "100\n",
      "inliers number:775,error:0.44593923945291863\n",
      "Ignore RS.\n",
      "No.2 iter icp error:0.4459787002434783\n",
      "distance_iter:[[[0.45949017]\n",
      "  [0.45949017]]\n",
      "\n",
      " [[0.44604218]\n",
      "  [0.45949017]]\n",
      "\n",
      " [[0.4459787 ]\n",
      "  [0.45949017]]]\n",
      "ICP distance:0.44593923945291863\n",
      "ICP_RS distance:0.44377079244803935\n",
      "RS_ICP distance:0.44593923945291863\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fix_spacing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\Charlotte\\AppData\\Local\\Temp\\ipykernel_22552\\1833403139.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnapari\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastronaut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mnapari\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     viewer.add_points(np.transpose(np.array([D[:,0]/fix_spacing[0],D[:,1]/fix_spacing[1],D[:,2]/fix_spacing[2]])),name ='D', size=1,\n\u001b[0m\u001b[0;32m     63\u001b[0m                       face_color='yellow',edge_color='yellow',blending='opaque') \n",
      "\u001b[1;31mNameError\u001b[0m: name 'fix_spacing' is not defined"
     ]
    }
   ],
   "source": [
    "#RANSAC ICP \n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#     spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R2_c3_spots.txt'\n",
    "#     A = np.loadtxt(spotdir, delimiter=',')\n",
    "#     spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R1_c3_spots.txt'\n",
    "#     B = np.loadtxt(spotdir, delimiter=',')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    A = np.loadtxt('D:/Users/Charlotte/OneDrive - International Campus, Zhejiang University/Sternson Lab/seqFISH Project/220717_test files/5#_RANSAC_R2_c3_spots.txt',delimiter=',')\n",
    "    B = np.loadtxt('D:/Users/Charlotte/OneDrive - International Campus, Zhejiang University/Sternson Lab/seqFISH Project/220717_test files/5#_RANSAC_R1_c3_spots.txt',delimiter=',')\n",
    "    \n",
    "    print(f'icp start')\n",
    "    Transform_ICP,_,_ = icp(A, B,neighbor_radius2) \n",
    "    \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform_ICP).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist_ICP,_,_ = colocalization(A,C,neighbor_radius2)  # return in pixel\n",
    "   \n",
    "    print(f'icp ransac start')\n",
    "    Transform_ICP_RS,_,_ = ICP_RANSAC(A, B,neighbor_radius2)  # A->B \n",
    "    \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform_ICP_RS).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist_ICP_RS,_,_ = colocalization(A,C,neighbor_radius2)  # return in pixel\n",
    "    \n",
    "    print(f'ransac icp start')\n",
    "    Transform_RS_ICP,_,_ = RANSAC_ICP(A, B,neighbor_radius2)  # A->B \n",
    "    \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform_RS_ICP).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist_RS_ICP,_,_ = colocalization(A,C,neighbor_radius2)  # return in pixel\n",
    "    \n",
    "    print(f'ICP distance:{dist_ICP}')\n",
    "    print(f'ICP_RS distance:{dist_ICP_RS}')\n",
    "    print(f'RS_ICP distance:{dist_RS_ICP}')\n",
    "    \n",
    "#     print(f'ICP:{Transform_ICP}')\n",
    "#     print(f'ICP_RS:{Transform_ICP_RS}')\n",
    "#     print(f'RS_ICP:{Transform_RS_ICP}')\n",
    "#     if (Transform_ICP_RS == Transform).all():\n",
    "#         print(f'yes ICP_RS=ICP')\n",
    "#     else:\n",
    "#         print(f'ICP_RS !=ICP')\n",
    "#     if (Transform_ICP_RS == Transform_RS_ICP).all():\n",
    "#         print(f'yes ICP_RS=RS_ICP')\n",
    "#     else:\n",
    "#         print(f'ICP_RS !=RS_ICP')\n",
    "\n",
    "    viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "    napari.run()\n",
    "    viewer.add_points(np.transpose(np.array([D[:,0]/fix_spacing[0],D[:,1]/fix_spacing[1],D[:,2]/fix_spacing[2]])),name ='D', size=1,\n",
    "                      face_color='yellow',edge_color='yellow',blending='opaque') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANSAC ICP \n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#     spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R2_c3_spots.txt'\n",
    "#     A = np.loadtxt(spotdir, delimiter=',')\n",
    "#     spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R1_c3_spots.txt'\n",
    "#     B = np.loadtxt(spotdir, delimiter=',')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    A = np.loadtxt('D:/Users/Charlotte/OneDrive - International Campus, Zhejiang University/Sternson Lab/seqFISH Project/220717_test files/5#_RANSAC_R2_c0_spots.txt',delimiter=',')\n",
    "    B = np.loadtxt('D:/Users/Charlotte/OneDrive - International Campus, Zhejiang University/Sternson Lab/seqFISH Project/220717_test files/5#_RANSAC_R1_c0_spots.txt',delimiter=',')\n",
    "    \n",
    "    print(f'icp start')\n",
    "    Transform_ICP,_,_ = icp(A, B,neighbor_radius2) \n",
    "    \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform_ICP).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist_ICP,_,_ = colocalization(A,C,neighbor_radius2)  # return in pixel\n",
    "   \n",
    "    \n",
    "    print(f'icp ransac start')\n",
    "    Transform_ICP_RS,_,_ = ICP_RANSAC(A, B,neighbor_radius2)  # A->B \n",
    "    \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform_ICP_RS).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist_ICP_RS,_,_ = colocalization(A,C,neighbor_radius2)  # return in pixel\n",
    "    \n",
    "    print(f'ransac icp start')\n",
    "    Transform_RS_ICP,_,_ = RANSAC_ICP(A, B,neighbor_radius2)  # A->B \n",
    "    \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform_RS_ICP).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist_RS_ICP,_,_ = colocalization(A,C,neighbor_radius2)  # return in pixel\n",
    "\n",
    "    \n",
    "    print(f'ICP distance:{dist_ICP}')\n",
    "    print(f'ICP_RS distance:{dist_ICP_RS}')\n",
    "    print(f'RS_ICP distance:{dist_RS_ICP}')\n",
    "    \n",
    "#     print(f'ICP:{Transform_ICP}')\n",
    "#     print(f'ICP_RS:{Transform_ICP_RS}')\n",
    "#     print(f'RS_ICP:{Transform_RS_ICP}')\n",
    "#     if (Transform_ICP_RS == Transform).all():\n",
    "#         print(f'yes ICP_RS=ICP')\n",
    "#     else:\n",
    "#         print(f'ICP_RS !=ICP')\n",
    "#     if (Transform_ICP_RS == Transform_RS_ICP).all():\n",
    "#         print(f'yes ICP_RS=RS_ICP')\n",
    "#     else:\n",
    "#         print(f'ICP_RS !=RS_ICP')\n",
    "    \n",
    "\n",
    "    viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "    napari.run()\n",
    "    viewer.add_points(np.transpose(np.array([D[:,0]/fix_spacing[0],D[:,1]/fix_spacing[1],D[:,2]/fix_spacing[2]])),name ='D', size=1,\n",
    "                      face_color='yellow',edge_color='yellow',blending='opaque') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
