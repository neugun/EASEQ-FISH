{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ransac affine for point cloud alignment\n",
    "After starfinity for finding ROI and ROI_affine_2masks for affineing ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will learn to align several point clouds from the ROI using two variants of the ransac affine and ICP algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequistes:\n",
    "1. starfinity for finding ROI\n",
    "2. ### ROI_affine_2masks for warping ROIs.Inspect invalid ROIs, extract ROI_SPOTS \n",
    "\n",
    "Steps\n",
    "1. import spots location if using RS-FISH, checked with Napari images\n",
    "2. load images that the same as the registered or unregistered mask \n",
    "3. select each mask, load spot location of ROI (FISHSPOTS,RS-FISH, or starfish), perform\n",
    "ransac affine, ICP affine for each channels of two rounds\n",
    "4. ### Inspect invalid ROIs, perform another affine, export spots location of every ROIs. \n",
    "5. Visualization of spots of multiple channels and rounds\n",
    "6. Decode spots with knn neighbor or other 3d seqFISH methods.\n",
    "\n",
    "For later:Trying to implement other better non-rigid methods, local descriptor methods.\n",
    "\n",
    "bash\n",
    "1. for each channel, rounds, and # numbers of ROI (e.g., every 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with loading the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pools\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from math import pi, sin, cos, sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from matplotlib import cm\n",
    "from scipy import ndimage\n",
    "import scipy.io\n",
    "from skimage import data\n",
    "from skimage.io import imread, imsave\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from cv2 import estimateTranslation3D\n",
    "import tifffile\n",
    "import seaborn as sns\n",
    "\n",
    "# import bigstream library\n",
    "import zarr\n",
    "import z5py\n",
    "from bigstream import features\n",
    "from bigstream import features1\n",
    "from bigstream import ransac\n",
    "from bigstream import affine\n",
    "from bigstream import affine1\n",
    "from bigstream import transform\n",
    "from fishspot.filter import white_tophat\n",
    "from fishspot.detect import detect_spots_log\n",
    "\n",
    "# napari\n",
    "%gui qt5\n",
    "import napari\n",
    "# viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "# napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with loading the required modules for ransac."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colocalization filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucldist(coords1, coords2):\n",
    "    \"\"\" Calculates the euclidean distance between 2 lists of coordinates. \"\"\"\n",
    "    dist = np.zeros(len(coords1))\n",
    "    i = 0\n",
    "    for (x, y) in zip(coords1, coords2):\n",
    "        p1 = x\n",
    "        p2 = y\n",
    "        squared_dist = (p1[0]-p2[0])**2+(p1[1]-p2[1])**2+(p1[2]-p2[2])**2\n",
    "        dist[i] = np.sqrt(squared_dist)\n",
    "        i = i+1\n",
    "    return dist\n",
    "\n",
    "def cloud_distance(spot_fix,spot_mov):\n",
    "    \"\"\"compute distance of nearest spot cloud by KNN.\n",
    "    \"\"\"\n",
    "    c0=spot_fix[:,:3].copy()\n",
    "    c1=spot_mov[:,:3].copy()\n",
    "    kdtree_c0 = cKDTree(c0)\n",
    "    kdtree_c1 = cKDTree(c1)\n",
    "    dist2,idx2 = kdtree_c0.query(c1, k=3)\n",
    "    [Idx_unique, I] = np.unique(idx2,return_index=True)  \n",
    "    return dist2[:,0]\n",
    "\n",
    "def colocalization(spot_c0,spot_c1,neighbor_radius):\n",
    "    #vox=[0.23,0.23,0.38]\n",
    "    c0=spot_c0[:,:3].copy()\n",
    "    c1=spot_c1[:,:3].copy()\n",
    "\n",
    "    kdtree_c0 = cKDTree(c0)\n",
    "    kdtree_c1 = cKDTree(c1)\n",
    "    neighbors = kdtree_c0.query_ball_tree(kdtree_c1, neighbor_radius)\n",
    "    dist2,idx2 = kdtree_c0.query(c1, k=3)\n",
    "    [Idx_unique, I] = np.unique(idx2,return_index=True) \n",
    "    ## find the smallest repeated value location, and delete the others\n",
    "    for i in range(Idx_unique.shape[0]):  # should repeat for only once\n",
    "    #     print(Idx_unique[i])\n",
    "        Loc_rep=np.where(idx2==Idx_unique[i])    \n",
    "    #     print(Loc_rep[0])\n",
    "        A=dist2[Loc_rep[0],Loc_rep[1]]\n",
    "        minposition = min(A)\n",
    "        Loc_min = np.where(A==minposition)[0]\n",
    "    #     print(Loc_min)\n",
    "    #     Loc_rep_min=Loc_rep[0][Loc_min[0]]    \n",
    "        Loc_rep_nouse=np.delete(range(len(Loc_rep[0])),Loc_min)\n",
    "        dist2[Loc_rep[0][Loc_rep_nouse],Loc_rep[1][Loc_rep_nouse]]=neighbor_radius*2 \n",
    "    ## find the results that are less than radius; used later column data \n",
    "    # when only first row is not exist use latter column, or just dispose it. \n",
    "    co_loc=np.where(dist2>neighbor_radius)\n",
    "\n",
    "    for j in range(dist2.shape[0]):\n",
    "         if dist2[j,0] < neighbor_radius:\n",
    "                dist2[j,1] = neighbor_radius*2\n",
    "    for j in range(dist2.shape[0]):            \n",
    "         if dist2[j,0] <neighbor_radius or dist2[j,1] <neighbor_radius:\n",
    "                dist2[j,2] = neighbor_radius*2       \n",
    "    row_c1 = np.where(dist2<neighbor_radius)\n",
    "#     print(len(row_c1[0]))\n",
    "\n",
    "    # lipo spot_c1 is row_c1\n",
    "    pBind = row_c1[0]\n",
    "    # print(idx2)\n",
    "    # lipo spot_c1 is idx2\n",
    "    pAind = [(idx2[row_c1[0][x], row_c1[1][x]]) for x in range(len(row_c1[0]))]\n",
    "    lipo_c0 = spot_c0[pAind]\n",
    "    lipo_c1 = spot_c1[pBind]\n",
    "\n",
    "#     print(np.unique(pAind).shape) \n",
    "    true_pos_c0 = np.delete(spot_c0, pAind, axis=0)\n",
    "    true_pos_c1 = np.delete(spot_c1, pBind, axis=0) #true\n",
    "\n",
    "    if spot_c0.shape[0]>0:\n",
    "        P1 = (lipo_c0.shape[0] / spot_c0.shape[0])*100   # % mov spots from  previous images  /spot_c0.shape\n",
    "    else:\n",
    "        P1 = 0\n",
    "        \n",
    "    if spot_c1.shape[0]>0:\n",
    "        P2 = (lipo_c1.shape[0] / spot_c1.shape[0])*100  # % fixed spots can be found in later mov images  /spot_c0.shape\n",
    "    else:\n",
    "        P2 = 0\n",
    "#     print('% P1: ',str(P1) + ';  % P2: ',str(P2)) \n",
    "    Dist = np.mean(eucldist(lipo_c0,lipo_c1))\n",
    "\n",
    "    return lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,Dist,P1,P2\n",
    "\n",
    "def get_spot_inside(all_spots,segmentation_mini,fix_spacing,ROI_fixed,cc):\n",
    "    \"\"\"remove spots outside of a segmenation mask\n",
    "       change spot location back to segmentation mask in pixels\n",
    "    \"\"\"\n",
    "    fix_spots_mini = all_spots[:,:3] / fix_spacing * [0.5,0.25,0.25] + cc\n",
    "    spot_mini = np.zeros(len(fix_spots_mini))\n",
    "    rounded_spot = fix_spots_mini.astype('int') \n",
    "    for i in range(0, len(fix_spots_mini)):          \n",
    "        Coord = rounded_spot[i]\n",
    "        if Coord[0]<0: Coord[0] = 0\n",
    "        if Coord[1]<0: Coord[1] = 0\n",
    "        if Coord[2]<0: Coord[2] = 0\n",
    "        if Coord[0]>segmentation_mini.shape[0]: Coord[0] = segmentation_mini.shape[0]\n",
    "        if Coord[1]>segmentation_mini.shape[1]: Coord[1] = segmentation_mini.shape[1]            \n",
    "        if Coord[2]>segmentation_mini.shape[2]: Coord[2] = segmentation_mini.shape[2]\n",
    "        idx = segmentation_mini[Coord[0]-1, Coord[1]-1, Coord[2]-1]   # roi id\n",
    "        if idx == ROI_fixed:\n",
    "            spot_mini[i] = idx  # add ROI number  \n",
    "    spots_in = all_spots[np.where(spot_mini==ROI_fixed)]\n",
    "    spots_out = all_spots[np.where(spot_mini==0)]\n",
    "    \n",
    "    spots_in_index = np.where(spot_mini==ROI_fixed)\n",
    "    ns = spots_in.shape[0]\n",
    "#     print(f'Image: found {ns} key points inside ROI')\n",
    "    print(f'Image: found {spots_out.shape[0]} key points outside ROI')\n",
    "    return spots_in,spots_in_index\n",
    "\n",
    "## ICP\n",
    "def nearest_neighbor(src, dst):\n",
    "    '''\n",
    "    Find the nearest (Euclidean) neighbor in dst for each point in src\n",
    "    Input:\n",
    "        src: Nx3 array of points\n",
    "        dst: Nx3 array of points\n",
    "    Output:\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "        indecies: dst indecies of the nearest neighbor\n",
    "    '''\n",
    "    indecies = np.zeros(src.shape[0], dtype=np.int)\n",
    "    distances = np.zeros(src.shape[0])\n",
    "    for i, s in enumerate(src):\n",
    "        min_dist = np.inf\n",
    "        for j, d in enumerate(dst):\n",
    "            dist = np.linalg.norm(s-d)\n",
    "            # find Nearest dst[j] to src[i]\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                indecies[i] = j\n",
    "                distances[i] = dist\n",
    "    return distances, indecies  \n",
    "\n",
    "def get_scale(A,B):\n",
    "    dis_A=get_all_side_length(np.array(A))\n",
    "    dis_B=get_all_side_length(np.array(B))\n",
    "    scale = np.abs(dis_B/dis_A)\n",
    "    mask=np.abs(scale)>0.0001\n",
    "    scale_sort=np.sort(scale[mask].reshape(-1))\n",
    "    d_n=len(scale_sort)\n",
    "    s_mean=scale_sort[int(d_n/4):int(d_n*3/4)].mean() #only use medium data\n",
    "    return s_mean\n",
    "\n",
    "def best_fit_transform(A, B):\n",
    "    '''\n",
    "    Calculates the least-squares best-fit transform between corresponding 3D points A->B\n",
    "    Input:\n",
    "      A: Nx3 numpy array of corresponding 3D points\n",
    "      B: Nx3 numpy array of corresponding 3D points\n",
    "    Returns:\n",
    "      T: 4x4 homogeneous transformation matrix\n",
    "      R: 3x3 rotation matrix\n",
    "      t: 3x1 column vector\n",
    "    '''\n",
    "    assert len(A) == len(B)\n",
    "\n",
    "    # translate points to their centroids\n",
    "    centroid_A = np.mean(A, axis=0) \n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # rotation matrix\n",
    "    W = np.dot(BB.T, AA)\n",
    "    U, s, VT = np.linalg.svd(W, full_matrices=True, compute_uv=True)\n",
    "    R = np.dot(U, VT)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "        VT[2,:] *= -1\n",
    "        R = np.dot(U, VT)\n",
    "\n",
    "    # translation\n",
    "    t = centroid_B.T - np.dot(R,centroid_A.T)\n",
    "\n",
    "    #scale \n",
    "#     s_mean=get_scale(A,B)\n",
    "    s_mean=1\n",
    "    \n",
    "    # homogeneous transformation\n",
    "    T = np.identity(4)\n",
    "#     T[0:3, 0:3] = s_mean * R\n",
    "    T[0:3, 0:3] = R\n",
    "    T[0:3, 3] = t\n",
    "    \n",
    "    return T, R, t, s_mean\n",
    "       \n",
    "def icp(A0, B0,distance_forICP,init_pose = None, max_iterations=200, tolerance=0.0001):\n",
    "    '''\n",
    "    The Iterative Closest Point method\n",
    "    Input:\n",
    "        A: Nx3 numpy array of source 3D points\n",
    "        B: Nx3 numpy array of destination 3D point\n",
    "        init_pose: 4x4 homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "    '''\n",
    "    #  select points\n",
    "#     distance_forICP = 3\n",
    "\n",
    "    A,B,_,_,dist,_,_ = colocalization(A0,B0,distance_forICP)\n",
    "    \n",
    "    # make points homogeneous, copy them so as to maintain the originals\n",
    "    src = np.ones((4,A.shape[0]))  #(4, A.shape[0])\n",
    "    dst = np.ones((4,B.shape[0]))\n",
    "    src[0:3,:] = np.copy(A.T)  # A.T shape (3,20)\n",
    "    dst[0:3,:] = np.copy(B.T) # FIX\n",
    "    \n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    prev_error = 0\n",
    "    distances_iter = np.zeros((max_iterations,1))\n",
    "    for i in range(max_iterations):\n",
    "        # find the nearest neighbours between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[0:3,:].T, dst[0:3,:].T)\n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T,R,t,s_mean = best_fit_transform(src[0:3,:].T, dst[0:3,indices].T)  #Sort dst[] by indices\n",
    "        src = np.dot(T, src)\n",
    "        # check error\n",
    "        mean_error = np.sum(distances) / distances.size\n",
    "        if abs(prev_error-mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "        distances_iter[i] = mean_error\n",
    "    T,R,t,s_mean = best_fit_transform(A, src[0:3,:].T)\n",
    "    \n",
    "    src_1 = np.ones((4,A0.shape[0]))  #(4, A.shape[0])\n",
    "    src_1[0:3,:] = np.copy(A0.T)  # A.T shape (3,20)    \n",
    "    C = np.dot(T, src_1) # A transform\n",
    "    C =  C[0:3,:].T      # save file as the same order \n",
    "    \n",
    "    return T, distances, C \n",
    "\n",
    "def get_all_side_length(points):\n",
    "    all_dis=[]\n",
    "    for i in range(len(points)-1):\n",
    "        for j in range(i+1,len(points)):\n",
    "            all_dis.append(points[i]-points[j])\n",
    "    all_dis=np.array(all_dis)\n",
    "    return np.linalg.norm(all_dis,axis=1)\n",
    "\n",
    "def estimate_similarity_transform_3D(A, B):\n",
    "                 \n",
    "    assert len(A) == len(B)\n",
    "    N = A.shape[0];\n",
    "    mu_A = mean(A, axis=0)\n",
    "    mu_B = mean(B, axis=0)\n",
    "\n",
    "    AA = A - tile(mu_A, (N, 1))\n",
    "    BB = B - tile(mu_B, (N, 1))\n",
    "    H = transpose(AA) * BB\n",
    "    U, S, Vt = linalg.svd(H)\n",
    "    R = Vt.T * U.T\n",
    "                 \n",
    "    if linalg.det(R) < 0:\n",
    "        print (\"Reflection detected\")\n",
    "        Vt[2, :] *= -1\n",
    "        R = Vt.T * U.T\n",
    "    s_mean=get_scale(A,B)\n",
    "    t = -s_mean * R * mu_A.T + mu_B.T\n",
    "\n",
    "    return R, t\t,s_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RANSAC modules #c\n",
    "def get_random_sample(data,n_items: int) -> np.ndarray:\n",
    "    indices = np.random.choice(len(data), n_items, replace=False)\n",
    "    return indices\n",
    "\n",
    "def estimate_n_trials_needed(n_sample_points, inlier_ratio: float = 0.8, probability: float = 0.95) -> int:\n",
    "    \"\"\"\n",
    "    Estimate number of trials needed to select only true inliers with RANSAC.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    inlier_ratio : number of inliers / number of all points\n",
    "    n_sample_points :number of selected point in each iteration\n",
    "    probability : desired probability of success.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Estimated number of trials needed.\n",
    "    \"\"\"\n",
    "    return int(np.log(1 - probability) / np.log(1 - inlier_ratio ** n_sample_points))\n",
    "\n",
    "#main\n",
    "def ransac_remove_outliers(\n",
    "    observation,reference,inlier_ratio=0.8,error_threshold=10,n_sample_points=5,\n",
    "    inlier_threshold=2,fit_with_final_inliers=True\n",
    ")->np.ndarray: \n",
    "    '''\n",
    "    This is to remove outliers after each iteration of ICP\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observation - a set of points need to be registered to the ref\n",
    "    inlier_ratio : number of inliers / number of all point\n",
    "    error_threshold – threshold value to determine when a data point fits a model\n",
    "    n_sample_points- number of selected point in each iteration\n",
    "    fit_with_final_inliers: Fit final model with final inliers solved by the algorithm.\n",
    "    inlier_threshold – minimum number of data points required to fit the model\n",
    "  \n",
    "    max_trials – maximum number of iterations allowed in the algorithm\n",
    "    \n",
    "    #not set # d – number of close data points required to assert that a model fits well to data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    inlier indices\n",
    "    '''\n",
    "    # initialization\n",
    "    inlier_indices_candidate = None\n",
    "    inlier_indices = None\n",
    "    trial_number = 0\n",
    "    best_error = np.inf\n",
    "    best_model = None\n",
    "    \n",
    "\n",
    "    is_termination = None #if iteration should be terminated.\n",
    "    is_solution_valid = None #if solution valid or not.\n",
    "    \n",
    "    max_trials = estimate_n_trials_needed(n_sample_points,inlier_ratio)\n",
    "    \n",
    "    #fit\n",
    "    for trial in range(max_trials):\n",
    "        src=observation\n",
    "        trial_number = trial\n",
    "        sample = get_random_sample(src,n_sample_points) #get data \n",
    "        current_model,_,_= best_fit_transform(sample[0:3,:].T,reference[0:3,:].T)\n",
    "        src= np.dot(current_model,src)\n",
    "        #get inliers\n",
    "        distance,_ = nearest_neighbor(src[0:3,:].T, reference[0:3,:].T)\n",
    "        j=0\n",
    "        for i, s in enumerate(src):\n",
    "            d = distance[i]\n",
    "            if d <= error_threshold:\n",
    "                indices[j] = i\n",
    "                j = j + 1\n",
    "        inlier_indices_candidate = indices #find inliers\n",
    "       \n",
    "        #Verify if the current model is valid\n",
    "        if (inlier_indices_candidate.size-n_sample_points) >= inlier_threshold:\n",
    "            is_valid_solution = True\n",
    "        if not is_valid_solution:\n",
    "            continue\n",
    "        \n",
    "        error = np.sum(distance) / distance.size\n",
    "\n",
    "        # Update solution if best so far\n",
    "        if error < best_error:\n",
    "            inlier_indices = inlier_indices_candidate.copy()\n",
    "            best_error = error\n",
    "\n",
    "    if fit_with_final_inliers:\n",
    "        inliers = observation[inlier_indices]\n",
    "        T_rs,_,_= best_fit_transform(inliers[0:3,:].T,reference[0:3,:].T)\n",
    "\n",
    "    return T_rs\n",
    "\n",
    "def ICP_RANSAC(\n",
    "    A, B, ICP_error,init_pose = None, max_iterations=200, tolerance=0.001\n",
    "):\n",
    "    '''\n",
    "    The Iterative Closest Point with RANSAC\n",
    "    Input:\n",
    "        A: Nx3 numpy array of source 3D points\n",
    "        B: Nx3 numpy array of destination 3D point\n",
    "        ICP_error\n",
    "        init_pose: 4x4 homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "    '''\n",
    "    #  select points \n",
    "    ICP_error = 30\n",
    "#     A,B,_,_,_ = colocalization(A,B,ICP_error)\n",
    "    \n",
    "    # make points homogeneous, copy them so as to maintain the originals\n",
    "    src = np.ones((4,A.shape[0])) #(4, A.shape[0])\n",
    "    dst = np.ones((4,B.shape[0]))\n",
    "    src[0:3,:] = np.copy(A.T) # A.T shape (3,20)\n",
    "    dst[0:3,:] = np.copy(B.T)\n",
    "    \n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    prev_error = 0\n",
    "    distances_iter = np.zeros((max_iterations,1))\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # find the nearest neighbours between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[0:3,:].T, dst[0:3,:].T)\n",
    "        \n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T,_,_,_ = best_fit_transform(src[0:3,:].T, dst[0:3,indices].T)  \n",
    "        # update the current source\n",
    "        # refer to \"Introduction to Robotics\" Chapter2 P28. Spatial description and transformations\n",
    "        src = np.dot(T, src)\n",
    "\n",
    "        # add RANSAC to remove outliers #Shiqi Wang\n",
    "        T = ransac_remove_outliers(src,dst)\n",
    "        src = np.dot(T, src)\n",
    "\n",
    "        # check error\n",
    "        mean_error = np.sum(distances) / distances.size\n",
    "        print(f'mean_error: {mean_error}')\n",
    "        if abs(prev_error-mean_error) < tolerance:\n",
    "           break\n",
    "        prev_error = mean_error\n",
    "        distances_iter[i] = mean_error\n",
    "\n",
    "#     fig=plt.figure(dpi=120,figsize=(2,3))\n",
    "#     plt.plot(distances_iter[:20])\n",
    "#     sns.despine() \n",
    "#     plt.xlabel('Spots:'+ str(distances_iter[:20].shape[0]))\n",
    "#     plt.ylabel('Distance/pixel')\n",
    "#     ave=np.average(distances_iter[:20])\n",
    "#     plt.title(str(float('%.2f' % ave)))\n",
    "#     plt.show()\n",
    "\n",
    "    # calculcate final tranformation\n",
    "    T,R,t,s_mean = best_fit_transform(A, src[0:3,:].T)\n",
    "    \n",
    "    src_1 = np.ones((4,A0.shape[0]))  #(4, A.shape[0])\n",
    "    src_1[0:3,:] = np.copy(A0.T)  # A.T shape (3,20)    \n",
    "    C = np.dot(T, src_1) # A transform\n",
    "    C =  C[0:3,:].T      # save file as the same order \n",
    "    \n",
    "    return T, distances, C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_trackaffine_bash(segmentation1,segmentation2,ROI_fixed,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,\n",
    "                         threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,ransac_affine,global_affine_0,\n",
    "                         inv_affine_0,Transform_0,inv_Transform_0,Chn,global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots):\n",
    "    \"\"\"\n",
    "    default: apply DAPI channel to the FISH channels\n",
    "    \"\"\"\n",
    "    seg_dir = 'E:/Maxprobe_analysis/R2_R1_3tm50/'\n",
    "    fix_spacing=np.array([0.42,0.23,0.23])\n",
    "    mov_spacing=fix_spacing\n",
    "    min_radius=6\n",
    "    max_radius=12\n",
    "    cc_radius=cc_r # used for radius pixel of context information.\n",
    "    nspots=30000\n",
    "    num_sigma_max=6\n",
    "#     neighbor_radius0 = 12  # 12 : used to find nearest match spots for later local affine\n",
    "    neighbor_radius1 = 3    # 3 used to find nearest match spots in the validation \n",
    "    neighbor_radius2 = neighbor_radius1/3  # /3 used to for ICP\n",
    "#     image_ransac = 1 # >0 is to get point correspondences from image; or o is to find nearest neighbors\n",
    "    \n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    cc = [min(AA[0]),min(AA[1]),min(AA[2])]\n",
    "    BB=np.where(segmentation2==ROI_moving)\n",
    "    dd = [min(BB[0]),min(BB[1]),min(BB[2])]   \n",
    "    fix_ds = fixed_ROI\n",
    "    \n",
    "    # transform DAPI image\n",
    "    mov_affine_0 = transform.apply_global_affine(fix_ds, moving_ROI,fix_spacing, fix_spacing, global_affine_0,)\n",
    "    mov_ds = transform.apply_global_affine(fix_ds, mov_affine_0,fix_spacing, fix_spacing,Transform_0,) # inv_Transform_0\n",
    "#     print(global_affine_0)\n",
    "#     mov_affine_0 = scipy.ndimage.affine_transform(moving_ROI,np.linalg.inv(global_affine_0)) \n",
    "#     mov_ds = scipy.ndimage.affine_transform(mov_affine_0,np.linalg.inv(inv_Transform_0)) \n",
    "    \n",
    "    # if global_detection = 1, Adapt spots of ROI from hAirlocalize(um) or RS-FISH(pixel).\n",
    "    if global_detection > 0:\n",
    "        zoom=[2,4,4]\n",
    "        if hAir == 1:\n",
    "            # read spot data into memory as numpy arrays  Airlocolize spots data in xyz order: um\n",
    "            print(f'hAirlocalize points')\n",
    "            # find specific fixed roi\n",
    "            spotdir = seg_dir + 'hAir/R2_' + Chn + '_ROI.txt'\n",
    "            spot_fix=np.loadtxt(spotdir, delimiter=',')\n",
    "            fixed_spots1 = spot_fix[spot_fix[:,4] == ROI_fixed][:,:3]\n",
    "    #         print(fixed_spots1)\n",
    "            # find specific moving roi\n",
    "            spotdir = seg_dir + 'hAir/R1_' + Chn + '_ROI.txt'\n",
    "            spot_mov=np.loadtxt(spotdir, delimiter=',')\n",
    "            moving_spots1 = spot_mov[spot_mov[:,4] == ROI_moving][:,:3]       \n",
    "            # change to zyx order\n",
    "            fixed_spots11 = np.transpose(np.array([fixed_spots1[:,2],fixed_spots1[:,1],fixed_spots1[:,0]]))\n",
    "            moving_spots11 = np.transpose(np.array([moving_spots1[:,2],moving_spots1[:,1],moving_spots1[:,0]]))\n",
    "            # convert to physical units\n",
    "            ccc = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "            fix_spots = (fixed_spots11 - ccc * fix_spacing)\n",
    "            ddd = [min(BB[0])*zoom[0],min(BB[1])*zoom[1],min(BB[2])*zoom[2]]\n",
    "            mov_spots = (moving_spots11 - ddd * mov_spacing)\n",
    "           \n",
    "        else:\n",
    "        ##RS-FISH\n",
    "            print(f'RS-FISH points from cluster')\n",
    "            spotdir = seg_dir + 'RS-FISH/R2_' + Chn + '_ROI.txt'\n",
    "            spot_fix = np.loadtxt(spotdir, delimiter=',')\n",
    "            fixed_spots1 = spot_fix[spot_fix[:,4] == ROI_fixed][:,:3]\n",
    "#             print(fixed_spots1.shape)\n",
    "            spotdir = seg_dir + 'RS-FISH/R1_' + Chn + '_ROI.txt'\n",
    "            spot_mov = np.loadtxt(spotdir, delimiter=',')\n",
    "            moving_spots1 = spot_mov[spot_mov[:,4] == ROI_moving][:,:3] \n",
    "\n",
    "            fixed_spots11 = np.transpose(np.array([fixed_spots1[:,2],fixed_spots1[:,1],fixed_spots1[:,0]]))\n",
    "            moving_spots11 = np.transpose(np.array([moving_spots1[:,2],moving_spots1[:,1],moving_spots1[:,0]]))\n",
    "            # convert to physical units\n",
    "            ccc = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "            fix_spots = (fixed_spots11 - ccc * fix_spacing)\n",
    "            ddd = [min(BB[0])*zoom[0],min(BB[1])*zoom[1],min(BB[2])*zoom[2]]\n",
    "            mov_spots = (moving_spots11 - ddd * mov_spacing)\n",
    "\n",
    "    #         print(f'RS-FISH points from FIJI')\n",
    "    #         spotdir = seg_dir + 'R2_3tm50_1920/ICP_111_C3C1/5_R2_C3_0.txt'\n",
    "    #         spot_fix=np.loadtxt(spotdir, delimiter='\\t')\n",
    "    #         spotdir = seg_dir + 'R2_3tm50_1920/ICP_111_C3C1/5_R1_C3_1.txt'\n",
    "    #         spot_mov=np.loadtxt(spotdir, delimiter='\\t')\n",
    "    #         fixed_spots11 = np.transpose(np.array([spot_fix[:,2],spot_fix[:,1],spot_fix[:,0]]))\n",
    "    #         moving_spots11 = np.transpose(np.array([spot_mov[:,2],spot_mov[:,1],spot_mov[:,0]]))\n",
    "    #         fix_spots =  fixed_spots11* fix_spacing\n",
    "    #         mov_spots =  moving_spots11* fix_spacing\n",
    "        \n",
    "        mov_spots,_ = spots_random_shuffled(moving_ROI_c2,segmentation2,BB,ROI_moving,mov_spots,Shuffle_spots)\n",
    "        \n",
    "        ## apply dapi affine\n",
    "        mov_spots_x = mov_spots\n",
    "        points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine_0,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "#         warp_spots_1 = points.dot(inv_affine_0.T)\n",
    "        warp_spots_1 = points.dot(np.linalg.inv(inv_Transform).T)\n",
    "        \n",
    "        points = np.append(warp_spots_1[:,:3], np.ones((warp_spots_1.shape[0],1)), axis=1)\n",
    "#         mov_spots = points.dot(inv_Transform_0.T)\n",
    "        mov_spots = points.dot(np.linalg.inv(Transform_0.T))\n",
    "        \n",
    "        mov_spots = mov_spots[:,:3]\n",
    "        fix_spots_new = fix_spots\n",
    "        ns1 = fix_spots.shape[0]\n",
    "        ns2 = mov_spots.shape[0]    \n",
    "        print(f'FIXED: found {ns1} key points; MOVING: found {ns2} key points')  \n",
    "    else: \n",
    "        # get spots in pixels\n",
    "        print('Getting FISH spots from image: disabled now')\n",
    "         \n",
    "    # return fix_spots,mov_spots\n",
    "\n",
    "    # remove spots outside of segmenation_mini\n",
    "    # change spot location back to segmentation mask in pixels\n",
    "    fix_spots_new,_ = get_spot_inside(fix_spots,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "    spot_fix = fix_spots_new\n",
    "    mov_spots_new = mov_spots\n",
    "    # print('colocalization of all spots before ransac affine') \n",
    "    lipo_c0,lipo_c1,_,_,dist1,_,_ = colocalization(fix_spots_new,mov_spots_new,neighbor_radius1)  # return in pixel\n",
    "    print(f'pre-ransac_Distance: {np.mean(dist1)}')\n",
    "    \n",
    "    ######################### if no spot detected.\n",
    "    if ns1 >= 10 and ns2 >= 10:\n",
    "        fix_spots1,mov_spots1,_,_,_,_,_ = colocalization(fix_spots_new,mov_spots_new,neighbor_radius0)  # return in pixel\n",
    "        print(f'Found {fix_spots1.shape[0]} matched fixed points')\n",
    "        if ransac_affine == 0:\n",
    "            global_affine = np.eye(4)[:3]\n",
    "            inv_affine = np.eye(4)[:3]\n",
    "        else:\n",
    "            global_affine = ransac_align_points(fix_spots1, mov_spots1, align_threshold,)  \n",
    "            inv_affine = ransac_align_points(mov_spots1, fix_spots1, align_threshold,)\n",
    "\n",
    "        points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "#         warp_spots = points.dot(inv_affine.T)\n",
    "        warp_spots = points.dot(np.linalg.inv(inv_Transform).T)   \n",
    "        \n",
    "#         print('colocalization of inside spots after ransac affine') \n",
    "        spot_mov = warp_spots\n",
    "        lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(fix_spots_new,spot_mov,neighbor_radius1)  # return in pixel\n",
    "        print(f'ransac_Distance: {np.mean(eucldist(lipo_c0,lipo_c1))}')\n",
    " \n",
    "        # image_ransac = 1 is to get point correspondences from image; or 0 is to find nearest neighbors\n",
    "        if image_ransac != 0 and np.mean(eucldist(lipo_c0,lipo_c1)) > image_ransac:\n",
    "            \n",
    "            print(\"local matching again by correlation of intensities in images\")\n",
    "            fix_spots_img =features1.blob_detection(fix_ds, min_radius, max_radius,\n",
    "                num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "                threshold=threshold_fixed, exclude_border=cc_radius,)\n",
    "            mov_spots_img = features1.blob_detection(mov_ds, min_radius, max_radius,\n",
    "                num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "                threshold=threshold_moving, exclude_border=cc_radius,)\n",
    "            \n",
    "            sort_idx = np.argsort(fix_spots_img[:, 3])[::-1]\n",
    "            fix_spots_img = fix_spots_img[sort_idx, :3][:nspots]\n",
    "            sort_idx = np.argsort(mov_spots_img[:, 3])[::-1]\n",
    "            mov_spots_img = mov_spots_img[sort_idx, :3][:nspots]\n",
    "            # convert to physical units(um)\n",
    "            fix_spots_img = fix_spots_img* fix_spacing\n",
    "            mov_spots_img = mov_spots_img* mov_spacing\n",
    "            fix_spots_img,_ = get_spot_inside(fix_spots_img,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "            # get contexts\n",
    "            ns1 = fix_spots_img.shape[0]\n",
    "            ns2 = mov_spots_img.shape[0]  \n",
    "            print(f'FIXED image: found {ns1} key points; MOVING image: found {ns2} key points')\n",
    "            fix_spots0_img = features.get_spot_context(\n",
    "                fix_ds, fix_spots_img, fix_spacing, cc_r,)\n",
    "            mov_spots0_img = features.get_spot_context(\n",
    "                mov_ds, mov_spots_img, mov_spacing, cc_r,)\n",
    "            \n",
    "            correlations = features.pairwise_correlation(\n",
    "                fix_spots0_img, mov_spots0_img,)\n",
    "            fix_spots1_img, mov_spots1_img = features.match_points(\n",
    "                fix_spots0_img, mov_spots0_img,\n",
    "                correlations, match_threshold,)\n",
    "            print(f'Found {fix_spots1_img.shape[0]} matched fixed points')\n",
    "            if ransac_affine == 0:\n",
    "                global_affine = np.eye(4)[:3]\n",
    "                inv_affine = np.eye(4)[:3]\n",
    "            else:\n",
    "                global_affine = ransac_align_points(fix_spots1_img, mov_spots1_img, align_threshold,)  \n",
    "                inv_affine = ransac_align_points(mov_spots1_img, fix_spots1_img, align_threshold,)\n",
    "            \n",
    "            warp_spots = []\n",
    "            points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "            inv_Transform = np.row_stack((global_affine,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "    #         warp_spots = points.dot(inv_affine.T)\n",
    "            warp_spots = points.dot(np.linalg.inv(inv_Transform).T)   \n",
    "            \n",
    "    #         print('colocalization of inside spots after ransac affine')\n",
    "            spot_mov = []\n",
    "            spot_mov = warp_spots\n",
    "            lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(fix_spots_new,spot_mov,neighbor_radius1)  # return in pixel\n",
    "            print(f'ransac_Distance_again: {np.mean(eucldist(lipo_c0,lipo_c1))}')\n",
    "                \n",
    "#         print('registration of all inside spots with ICP')\n",
    "#         A = spot_fix[:,:3]\n",
    "#         B = spot_mov[:,:3]\n",
    "# #         Transform, distances1,C = icp(A, B,neighbor_radius2)\n",
    "#         inv_Transform, distances2,C = icp(B, A,neighbor_radius2)\n",
    "#     #     print (Transform)\n",
    "#         # functions for applying transforms are in bigstream.transform. apply the ICP affine to the moved image\n",
    "#         ICP_affine = transform.apply_global_affine(\n",
    "#             fix_ds, mov_affine,\n",
    "#             fix_spacing, fix_spacing,\n",
    "#             Transform,)\n",
    "#         #     print (inv_Transform)\n",
    "#         p = np.append(B, np.ones((B.shape[0],1)), axis=1)\n",
    "#         C = p.dot(inv_Transform.T)\n",
    "        \n",
    "        A = spot_fix[:,:3]\n",
    "        B = spot_mov[:,:3]\n",
    "        return A, B,neighbor_radius2\n",
    "    \n",
    "#         Transform,_,_ = icp(A, B,neighbor_radius2)\n",
    "        \n",
    "    \n",
    "#         # A->B \n",
    "#         inv_Transform, distances2, _ = icp(B, A,neighbor_radius2) # B->A\n",
    "#         Transform[np.isnan(Transform)] = 0\n",
    "#         inv_Transform[np.isnan(inv_Transform)] = 0\n",
    "#         p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "#         D = p.dot(np.linalg.inv(Transform).T)        ## B->A spots (right) with B->A transform (right)\n",
    "# #         ICP_affine = scipy.ndimage.affine_transform(mov_affine,np.linalg.inv(inv_Transform)) \n",
    "#         C = D[:,:3]\n",
    "        \n",
    "#         # Test ICP distance change. Minor increased performance\n",
    "#         warp_spots_new,_ = get_spot_inside(C,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#         spot_mov = warp_spots_new\n",
    "#         lipo_c0,lipo_c1,_,_,dist3,P1,P2 = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#         print('% P1: ',str(P1) + ';  % P2: ',str(P2))\n",
    "#         pair_dist = eucldist(lipo_c0,lipo_c1)\n",
    "#         print(f'ICP_Distance: {np.mean(pair_dist)}')\n",
    "        \n",
    "#         # functions for images\n",
    "# #         if image_ransac > 0:\n",
    "#     else:\n",
    "#         print(f'Not found enough matched fixed points')\n",
    "#         global_affine = np.eye(4)[:3]    \n",
    "#         inv_affine = np.eye(4)[:3]\n",
    "#         warp_spots = mov_spots\n",
    "#         lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(spot_fix,warp_spots,neighbor_radius1)  # return in pixel\n",
    "# #         print(f'Distance: {np.mean(cloud_distance(spot_fix,spot_mov))}')\n",
    "#         Transform = np.eye(4)[:4]\n",
    "#         inv_Transform = np.eye(4)[:4]\n",
    "#         C = warp_spots[:,:3]\n",
    "#         warp_spots_new,_ = get_spot_inside(C,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#         spot_mov = warp_spots_new\n",
    "#         lipo_c0,lipo_c1,_,_,dist3,P1,P2 = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#         print('% P1: ',str(P1) + ';  % P2: ',str(P2)) \n",
    "#         pair_dist = eucldist(lipo_c0,lipo_c1)\n",
    "#         print(f'ICP_Distance: {np.mean(pair_dist)}')\n",
    "    \n",
    "#     if Chn == \"C3\":\n",
    "#         # bleedthrough correction \n",
    "#         lo = np.percentile(np.ndarray.flatten(moving_ROI_c2),99.5) #Estimate fluorescence intensity of bright DAPI signals\n",
    "#         bg_dapi=np.percentile(np.ndarray.flatten(moving_ROI_c2[moving_ROI_c2!=0]),1) \n",
    "#         bg_data=np.percentile(np.ndarray.flatten(moving_ROI[moving_ROI!=0]),1) #Estimate background in AF546 channel\n",
    "#         dapi_factor=np.median((moving_ROI[moving_ROI_c2>lo] - bg_data)/(moving_ROI_c2[moving_ROI_c2>lo] - bg_dapi)) #Estimate % of signal bleedthrough\n",
    "#         moving_ROI_new  = np.maximum(0, moving_ROI - bg_data - dapi_factor * (moving_ROI_c2 - bg_dapi)).astype('float32')#subtract background and bleedthrough\n",
    "#         mov_affine_0 = transform.apply_global_affine(fix_ds, moving_ROI_new,fix_spacing, fix_spacing,global_affine_0,)\n",
    "#         mov_ds = transform.apply_global_affine(fix_ds, mov_affine_0,fix_spacing,fix_spacing,Transform_0,)  \n",
    "        \n",
    "# #     mov_affine = scipy.ndimage.affine_transform(mov_ds,np.linalg.inv(global_affine))\n",
    "# #     ICP_affine = scipy.ndimage.affine_transform(mov_affine,np.linalg.inv(inv_Transform)) \n",
    "#     mov_affine = transform.apply_global_affine(fix_ds, mov_ds, fix_spacing, fix_spacing,global_affine,)\n",
    "#     ICP_affine = transform.apply_global_affine(fix_ds, mov_affine, fix_spacing, fix_spacing,Transform,) \n",
    "\n",
    "#     return P1,P2,dist1,dist2,pair_dist,spot_fix,mov_spots,warp_spots_new,ICP_affine,mov_affine,cc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_trackaffine_cca_bash(segmentation1,segmentation2,ROI_fixed,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,\n",
    "                         threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,ransac_affine,\n",
    "                         global_affine_fix,inv_affine_fix,Transform_fix,global_affine_mov,inv_affine_mov,\n",
    "                        Transform_mov,global_affine_0,inv_affine_0,Transform_0,inv_Transform_0,Chn,global_detection,\n",
    "                         image_ransac,hAir,neighbor_radius0,Shuffle_spots):\n",
    "    \"\"\"\n",
    "    1.Transform the affine matrix to correct chromatic aberration of two tracks for each rounds. fix and moving. C0 C1\n",
    "    points: points.dot(inv_Transform_0.T)\n",
    "    images: transform.apply_global_affine\n",
    "    2.Transform the DAPI affine matrix: points and images. \n",
    "    3.Do ROI-affine\n",
    "    \n",
    "    default: apply DAPI channel affine matrix to the FISH channels\n",
    "    \"\"\"\n",
    "    seg_dir = 'E:/Maxprobe_analysis/R2_R1_3tm50/'\n",
    "    fix_spacing=np.array([0.42,0.23,0.23])\n",
    "    mov_spacing=fix_spacing\n",
    "    min_radius=6\n",
    "    max_radius=12\n",
    "    cc_radius=cc_r # used for radius pixel of context information.\n",
    "    nspots=30000\n",
    "    num_sigma_max=6\n",
    "#     neighbor_radius0 = 12  # 12 : used to find nearest match spots for later local affine\n",
    "    neighbor_radius1 = 3    # 3 used to find nearest match spots in the validation \n",
    "    neighbor_radius2 = neighbor_radius1/3  # /3 used to for ICP\n",
    "#     image_ransac = 1 # >0 is to get point correspondences from image; or o is to find nearest neighbors\n",
    "    \n",
    "    AA=np.where(segmentation1==ROI_fixed)\n",
    "    cc = [min(AA[0]),min(AA[1]),min(AA[2])]\n",
    "    BB=np.where(segmentation2==ROI_moving)\n",
    "    dd = [min(BB[0]),min(BB[1]),min(BB[2])]\n",
    "    \n",
    "    \n",
    "    # transform cca for fixed images\n",
    "#     fix_ds = fixed_ROI\n",
    "    fix_affine_0 = transform.apply_global_affine(fixed_ROI,fixed_ROI,fix_spacing, fix_spacing, global_affine_fix,)\n",
    "    fix_ds = transform.apply_global_affine(fixed_ROI, fix_affine_0,fix_spacing, fix_spacing,Transform_fix,)\n",
    "#     fix_affine_0  = scipy.ndimage.affine_transform(fixed_ROI,np.linalg.inv(global_affine_fix)) \n",
    "#     fix_ds = scipy.ndimage.affine_transform(fix_affine_0 ,np.linalg.inv(inv_Transform_fix)) \n",
    "    \n",
    "    # transform cca and DAPI affine for moving images\n",
    "    mov_affine_cca = transform.apply_global_affine(moving_ROI,moving_ROI,fix_spacing, fix_spacing, global_affine_mov,)\n",
    "    mov_ds_cca = transform.apply_global_affine(moving_ROI, mov_affine_cca,fix_spacing, fix_spacing,Transform_mov,)\n",
    "#     mov_affine_cca  = scipy.ndimage.affine_transform(moving_ROI,np.linalg.inv(global_affine_mov)) \n",
    "#     mov_ds_cca = scipy.ndimage.affine_transform(mov_affine_cca,np.linalg.inv(inv_Transform_mov))     \n",
    "    # need to export and check colocalization\n",
    "    mov_affine_0 = transform.apply_global_affine(fix_ds, mov_ds_cca,fix_spacing, fix_spacing, global_affine_0,)\n",
    "    mov_ds = transform.apply_global_affine(fix_ds, mov_affine_0,fix_spacing, fix_spacing,Transform_0,)\n",
    "#     mov_affine_0  = scipy.ndimage.affine_transform(mov_ds_cca,np.linalg.inv(global_affine_0)) \n",
    "#     mov_ds = scipy.ndimage.affine_transform(mov_affine_0,np.linalg.inv(Transform_0)) \n",
    "    \n",
    "    # if global_detection = 1, Adapt spots of ROI from hAirlocalize(um) or RS-FISH(pixel).\n",
    "    if global_detection > 0:\n",
    "        zoom=[2,4,4]\n",
    "        if hAir == 1:\n",
    "            # read spot data into memory as numpy arrays  Airlocolize spots data in xyz order: um\n",
    "            print(f'hAirlocalize points')\n",
    "            spotdir1 = seg_dir + 'hAir/R2_' + Chn + '_ROI.txt'\n",
    "            spotdir2 = seg_dir + 'hAir/R1_' + Chn + '_ROI.txt'\n",
    "        else:\n",
    "            ##RS-FISH\n",
    "            print(f'RS-FISH points from cluster')\n",
    "            spotdir1 = seg_dir + 'RS-FISH/R2_' + Chn + '_ROI.txt'\n",
    "            spotdir2 = seg_dir + 'RS-FISH/R1_' + Chn + '_ROI.txt'\n",
    "\n",
    "        spot_fix=np.loadtxt(spotdir1, delimiter=',')\n",
    "        fixed_spots1 = spot_fix[spot_fix[:,4] == ROI_fixed][:,:3]\n",
    "        # find specific moving roi\n",
    "        spot_mov=np.loadtxt(spotdir2, delimiter=',')\n",
    "        moving_spots1 = spot_mov[spot_mov[:,4] == ROI_moving][:,:3]       \n",
    "        # change to zyx order\n",
    "        fixed_spots11 = np.transpose(np.array([fixed_spots1[:,2],fixed_spots1[:,1],fixed_spots1[:,0]]))\n",
    "        moving_spots11 = np.transpose(np.array([moving_spots1[:,2],moving_spots1[:,1],moving_spots1[:,0]]))\n",
    "        # convert to physical units\n",
    "        ccc = [min(AA[0])*zoom[0],min(AA[1])*zoom[1],min(AA[2])*zoom[2]]\n",
    "        fix_spots = (fixed_spots11 - ccc * fix_spacing)\n",
    "        ddd = [min(BB[0])*zoom[0],min(BB[1])*zoom[1],min(BB[2])*zoom[2]]\n",
    "        mov_spots = (moving_spots11 - ddd * mov_spacing)\n",
    "        \n",
    "        ########################################################################\n",
    "        ## apply cca affine for fix spots\n",
    "        \n",
    "        points1 = np.append(fix_spots, np.ones((fix_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine_fix,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "        warp_spots_1 = points1.dot(np.linalg.inv(inv_Transform).T)[:,:3] \n",
    "        points2 = np.append(warp_spots_1, np.ones((warp_spots_1.shape[0],1)), axis=1)\n",
    "        fix_spots = points2.dot(np.linalg.inv(Transform_fix).T)\n",
    "        fix_spots = fix_spots[:,:3]\n",
    "        \n",
    "        ## apply cca affine for mov spots\n",
    "        points2 = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine_mov,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "        warp_spots_2 = points2.dot(np.linalg.inv(inv_Transform).T)[:,:3]\n",
    "        points2 = np.append(warp_spots_2, np.ones((warp_spots_2.shape[0],1)), axis=1)\n",
    "        mov_spots_x = points2.dot(np.linalg.inv(Transform_mov).T)\n",
    "        mov_spots_x = mov_spots_x[:,:3]\n",
    "        ## apply dapi affine for mov \n",
    "        points3 = np.append(mov_spots_x, np.ones((mov_spots_x.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine_0,np.array([[0,0,0,1]]))) #FIX->FIX_reg\n",
    "        warp_spots_3 = points3.dot(np.linalg.inv(inv_Transform).T)[:,:3]\n",
    "        points3 = np.append(warp_spots_3, np.ones((warp_spots_3.shape[0],1)), axis=1)\n",
    "        mov_spots = points3.dot(np.linalg.inv(Transform_0.T))\n",
    "        mov_spots = mov_spots[:,:3]\n",
    "        \n",
    "        ns1 = fix_spots.shape[0]\n",
    "        ns2 = mov_spots.shape[0]    \n",
    "        print(f'FIXED: found {ns1} key points; MOVING: found {ns2} key points')  \n",
    "    else: \n",
    "        # get spots in pixels\n",
    "        print('Getting FISH spots from image: disabled now')\n",
    "    \n",
    "    mov_spots,_ = spots_random_shuffled(moving_ROI_c2,segmentation2,BB,ROI_moving,mov_spots,Shuffle_spots)\n",
    "    \n",
    "    # remove spots outside of segmenation_mini\n",
    "    # change spot location back to segmentation mask in pixels\n",
    "    fix_spots_new,_ = get_spot_inside(fix_spots,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "    spot_fix = fix_spots_new\n",
    "    mov_spots_new = mov_spots\n",
    "    # print('colocalization of all spots before ransac affine') \n",
    "    lipo_c0,lipo_c1,_,_,dist1,_,_ = colocalization(fix_spots_new,mov_spots_new,neighbor_radius1)  # return in pixel\n",
    "    print(f'pre-ransac_Distance: {np.mean(dist1)}')\n",
    "    \n",
    "    ######################### if no spot detected.\n",
    "    if ns1 >= 10 and ns2 >= 10:\n",
    "        fix_spots1,mov_spots1,_,_,_,_,_ = colocalization(fix_spots_new,mov_spots_new,neighbor_radius0)  # return in pixel\n",
    "        print(f'Found {fix_spots1.shape[0]} matched fixed points')\n",
    "        if ransac_affine == 0:\n",
    "            global_affine = np.eye(4)[:3]\n",
    "            inv_affine = np.eye(4)[:3]\n",
    "        else:\n",
    "            global_affine = ransac_align_points(fix_spots1, mov_spots1, align_threshold,)  \n",
    "            inv_affine = ransac_align_points(mov_spots1, fix_spots1, align_threshold,)\n",
    "\n",
    "        points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "        inv_Transform = np.row_stack((global_affine,np.array([[0,0,0,1]]))) #FIX->FIX_reg  \n",
    "        warp_spots = points.dot(np.linalg.inv(inv_Transform).T)\n",
    "#         print('colocalization of inside spots after ransac affine') \n",
    "        spot_mov = warp_spots\n",
    "        lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(fix_spots_new,spot_mov,neighbor_radius1)  # return in pixel\n",
    "        print(f'ransac_Distance: {np.mean(eucldist(lipo_c0,lipo_c1))}')\n",
    " \n",
    "        # image_ransac = 1 is to get point correspondences from image; or 0 is to find nearest neighbors\n",
    "        if image_ransac != 0 and np.mean(eucldist(lipo_c0,lipo_c1)) > image_ransac:\n",
    "            \n",
    "            print(\"local matching again by correlation of intensities in images\")\n",
    "            fix_spots_img =features1.blob_detection(fix_ds, min_radius, max_radius,\n",
    "                num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "                threshold=threshold_fixed, exclude_border=cc_radius,)\n",
    "            mov_spots_img = features1.blob_detection(mov_ds, min_radius, max_radius,\n",
    "                num_sigma=min(max_radius-min_radius, num_sigma_max),\n",
    "                threshold=threshold_moving, exclude_border=cc_radius,)\n",
    "            \n",
    "            sort_idx = np.argsort(fix_spots_img[:, 3])[::-1]\n",
    "            fix_spots_img = fix_spots_img[sort_idx, :3][:nspots]\n",
    "            sort_idx = np.argsort(mov_spots_img[:, 3])[::-1]\n",
    "            mov_spots_img = mov_spots_img[sort_idx, :3][:nspots]\n",
    "            # convert to physical units(um)\n",
    "            fix_spots_img = fix_spots_img* fix_spacing\n",
    "            mov_spots_img = mov_spots_img* mov_spacing\n",
    "            fix_spots_img,_ = get_spot_inside(fix_spots_img,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#             mov_spots_new1 = get_spot_inside(mov_spots,segmentation2,fix_spacing,ROI_fixed,cc) ## avoid no features\n",
    "            # get contexts\n",
    "            ns1 = fix_spots_img.shape[0]\n",
    "            ns2 = mov_spots_img.shape[0]  \n",
    "            print(f'FIXED image: found {ns1} key points; MOVING image: found {ns2} key points')\n",
    "            fix_spots0_img = features.get_spot_context(\n",
    "                fix_ds, fix_spots_img, fix_spacing, cc_r,)\n",
    "            mov_spots0_img = features.get_spot_context(\n",
    "                mov_ds, mov_spots_img, mov_spacing, cc_r,)\n",
    "            \n",
    "            correlations = features.pairwise_correlation(\n",
    "                fix_spots0_img, mov_spots0_img,)\n",
    "            fix_spots1_img, mov_spots1_img = features.match_points(\n",
    "                fix_spots0_img, mov_spots0_img,\n",
    "                correlations, match_threshold,)\n",
    "            print(f'Found {fix_spots1_img.shape[0]} matched fixed points')\n",
    "            if ransac_affine == 0:\n",
    "                global_affine = np.eye(4)[:3]\n",
    "                inv_affine = np.eye(4)[:3]\n",
    "            else:\n",
    "                global_affine = ransac_align_points(fix_spots1_img, mov_spots1_img, align_threshold,)  \n",
    "                inv_affine = ransac_align_points(mov_spots1_img, fix_spots1_img, align_threshold,)\n",
    "            \n",
    "            points = np.append(mov_spots, np.ones((mov_spots.shape[0],1)), axis=1)\n",
    "            inv_Transform = np.row_stack((global_affine,np.array([[0,0,0,1]]))) #FIX->FIX_reg  \n",
    "            warp_spots = points.dot(np.linalg.inv(inv_Transform).T)\n",
    "    #         print('colocalization of inside spots after ransac affine') \n",
    "            spot_mov = warp_spots\n",
    "            lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(fix_spots_new,spot_mov,neighbor_radius1)  # return in pixel\n",
    "            print(f'ransac_Distance_again: {np.mean(eucldist(lipo_c0,lipo_c1))}')\n",
    "                \n",
    "        A = fix_spots_new[:,:3]\n",
    "        B = spot_mov[:,:3]\n",
    "        Transform,_,_ = icp(A, B,neighbor_radius2)  # A->B \n",
    "        return A, B,neighbor_radius2\n",
    "    \n",
    "#         inv_Transform, distances2, _ = icp(B, A,neighbor_radius2) # B->A \n",
    "#         p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "#         D = p.dot(np.linalg.inv(Transform).T)        ## B->A spots (right) with B->A transform (right)\n",
    "# #         ICP_affine = scipy.ndimage.affine_transform(mov_affine,np.linalg.inv(inv_Transform)) \n",
    "#         C = D[:,:3]\n",
    "        \n",
    "#         # Test ICP distance change. Minor increased performance\n",
    "#         warp_spots_new,_ = get_spot_inside(C,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#         spot_mov = warp_spots_new\n",
    "#         lipo_c0,lipo_c1,_,_,dist3,P1,P2 = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#         print('% P1: ',str(P1) + ';  % P2: ',str(P2))\n",
    "#         pair_dist = eucldist(lipo_c0,lipo_c1)\n",
    "#         print(f'ICP_Distance: {np.mean(pair_dist)}')\n",
    "        \n",
    "#         # functions for images\n",
    "# #         if image_ransac > 0:\n",
    "#     else:\n",
    "#         print(f'Not found enough matched fixed points')\n",
    "#         global_affine = np.eye(4)[:3]    \n",
    "#         inv_affine = np.eye(4)[:3]\n",
    "#         warp_spots = mov_spots\n",
    "#         lipo_c0,lipo_c1,_,_,dist2,_,_ = colocalization(spot_fix,warp_spots,neighbor_radius1)  # return in pixel\n",
    "# #         print(f'Distance: {np.mean(cloud_distance(spot_fix,spot_mov))}')\n",
    "#         Transform = np.eye(4)[:4]\n",
    "#         inv_Transform = np.eye(4)[:4]\n",
    "#         C = warp_spots[:,:3]\n",
    "#         warp_spots_new,_ = get_spot_inside(C,segmentation1,fix_spacing,ROI_fixed,cc)\n",
    "#         spot_mov = warp_spots_new\n",
    "#         lipo_c0,lipo_c1,_,_,dist3,P1,P2 = colocalization(spot_fix,warp_spots_new,neighbor_radius1)  # return in pixel\n",
    "#         print('% P1: ',str(P1) + ';  % P2: ',str(P2)) \n",
    "#         pair_dist = eucldist(lipo_c0,lipo_c1)\n",
    "#         print(f'ICP_Distance: {np.mean(pair_dist)}')\n",
    "    \n",
    "#     if Chn == \"C3\":\n",
    "#         # bleedthrough correction \n",
    "#         lo = np.percentile(np.ndarray.flatten(moving_ROI_c2),99.5) #Estimate fluorescence intensity of bright DAPI signals\n",
    "#         bg_dapi=np.percentile(np.ndarray.flatten(moving_ROI_c2[moving_ROI_c2!=0]),1) \n",
    "#         bg_data=np.percentile(np.ndarray.flatten(moving_ROI[moving_ROI!=0]),1) #Estimate background in AF546 channel\n",
    "#         dapi_factor=np.median((moving_ROI[moving_ROI_c2>lo] - bg_data)/(moving_ROI_c2[moving_ROI_c2>lo] - bg_dapi)) #Estimate % of signal bleedthrough\n",
    "#         moving_ROI_new  = np.maximum(0, moving_ROI - bg_data - dapi_factor * (moving_ROI_c2 - bg_dapi)).astype('float32')#subtract background and bleedthrough\n",
    "#         mov_affine_0 = transform.apply_global_affine(fix_ds, moving_ROI_new,fix_spacing, fix_spacing,global_affine_0,)\n",
    "#         mov_ds = transform.apply_global_affine(fix_ds, mov_affine_0,fix_spacing,fix_spacing,Transform_0,)\n",
    "        \n",
    "# #     mov_affine = scipy.ndimage.affine_transform(mov_ds,np.linalg.inv(global_affine)) \n",
    "#     mov_affine = transform.apply_global_affine(fix_ds, mov_ds, fix_spacing, fix_spacing,global_affine,)\n",
    "#     ICP_affine = transform.apply_global_affine(fix_ds, mov_affine, fix_spacing, fix_spacing,Transform,) \n",
    "# #     ICP_affine = scipy.ndimage.affine_transform(mov_affine,np.linalg.inv(invTransform)) \n",
    "    \n",
    "#     return P1,P2,dist1,dist2,pair_dist,spot_fix,mov_spots,warp_spots_new,fix_ds,ICP_affine,mov_affine,cc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the raw images and segmented ROIs (registered)\n",
    "We load the images of 2 channels of two rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 953 ms\n",
      "Wall time: 6.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # file paths to bigstrem REGISTERED data N5 files(include deform)\n",
    "# create Zarr file object using N5Stores\n",
    "seg_dir='E:/Maxprobe_analysis/R2_R1_3tm50/' # Analyze the below images ## image is in zyx or\n",
    "im_fixed = z5py.File(seg_dir + 'R2_3tm50_1920/stitching/export.n5', use_zarr_format=False)\n",
    "im_moving = z5py.File(seg_dir + 'R1_3tm50_1920/stitching/export.n5', use_zarr_format=False)\n",
    "\n",
    "# # UNREGISTERED of two rounds\n",
    "segmentation1=imread(seg_dir + 'R2_filtered_mask.tif')\n",
    "# # Registered and enlarged ROI\n",
    "segmentation2=imread(seg_dir + 'R1_filtered_mask.tif')\n",
    "# viewer.add_image(segmentation1,colormap='green',blending='additive') #load image data into napari\n",
    "# viewer.add_image(segmentation2,colormap='red',blending='additive') #load image data into napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign_roi_images\n",
    "#### need to load big raw images for each tile if using distributed computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# t = time()\n",
    "En_pixels = 0\n",
    "tile_number = 5\n",
    "out_dir = seg_dir +'R1_3tm50_1920/registration/python/tiles/'\n",
    "fix_path = seg_dir + 'R2_3tm50_1920/ROI/'\n",
    "roi_dir = seg_dir + 'allroi_matched.csv'   # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "# assign_roi_images(tile_number,fix_path,out_dir,seg_dir,roi_dir,segmentation1,segmentation2,En_pixels)\n",
    "# print('tictoc：%.2fs' % (time() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI_affine with image assisted cca on the true or shuffled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI_fix: 5; ROI_moving: 5\n",
      "DAPI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenggang\\Anaconda3\\envs\\easifish\\lib\\site-packages\\fishspot\\filter.py:12: FutureWarning: `selem` is a deprecated argument name for `white_tophat`. It will be removed in version 1.0. Please use `footprint` instead.\n",
      "  return skimage_white_tophat(image, selem=selem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIXED image: found 72 key points; MOVING image: found 55 key points\n",
      "Image: found 25 key points outside ROI\n",
      "match by correlation of intensities in images\n",
      "Found 42 matched fixed points\n",
      "ransac_Distance: 0.43716283053002586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenggang\\AppData\\Local\\Temp\\ipykernel_25312\\2236698611.py:123: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indecies = np.zeros(src.shape[0], dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: found 1 key points outside ROI\n",
      "% P1:  87.2340425531915;  % P2:  100.0\n",
      "ICP_Distance: 0.4290115700311131\n",
      "R2\n",
      "5# matches: ROI 347#\n",
      "R1\n",
      "5# matches: ROI 163#\n",
      "C3\n",
      "RS-FISH points from cluster\n",
      "FIXED: found 1504 key points; MOVING: found 1464 key points\n",
      "Image: found 17 key points outside ROI\n",
      "pre-ransac_Distance: 0.7959269732176549\n",
      "Found 1001 matched fixed points\n",
      "ransac_Distance: 0.6479384950207309\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 11, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:113\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 11, got 3)"
     ]
    }
   ],
   "source": [
    "%%time  \n",
    "#time: 60 images, 60 s for 4 images (c0-c3) if apply image ransac,40 s for 4 images (c0-c3) if not.\n",
    "tile_number = 5 #35\n",
    "seg_dir='E:/Maxprobe_analysis/R2_R1_3tm50/'\n",
    "roi_dir = seg_dir + 'allroi_matched.csv'   # directory to file containing the ROI metadata (neuron volume, etc.)\n",
    "df_allroi = pd.read_csv(roi_dir)\n",
    "spot_fix_c3_all = np.zeros((1, 4))\n",
    "warp_spots_c3_all = np.zeros((1, 4))\n",
    "spot_fix_c1_all = np.zeros((1, 4))\n",
    "warp_spots_c1_all = np.zeros((1, 4))\n",
    "spot_fix_c0_all = np.zeros((1, 4))\n",
    "warp_spots_c0_all = np.zeros((1, 4))\n",
    "fix_spacing=np.array([0.42,0.23,0.23])\n",
    "j=0\n",
    "Dist_sum_1 = np.zeros((len(df_allroi['fix']), 14)) # directory to file containing the registration stats\n",
    "affine_borrow = np.zeros((len(df_allroi['fix']), 6))\n",
    "# Dist_sum_1 = np.zeros((len(gad1_list), 14)) # when apply for GAD1 cells.\n",
    "# affine_borrow = np.zeros((len(gad1_list), 6))\n",
    "Shuffle_spots = 0\n",
    "\n",
    "for i in range(0, tile_number): # distributed\n",
    "#     i = 0\n",
    "#     seg_dir1='E:/Maxprobe_analysis/R2_R1_3tm50/R2_3tm50_1920/segmentation/'\n",
    "#     segmentation1=imread(seg_dir+'mask_all_R2.tif')\n",
    "#     seg_dir='E:/Maxprobe_analysis/R2_R1_3tm50/copytostephan/'\n",
    "#     segmentation2=imread(seg_dir+'mask_all_R1.tif') # Before bigstream\n",
    "    roi_dir = seg_dir + 'allroi_matched.csv'       # directory to file containing the ROI correspondence\n",
    "    df_allroi = pd.read_csv(roi_dir)\n",
    "    fix3_path = seg_dir + 'R2_3tm50_1920/ROI/'\n",
    "    ROI_RGB_path = seg_dir + 'R2_3tm50_1920/ROI_RGB/'\n",
    "    if not os.path.exists(ROI_RGB_path): os.mkdir(ROI_RGB_path)\n",
    "    roi_dir = fix3_path + str(i) + '/ROI_id.csv'   # directory to file containing the ROI correspondence of single tile\n",
    "    df_tile_roi = pd.read_csv(roi_dir)\n",
    "    ROI_id = df_tile_roi['fix'].astype(int)\n",
    "#     ROI_id = ROI_all[roi_inc*i:(i+1)*roi_inc]\n",
    "    \n",
    "    for aa in ROI_id:\n",
    "#         if aa in gad1_list: # < 1106\n",
    "        if aa == 5: #81 c2 529 for shuffle?\n",
    "            roi_dir = fix3_path + str(i) + '/R2_' + str(aa) + '_C2.tif'\n",
    "            fixed_ROI_c2 = imread(roi_dir)\n",
    "#             ROI_moving = df_allroi.loc[df_allroi['fix'].astype(int) == aa]['mov'].values[0].astype(int) #379\n",
    "            ROI_moving = aa\n",
    "            print('ROI_fix: ' + str(aa) + '; ROI_moving: ' + str(ROI_moving))\n",
    "            roi_dir = fix3_path + str(i) + '/R1_' + str(ROI_moving) + '_C2.tif'\n",
    "            moving_ROI_c2 = imread(roi_dir)\n",
    "\n",
    "            #for dapi: ~50 blobs can be detected\n",
    "            print(\"DAPI\")\n",
    "            threshold_fixed=0.001/50 #/50\n",
    "            threshold_moving=0.001/5 #/5\n",
    "            cc_r=12 \n",
    "            match_threshold=0.6  #0.7\n",
    "            align_threshold=0.5\n",
    "            Global_detection = 0\n",
    "            image_ransac = 1 # 1 is to get point correspondences from image; or 0 is to use nearest neighbors for local ransac\n",
    "            P1_C2,P2_C2,_,_,distances_2,global_affine2,inv_affine2,Transform2,inv_Transform2,fix_spots_2,mov_spots_2,warp_spots_new_2,ICP_affine_2,cc_2 = ROI_affine_bash(\n",
    "            segmentation1,segmentation2,aa,ROI_moving,fixed_ROI_c2,moving_ROI_c2,threshold_fixed,threshold_moving,\n",
    "            cc_r,match_threshold,align_threshold,Global_detection,image_ransac)\n",
    "            \n",
    "            a_rgb = np.zeros(fixed_ROI_c2.shape + (4,))\n",
    "            a_rgb[..., 0] = fixed_ROI_c2.astype(np.uint16)\n",
    "            a_rgb[..., 1] = ICP_affine_2.astype(np.uint16)\n",
    "            \n",
    "            Global_detection = 1\n",
    "            ransac_affine = 1 ## 1 is to apply local ransac affine (not use image) before ICP,0 is used orginal point cloud for ICP.\n",
    "#             image_ransac = 1 # > 0 is to get point correspondences from image after using nearest neighbors ; or 0 is to use nearest neighbors for local ransac\n",
    "            hAir = 0 # 0 is RS-FISH; 1 is for hAirlocalize\n",
    "            # find affine for cca\n",
    "            spotdir = seg_dir + 'R2ROI_points_fix.txt'\n",
    "            Rounds = [\"R2\",\"R1\"]\n",
    "            global_affine_fix,inv_affine_fix,Transform_fix,global_affine_mov,inv_affine_mov,Transform_mov,affine_borrow_idx = cca(\n",
    "                seg_dir,spotdir,aa,Rounds) \n",
    "\n",
    "            for Chn in [\"C3\"]: # [\"C1\",\"C3\",\"C0\"]\n",
    "#                 Chn = \"C3\"\n",
    "                print(Chn)\n",
    "                roi_dir = fix3_path + str(i) + '/R2_' + str(aa) + '_'+ Chn + '.tif'\n",
    "                fixed_ROI = imread(roi_dir)\n",
    "                roi_dir = fix3_path + str(i) + '/R1_' + str(ROI_moving) + '_'+ Chn + '.tif'\n",
    "                moving_ROI = imread(roi_dir)\n",
    "                # save rgb images \n",
    "                if Chn == \"C1\":\n",
    "                    #for c1\n",
    "                    threshold_fixed=0.001/20 #/20\n",
    "                    threshold_moving=0.001/2 #/2\n",
    "                    match_threshold=0.5  #0.5\n",
    "                    align_threshold=0.5  # 0.5\n",
    "                    neighbor_radius0 = 12\n",
    "                    image_ransac = 1 # number is specific distance threshold\n",
    "                    P1_C1,P2_C1,_,_,pair_dist_1, fix_spots_1,mov_spots_1,warp_spots_new_1,fixed_ROI_c1,ICP_affine_1,moving_affine_1,cc_1 = ROI_trackaffine_cca_bash(\n",
    "                        segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,\n",
    "                        cc_r,match_threshold,align_threshold,ransac_affine,global_affine_fix,inv_affine_fix,Transform_fix,\n",
    "                        global_affine_mov,inv_affine_mov,Transform_mov,global_affine2,inv_affine2,Transform2,inv_Transform2,\n",
    "                        Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "                    \n",
    "                    distances_1 = np.mean(pair_dist_1)                   \n",
    "                    a_rgb[..., 2] = fixed_ROI_c1.astype(np.uint16)\n",
    "                    a_rgb[..., 3] = ICP_affine_1.astype(np.uint16)\n",
    "#                     a_rgb[..., 3] = moving_affine_1.astype(np.uint16)\n",
    "                    roi_dir = ROI_RGB_path + '/'+ str(aa) + '_' + 'C2' + Chn +'.tif'\n",
    "                    imsave(roi_dir, a_rgb)\n",
    "                    a_rgb = []\n",
    "\n",
    "                elif Chn == \"C3\":\n",
    "                    #for c3\n",
    "                    \n",
    "                    threshold_fixed=0.001/8 #/4\n",
    "                    threshold_moving=0.001/4 #/2\n",
    "                    match_threshold=0.5  #0.7\n",
    "                    align_threshold=0.5\n",
    "                    image_ransac = 1 # number is specific distance threshold \n",
    "                    neighbor_radius0 = 12\n",
    "                    P1_C3,P2_C3,dist1,dist2,pair_dist_3,fix_spots_3,mov_spots_3,warp_spots_new_3,ICP_affine_3,moving_affine_3,cc_3 = ROI_trackaffine_bash(\n",
    "                    segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "                    ransac_affine,global_affine2,inv_affine2,Transform2,inv_Transform2,Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "         \n",
    "                    distances_3 = np.mean(pair_dist_3)\n",
    "                    lo=np.percentile(np.ndarray.flatten(fixed_ROI_c2),99.5) #Estimate fluorescence intensity of bright DAPI signals\n",
    "                    bg_dapi=np.percentile(np.ndarray.flatten(fixed_ROI_c2[fixed_ROI_c2!=0]),1) \n",
    "                    bg_data=np.percentile(np.ndarray.flatten(fixed_ROI[fixed_ROI!=0]),1) #Estimate background in AF546 channel\n",
    "                    dapi_factor=np.median((fixed_ROI[fixed_ROI_c2>lo] - bg_data)/(fixed_ROI_c2[fixed_ROI_c2>lo] - bg_dapi)) #Estimate % of signal bleedthrough\n",
    "                    fixed_ROI  = np.maximum(0, fixed_ROI - bg_data - dapi_factor * (fixed_ROI_c2 -bg_dapi)).astype('float32')#subtract background and bleedthrough                   \n",
    "                    a_rgb = np.zeros(fixed_ROI.shape + (4,))\n",
    "                    a_rgb[..., 0] = fixed_ROI.astype(np.uint16)\n",
    "                    a_rgb[..., 1] = ICP_affine_3.astype(np.uint16)\n",
    "                    fixed_ROI_c3 = fixed_ROI\n",
    "                    \n",
    "                else:\n",
    "                    #for c0\n",
    "                    threshold_fixed=0.001/20 #/20\n",
    "                    threshold_moving=0.001/2 #/2\n",
    "                    match_threshold=0.5  #0.5\n",
    "                    align_threshold=0.5  #0.5\n",
    "                    image_ransac = 1 # number is specific distance threshold for non-dapi track\n",
    "                    neighbor_radius0 = 12\n",
    "                    P1_C0,P2_C0,_,_,pair_dist_0,fix_spots_0,mov_spots_0,warp_spots_new_0,fixed_ROI_c0,ICP_affine_0,moving_affine_0,cc_0 = ROI_trackaffine_cca_bash(\n",
    "                        segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,\n",
    "                        cc_r,match_threshold,align_threshold,ransac_affine,global_affine_fix,inv_affine_fix,Transform_fix,\n",
    "                        global_affine_mov,inv_affine_mov,Transform_mov,global_affine2,inv_affine2,Transform2,inv_Transform2,\n",
    "                        Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "             \n",
    "                    distances_0 = np.mean(pair_dist_0)\n",
    "                    a_rgb[..., 2] = fixed_ROI_c0.astype(np.uint16)\n",
    "                    a_rgb[..., 3] = ICP_affine_0.astype(np.uint16)\n",
    "#                     a_rgb[..., 3] = moving_affine_0.astype(np.uint16)\n",
    "                    roi_dir = ROI_RGB_path + '/'+ str(aa) + '_' + 'C3' + Chn +'.tif'\n",
    "                    imsave(roi_dir, a_rgb)\n",
    "                    a_rgb = []\n",
    "            stop\n",
    "            # save C3 spots, global affine, warp affine.        \n",
    "            spot_fix3 = fix_spots_3/fix_spacing + [2*cc_3[0],4*cc_3[1],4*cc_3[2]]  # pre:in um, post: in px[um to px + mask(0, in px)]\n",
    "            spot_fix_c3 = np.column_stack((spot_fix3,np.ones(len(spot_fix3)).dot(aa))) # add ROI_ID\n",
    "            spot_fix_c3_all = np.row_stack((spot_fix_c3_all,spot_fix_c3))   # for all ROIs\n",
    "            warp_spots_3 = warp_spots_new_3[:,:3]/fix_spacing + [2*cc_3[0],4*cc_3[1],4*cc_3[2]]  # in pixels of S2\n",
    "            warp_spots_new_c3 = np.column_stack((warp_spots_3,np.ones(len(warp_spots_new_3)).dot(aa)))\n",
    "            warp_spots_c3_all = np.row_stack((warp_spots_c3_all,warp_spots_new_c3))\n",
    "            \n",
    "            # save C1 spots, global affine, warp affine.\n",
    "            spot_fix1 = fix_spots_1/fix_spacing + [2*cc_1[0],4*cc_1[1],4*cc_1[2]]  # in phsical distance of S2\n",
    "            spot_fix_c1 = np.column_stack((spot_fix1,np.ones(len(spot_fix1)).dot(aa)))\n",
    "            spot_fix_c1_all = np.row_stack((spot_fix_c1_all,spot_fix_c1))\n",
    "            if warp_spots_new_1.shape[0] == 0:\n",
    "                warp_spots_c1_all = warp_spots_c1_all\n",
    "            else:\n",
    "                warp_spots_1 = warp_spots_new_1[:,:3]/fix_spacing + [2*cc_1[0],4*cc_1[1],4*cc_1[2]]  # in pixels of S2\n",
    "                warp_spots_new_c1 = np.column_stack((warp_spots_1,np.ones(len(warp_spots_new_1)).dot(aa)))\n",
    "                warp_spots_c1_all = np.row_stack((warp_spots_c1_all,warp_spots_new_c1))\n",
    "            \n",
    "            # save C0 spots, global affine, warp affine.\n",
    "            spot_fix0 = fix_spots_0/fix_spacing + [2*cc_0[0],4*cc_0[1],4*cc_0[2]]  # in phsical distance of S2\n",
    "            spot_fix_c0 = np.column_stack((spot_fix0,np.ones(len(spot_fix0)).dot(aa)))\n",
    "            spot_fix_c0_all = np.row_stack((spot_fix_c0_all,spot_fix_c0))\n",
    "            warp_spots_0 = warp_spots_new_0[:,:3]/fix_spacing + [2*cc_0[0],4*cc_0[1],4*cc_0[2]]  # in pixels of S2\n",
    "            warp_spots_new_c0 = np.column_stack((warp_spots_0,np.ones(len(warp_spots_new_0)).dot(aa)))\n",
    "            warp_spots_c0_all = np.row_stack((warp_spots_c0_all,warp_spots_new_c0))\n",
    "            \n",
    "            affine_borrow[j,:] = affine_borrow_idx\n",
    "            # remember to remove the first 000 coordinates\n",
    "            Dist_sum_1[j,:] = [aa,ROI_moving,distances_0,P1_C0,P2_C0,\n",
    "                               distances_1,P1_C1,P2_C1,distances_2,P1_C2,P2_C2,\n",
    "                               distances_3,P1_C3,P2_C3]\n",
    "            j = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export RANSAC result spots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RS-FISH points from cluster\n",
      "FIXED: found 1504 key points; MOVING: found 1464 key points\n",
      "Image: found 17 key points outside ROI\n",
      "pre-ransac_Distance: 0.7959269732176549\n",
      "Found 1001 matched fixed points\n",
      "ransac_Distance: 0.6479384950207309\n"
     ]
    }
   ],
   "source": [
    "# A,B,neighbor_radius2 = ROI_trackaffine_cca_bash(\n",
    "#                         segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,\n",
    "#                         cc_r,match_threshold,align_threshold,ransac_affine,global_affine_fix,inv_affine_fix,Transform_fix,\n",
    "#                         global_affine_mov,inv_affine_mov,Transform_mov,global_affine2,inv_affine2,Transform2,inv_Transform2,\n",
    "#                         Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "\n",
    "# spot_extraction = ['hAir/','RS-FISH/affine_cca/'][1]\n",
    "# np.savetxt(seg_dir + spot_extraction + '5#_RANSAC_R2_c0_spots.txt',A,delimiter=',')\n",
    "# np.savetxt(seg_dir + spot_extraction + '5#_RANSAC_R1_c0_spots.txt',B,delimiter=',')\n",
    "\n",
    "# A,B,neighbor_radius2 = ROI_trackaffine_bash(\n",
    "#                     segmentation1,segmentation2,aa,ROI_moving,fixed_ROI,moving_ROI,moving_ROI_c2,threshold_fixed,threshold_moving,cc_r,match_threshold,align_threshold,\n",
    "#                     ransac_affine,global_affine2,inv_affine2,Transform2,inv_Transform2,Chn,Global_detection,image_ransac,hAir,neighbor_radius0,Shuffle_spots)\n",
    "\n",
    "# spot_extraction = ['hAir/','RS-FISH/affine_cca/'][1]\n",
    "# np.savetxt(seg_dir + spot_extraction + '5#_RANSAC_R2_c3_spots.txt',A,delimiter=',')\n",
    "# np.savetxt(seg_dir + spot_extraction + '5#_RANSAC_R1_c3_spots.txt',B,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test part for Shiqi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use ICP to register point clouds of an example ROI dataset. \n",
    "These spots have been corasely registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenggang\\Anaconda3\\envs\\easifish\\lib\\site-packages\\napari_tools_menu\\__init__.py:179: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    }
   ],
   "source": [
    "neighbor_radius2 = 1\n",
    "viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenggang\\AppData\\Local\\Temp\\ipykernel_25312\\2236698611.py:123: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indecies = np.zeros(src.shape[0], dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6426282206798919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenggang\\Anaconda3\\envs\\easifish\\lib\\site-packages\\numpy\\core\\numeric.py:2449: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "C:\\Users\\zhenggang\\Anaconda3\\envs\\easifish\\lib\\site-packages\\numpy\\core\\numeric.py:2449: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n",
      "C:\\Users\\zhenggang\\Anaconda3\\envs\\easifish\\lib\\site-packages\\numpy\\core\\numeric.py:2449: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "#ICP\n",
    "if __name__ == \"__main__\":\n",
    "    spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R2_c3_spots.txt'\n",
    "    A = np.loadtxt(spotdir, delimiter=',')\n",
    "    spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R1_c3_spots.txt'\n",
    "    B = np.loadtxt(spotdir, delimiter=',')\n",
    "    \n",
    "    Transform,_,_ = icp(A, B,neighbor_radius2)  # A->B \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    C = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist,_,_ = colocalization(A,C,neighbor_radius2*3)  # return in pixel\n",
    "    \n",
    "    print(dist)\n",
    "\n",
    "    viewer.add_points(np.transpose(np.array([A[:,0]/fix_spacing[0],A[:,1]/fix_spacing[1],A[:,2]/fix_spacing[2]])),name ='A', size=1,\n",
    "                      face_color='green',edge_color='green',blending='opaque') \n",
    "    viewer.add_points(np.transpose(np.array([B[:,0]/fix_spacing[0],B[:,1]/fix_spacing[1],B[:,2]/fix_spacing[2]])),name ='B', size=1, \n",
    "                      face_color='red',edge_color='red',blending='opaque') \n",
    "    viewer.add_points(np.transpose(np.array([C[:,0]/fix_spacing[0],C[:,1]/fix_spacing[1],C[:,2]/fix_spacing[2]])),name ='C', size=1,\n",
    "                      face_color='yellow',edge_color='yellow',blending='opaque') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ransac_icp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m spotdir \u001b[38;5;241m=\u001b[39m seg_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRS-FISH/affine_cca/5#_RANSAC_R1_c3_spots.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(spotdir, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m Transform,_,_ \u001b[38;5;241m=\u001b[39m \u001b[43mransac_icp\u001b[49m(A, B,neighbor_radius2)  \u001b[38;5;66;03m# A->B \u001b[39;00m\n\u001b[0;32m      9\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(B, np\u001b[38;5;241m.\u001b[39mones((B\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)        \n\u001b[0;32m     10\u001b[0m D \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mdot(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(Transform)\u001b[38;5;241m.\u001b[39mT)        \u001b[38;5;66;03m## B->A spots (right) with B->A transform (right)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ransac_icp' is not defined"
     ]
    }
   ],
   "source": [
    "#RANSAC ICP \n",
    "if __name__ == \"__main__\":\n",
    "    spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R2_c3_spots.txt'\n",
    "    A = np.loadtxt(spotdir, delimiter=',')\n",
    "    spotdir = seg_dir + 'RS-FISH/affine_cca/5#_RANSAC_R1_c3_spots.txt'\n",
    "    B = np.loadtxt(spotdir, delimiter=',')\n",
    "    \n",
    "    Transform,_,_ = ransac_icp(A, B,neighbor_radius2)  # A->B \n",
    "    p = np.append(B, np.ones((B.shape[0],1)), axis=1)        \n",
    "    D = p.dot(np.linalg.inv(Transform).T)        ## B->A spots (right) with B->A transform (right)\n",
    "    D = D[:,:3]\n",
    "    # Test ICP distance change. Minor increased performance\n",
    "    lipo_c0,lipo_c1,true_pos_c0,true_pos_c1,dist,_,_ = colocalization(A,C,neighbor_radius2*3)  # return in pixel\n",
    "    \n",
    "    print(dist)\n",
    "    viewer = napari.view_image(data.astronaut(), rgb=True)\n",
    "    napari.run()\n",
    "    viewer.add_points(np.transpose(np.array([D[:,0]/fix_spacing[0],D[:,1]/fix_spacing[1],D[:,2]/fix_spacing[2]])),name ='D', size=1,\n",
    "                      face_color='yellow',edge_color='yellow',blending='opaque') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easifish",
   "language": "python",
   "name": "easifish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
